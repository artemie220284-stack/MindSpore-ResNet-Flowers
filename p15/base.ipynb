{
 "cells": [
  {
   "cell_type": "code",
   "id": "c7e5a666-fdab-4bf7-9a7f-11653c01bccb",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-12-29T06:11:06.413262703Z",
     "start_time": "2025-12-29T06:11:06.354485613Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 设置CUDA_HOME环境变量\n",
    "conda_prefix = os.environ.get('CONDA_PREFIX')\n",
    "if conda_prefix:\n",
    "    os.environ['CUDA_HOME'] = conda_prefix\n",
    "    os.environ['LD_LIBRARY_PATH'] = f\"{conda_prefix}/lib:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
    "    \n",
    "    print(f\"已设置环境变量:\")\n",
    "    print(f\"  CUDA_HOME: {os.environ['CUDA_HOME']}\")\n",
    "    print(f\"  CONDA_PREFIX: {conda_prefix}\")\n",
    "    \n",
    "    # 验证libcuda.so是否存在\n",
    "    libcuda_path = f\"{conda_prefix}/lib/libcuda.so\"\n",
    "    if os.path.exists(libcuda_path):\n",
    "        print(f\"  ✓ libcuda.so: 找到 ({libcuda_path})\")\n",
    "    else:\n",
    "        print(f\"  ✗ libcuda.so: 在conda环境中未找到\")\n",
    "        \n",
    "        # 创建符号链接到系统libcuda\n",
    "        system_libcuda = \"/usr/lib/x86_64-linux-gnu/libcuda.so\"\n",
    "        if os.path.exists(system_libcuda):\n",
    "            os.system(f\"ln -sf {system_libcuda} {conda_prefix}/lib/libcuda.so\")\n",
    "            print(f\"  ✓ 已创建符号链接: {conda_prefix}/lib/libcuda.so -> {system_libcuda}\")\n",
    "        else:\n",
    "            print(f\"  ⚠ 系统libcuda.so也未找到\")\n",
    "else:\n",
    "    print(\"CONDA_PREFIX未设置，请先激活conda环境\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已设置环境变量:\n",
      "  CUDA_HOME: /home/y/anaconda3/envs/mindspore\n",
      "  CONDA_PREFIX: /home/y/anaconda3/envs/mindspore\n",
      "  ✓ libcuda.so: 找到 (/home/y/anaconda3/envs/mindspore/lib/libcuda.so)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ddc3cd83-306b-4729-a17d-376ae08cc8e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:11:07.133968392Z",
     "start_time": "2025-12-29T06:11:06.415531700Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "from mindspore import Parameter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 检查MindSpore环境\n",
    "print(\"=\"*60)\n",
    "print(\"MindSpore环境检查\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import mindspore as ms\n",
    "    from mindspore import context, Tensor, Model, load_checkpoint, save_checkpoint\n",
    "    import mindspore.nn as nn\n",
    "    import mindspore.ops as ops\n",
    "    from mindspore.train.callback import LossMonitor, TimeMonitor, ModelCheckpoint, CheckpointConfig\n",
    "    from mindspore import dataset as ds\n",
    "    import mindspore.dataset.vision as vision\n",
    "    import mindspore.dataset.transforms as transforms\n",
    "    \n",
    "    # 设置GPU\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target='GPU')\n",
    "    print(f\"✓ MindSpore版本: {ms.__version__}\")\n",
    "    print(f\"✓ 使用设备: GPU\")\n",
    "    print(f\"✓ 运行模式: GRAPH_MODE\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ MindSpore导入失败: {e}\")\n",
    "    # 尝试使用CPU\n",
    "    try:\n",
    "        context.set_context(device_target='CPU')\n",
    "        print(f\"✓ 使用设备: CPU (备用)\")\n",
    "    except:\n",
    "        print(\"✗ MindSpore环境异常\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MindSpore环境检查\n",
      "============================================================\n",
      "✓ MindSpore版本: 2.2.0\n",
      "✓ 使用设备: GPU\n",
      "✓ 运行模式: GRAPH_MODE\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "6721515c-e121-437c-8aea-10fd286a39f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-12-29T06:11:07.226487084Z",
     "start_time": "2025-12-29T06:11:07.181091554Z"
    }
   },
   "source": [
    "class Config:\n",
    "    # 路径配置\n",
    "    data_dir = \"flowers\"  # 数据目录\n",
    "    model_path = \"best_flower_model.ckpt\"  # 模型保存路径\n",
    "    metrics_path = \"training_metrics.npy\"  # 指标保存路径\n",
    "    \n",
    "    # 类别信息\n",
    "    class_names = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # 训练参数\n",
    "    batch_size = 32\n",
    "    epochs = 20\n",
    "    learning_rate = 1e-4\n",
    "    image_size = (224, 224)\n",
    "    \n",
    "    # 数据集分割\n",
    "    train_ratio = 0.8  # 训练集比例\n",
    "    \n",
    "config = Config()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "75c33ffd-576b-4130-a26e-2c57c8432adb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-12-29T06:11:07.340747917Z",
     "start_time": "2025-12-29T06:11:07.227052585Z"
    }
   },
   "source": [
    "def prepare_dataset():\n",
    "    \"\"\"准备和预处理数据集\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"数据准备\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 检查数据目录\n",
    "    if not os.path.exists(config.data_dir):\n",
    "        print(f\"✗ 数据目录不存在: {config.data_dir}\")\n",
    "        print(\"请确保在项目根目录下创建 'flowers' 文件夹，并包含以下子目录：\")\n",
    "        print(\"  flowers/train/  - 训练图像\")\n",
    "        print(\"  flowers/test/   - 测试图像\")\n",
    "        print(\"每个子目录下应有5个文件夹: daisy, dandelion, rose, sunflower, tulip\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # 数据集统计\n",
    "    def count_images(folder):\n",
    "        count = 0\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            count += len([f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        return count\n",
    "    \n",
    "    train_dir = os.path.join(config.data_dir, \"train\")\n",
    "    test_dir = os.path.join(config.data_dir, \"test\")\n",
    "    \n",
    "    if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "        print(\"✗ 未找到 train/ 或 test/ 子目录\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # 统计数据\n",
    "    train_count = count_images(train_dir)\n",
    "    test_count = count_images(test_dir)\n",
    "    \n",
    "    print(f\"✓ 训练集图像: {train_count} 张\")\n",
    "    print(f\"✓ 测试集图像: {test_count} 张\")\n",
    "    print(f\"✓ 类别数量: {config.num_classes}\")\n",
    "    print(f\"✓ 类别名称: {config.class_names}\")\n",
    "    \n",
    "    # 定义数据变换 - 修复：添加 Decode() 操作\n",
    "    # 训练集变换（数据增强）\n",
    "    train_transform = [\n",
    "        vision.Decode(),  # 关键修复：必须先解码图像\n",
    "        vision.Resize(config.image_size),\n",
    "        vision.RandomHorizontalFlip(prob=0.5),\n",
    "        vision.RandomColorAdjust(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        vision.RandomRotation(degrees=15),\n",
    "        vision.ToTensor(),\n",
    "        vision.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], is_hwc=False)\n",
    "    ]\n",
    "    \n",
    "    # 测试集变换（无数据增强）\n",
    "    test_transform = [\n",
    "        vision.Decode(),  # 关键修复：必须先解码图像\n",
    "        vision.Resize(config.image_size),\n",
    "        vision.ToTensor(),\n",
    "        vision.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], is_hwc=False)\n",
    "    ]\n",
    "    \n",
    "    # 创建MindSpore数据集\n",
    "    def create_mindspore_dataset(data_path, transform, shuffle=True):\n",
    "        dataset = ds.ImageFolderDataset(\n",
    "            data_path,\n",
    "            shuffle=shuffle,\n",
    "            extensions=[\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\"]\n",
    "        )\n",
    "        \n",
    "        # 应用变换\n",
    "        dataset = dataset.map(\n",
    "            operations=transform,\n",
    "            input_columns=\"image\"\n",
    "        )\n",
    "        \n",
    "        # 类型转换\n",
    "        dataset = dataset.map(\n",
    "            operations=transforms.TypeCast(ms.int32),\n",
    "            input_columns=\"label\"\n",
    "        )\n",
    "        \n",
    "        # 批处理\n",
    "        dataset = dataset.batch(config.batch_size, drop_remainder=False)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    # 创建数据集\n",
    "    print(\"创建训练数据集...\")\n",
    "    train_dataset = create_mindspore_dataset(train_dir, train_transform, shuffle=True)\n",
    "    print(\"创建测试数据集...\")\n",
    "    test_dataset = create_mindspore_dataset(test_dir, test_transform, shuffle=False)\n",
    "    \n",
    "    # 计算数据集大小\n",
    "    train_size = train_dataset.get_dataset_size() * config.batch_size\n",
    "    test_size = test_dataset.get_dataset_size() * config.batch_size\n",
    "    \n",
    "    print(f\"✓ 训练批次数: {train_dataset.get_dataset_size()}\")\n",
    "    print(f\"✓ 测试批次数: {test_dataset.get_dataset_size()}\")\n",
    "    \n",
    "    # 测试数据集是否能正常读取\n",
    "    print(\"\\n测试数据读取...\")\n",
    "    try:\n",
    "        test_iter = train_dataset.create_tuple_iterator()\n",
    "        test_images, test_labels = next(test_iter)\n",
    "        print(f\"✓ 数据读取测试通过\")\n",
    "        print(f\"  图像形状: {test_images.shape}\")\n",
    "        print(f\"  标签形状: {test_labels.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ 数据读取测试失败: {e}\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    return train_dataset, test_dataset, train_size, test_size\n",
    "\n",
    "# 准备数据\n",
    "train_dataset, test_dataset, train_size, test_size = prepare_dataset()\n",
    "# 准备数据\n",
    "train_dataset, test_dataset, train_size, test_size = prepare_dataset()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "数据准备\n",
      "============================================================\n",
      "✓ 训练集图像: 3665 张\n",
      "✓ 测试集图像: 652 张\n",
      "✓ 类别数量: 5\n",
      "✓ 类别名称: ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
      "创建训练数据集...\n",
      "创建测试数据集...\n",
      "✓ 训练批次数: 115\n",
      "✓ 测试批次数: 21\n",
      "\n",
      "测试数据读取...\n",
      "✓ 数据读取测试通过\n",
      "  图像形状: (32, 3, 224, 224)\n",
      "  标签形状: (32,)\n",
      "============================================================\n",
      "数据准备\n",
      "============================================================\n",
      "✓ 训练集图像: 3665 张\n",
      "✓ 测试集图像: 652 张\n",
      "✓ 类别数量: 5\n",
      "✓ 类别名称: ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
      "创建训练数据集...\n",
      "创建测试数据集...\n",
      "✓ 训练批次数: 115\n",
      "✓ 测试批次数: 21\n",
      "\n",
      "测试数据读取...\n",
      "✓ 数据读取测试通过\n",
      "  图像形状: (32, 3, 224, 224)\n",
      "  标签形状: (32,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "26b03fe6-f769-4caf-b0d1-12c3e7fd43aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:14:53.030093530Z",
     "start_time": "2025-12-29T06:14:52.535773918Z"
    }
   },
   "source": [
    "def build_resnet50_model():\n",
    "    \"\"\"构建ResNet50迁移学习模型\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"模型构建\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 方法1: 使用MindSpore内置的ResNet50\n",
    "    try:\n",
    "        from mindcv.models import create_model\n",
    "        \n",
    "        print(\"从MindSpore Hub加载预训练ResNet50...\")\n",
    "        # 从Hub加载预训练模型\n",
    "        model = create_model(\"BiT_resnet50\", pretrained=True, num_classes=1000)\n",
    "        \n",
    "        if hasattr(model, 'classifier'):\n",
    "            in_channels = model.classifier.in_channels\n",
    "            model.classifier = nn.Dense(in_channels, 5)\n",
    "            print(f\"✓ 替换classifier: {in_channels} -> 5\")\n",
    "        elif hasattr(model, 'head'):\n",
    "            in_channels = model.head.in_channels\n",
    "            model.head = nn.Dense(in_channels, 5)\n",
    "            print(f\"✓ 替换head: {in_channels} -> 5\")\n",
    "        elif hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Dense(in_features, 5)\n",
    "            print(f\"✓ 替换fc: {in_features} -> 5\")\n",
    "        else:\n",
    "            # 尝试找到最后一个Dense层\n",
    "            for name, cell in model.cells_and_names():\n",
    "                if isinstance(cell, nn.Dense):\n",
    "                    in_features = cell.in_features\n",
    "                    # 这里需要实际替换，但要知道层的位置\n",
    "                    print(f\"找到Dense层: {name}, 输入: {in_features}\")\n",
    "                    # 你可能需要直接修改模型结构\n",
    "                    break\n",
    "\n",
    "        # 冻结前面层\n",
    "        print(\"\\n冻结参数...\")\n",
    "        for name, param in model.parameters_and_names():\n",
    "            if 'classifier' in name or 'head' in name or 'fc' in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        trainable = sum(p.size for p in model.trainable_params())\n",
    "        total = sum(p.size for p in model.get_parameters())\n",
    "        print(f\"可训练参数: {trainable:,}/{total:,}\")\n",
    "\n",
    "        print(\"✓ 模型准备完成！\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"从Hub加载失败: {e}\")\n",
    "        print(\"使用自定义ResNet50实现...\")\n",
    "        \n",
    "        # 方法2: 自定义ResNet50\n",
    "        class ResNet50(nn.Cell):\n",
    "            def __init__(self, num_classes=config.num_classes):\n",
    "                super(ResNet50, self).__init__()\n",
    "                \n",
    "                # 简化的ResNet50结构\n",
    "                self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, pad_mode='pad', padding=3)\n",
    "                self.bn1 = nn.BatchNorm2d(64)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='same')\n",
    "                \n",
    "                # 残差块（简化版本）\n",
    "                self.layer1 = self._make_layer(64, 64, 3, stride=1)\n",
    "                self.layer2 = self._make_layer(64, 128, 4, stride=2)\n",
    "                self.layer3 = self._make_layer(128, 256, 6, stride=2)\n",
    "                self.layer4 = self._make_layer(256, 512, 3, stride=2)\n",
    "                \n",
    "                self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.fc = nn.Dense(512, num_classes)\n",
    "                \n",
    "            def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
    "                layers = []\n",
    "                # 第一个残差块可能需要下采样\n",
    "                layers.append(self._residual_block(in_channels, out_channels, stride))\n",
    "                \n",
    "                for _ in range(1, blocks):\n",
    "                    layers.append(self._residual_block(out_channels, out_channels, 1))\n",
    "                    \n",
    "                return nn.SequentialCell(layers)\n",
    "            \n",
    "            def _residual_block(self, in_channels, out_channels, stride):\n",
    "                return nn.SequentialCell([\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, \n",
    "                             pad_mode='pad', padding=1, has_bias=False),\n",
    "                    nn.BatchNorm2d(out_channels),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n",
    "                             pad_mode='pad', padding=1, has_bias=False),\n",
    "                    nn.BatchNorm2d(out_channels)\n",
    "                ])\n",
    "            \n",
    "            def construct(self, x):\n",
    "                x = self.conv1(x)\n",
    "                x = self.bn1(x)\n",
    "                x = self.relu(x)\n",
    "                x = self.maxpool(x)\n",
    "                \n",
    "                x = self.layer1(x)\n",
    "                x = self.layer2(x)\n",
    "                x = self.layer3(x)\n",
    "                x = self.layer4(x)\n",
    "                \n",
    "                x = self.avgpool(x)\n",
    "                x = self.flatten(x)\n",
    "                x = self.fc(x)\n",
    "                \n",
    "                return x\n",
    "        \n",
    "        model = ResNet50()\n",
    "        print(f\"✓ 自定义ResNet50构建完成\")\n",
    "        print(f\"✓ 参数量: {sum(p.size for p in model.trainable_params()):,}\")\n",
    "        \n",
    "        return model\n",
    "model=build_resnet50_model()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "模型构建\n",
      "============================================================\n",
      "从MindSpore Hub加载预训练ResNet50...\n",
      "✓ 替换classifier: 2048 -> 5\n",
      "\n",
      "冻结参数...\n",
      "可训练参数: 10,245/23,510,597\n",
      "✓ 模型准备完成！\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:18:08.908625023Z",
     "start_time": "2025-12-29T06:18:06.982724632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fix_bit_model_simple(model):\n",
    "    \"\"\"简单修复BiT模型维度问题\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"简单修复BiT模型维度\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    import mindspore.nn as nn\n",
    "    import mindspore.ops as ops\n",
    "\n",
    "    print(f\"模型类型: {type(model)}\")\n",
    "\n",
    "    # 方法：直接封装模型\n",
    "    class FixedBitModel(nn.Cell):\n",
    "        def __init__(self, backbone, num_classes=5):\n",
    "            super().__init__()\n",
    "            self.backbone = backbone\n",
    "\n",
    "            # 移除原分类头\n",
    "            if hasattr(backbone, 'classifier'):\n",
    "                backbone.classifier = nn.Identity()\n",
    "            if hasattr(backbone, 'head'):\n",
    "                backbone.head = nn.Identity()\n",
    "            if hasattr(backbone, 'fc'):\n",
    "                backbone.fc = nn.Identity()\n",
    "\n",
    "            # BiT-ResNet50输出2048维特征\n",
    "            self.global_pool = ops.ReduceMean(keep_dims=False)\n",
    "            self.classifier = nn.Dense(2048, num_classes)\n",
    "\n",
    "            # 冻结特征提取层\n",
    "            for param in self.backbone.get_parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        def construct(self, x):\n",
    "            # 提取特征\n",
    "            x = self.backbone(x)\n",
    "\n",
    "            # 处理维度\n",
    "            if len(x.shape) == 4:\n",
    "                # (B, C, H, W) -> (B, C)\n",
    "                x = self.global_pool(x, (2, 3))\n",
    "            elif len(x.shape) == 2:\n",
    "                # 已经展平\n",
    "                pass\n",
    "            else:\n",
    "                # 其他情况，简单展平\n",
    "                x = x.reshape(x.shape[0], -1)\n",
    "                if x.shape[1] != 2048:\n",
    "                    # 调整到2048维\n",
    "                    x = x[:, :2048] if x.shape[1] > 2048 else ops.pad(x, ((0, 0), (0, 2048 - x.shape[1])))\n",
    "\n",
    "            # 分类\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "    # 创建修复后的模型\n",
    "    fixed_model = FixedBitModel(model, config.num_classes)\n",
    "\n",
    "    print(f\"✓ 模型修复完成\")\n",
    "    print(f\"  输入: 3x224x224\")\n",
    "    print(f\"  输出: {config.num_classes}类\")\n",
    "\n",
    "    # 测试\n",
    "    import numpy as np\n",
    "    test_input = ms.Tensor(np.random.randn(2, 3, 224, 224).astype(np.float32))\n",
    "    output = fixed_model(test_input)\n",
    "    print(f\"  测试输入: {test_input.shape}\")\n",
    "    print(f\"  测试输出: {output.shape}\")\n",
    "\n",
    "    return fixed_model\n",
    "\n",
    "# 使用简单修复\n",
    "print(\"修复模型维度...\")\n",
    "model = fix_bit_model_simple(model)"
   ],
   "id": "7445e894986853b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修复模型维度...\n",
      "============================================================\n",
      "简单修复BiT模型维度\n",
      "============================================================\n",
      "模型类型: <class 'mindcv.models.bit.BiT_ResNet'>\n",
      "✓ 模型修复完成\n",
      "  输入: 3x224x224\n",
      "  输出: 5类\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(280126,79ff5f932600,python):2025-12-29-14:18:07.989.298 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_280126/3613542768.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  测试输入: (2, 3, 224, 224)\n",
      "  测试输出: (2, 5)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "f46994e3-511d-4360-8ee0-adbdba2d2a7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:18:12.672319449Z",
     "start_time": "2025-12-29T06:18:12.646587831Z"
    }
   },
   "source": [
    "def setup_training(model):\n",
    "    \"\"\"设置训练组件\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"训练配置\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 损失函数\n",
    "    loss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    \n",
    "    # 优化器 - 直接使用学习率，不在这里设置调度器\n",
    "    optimizer = nn.Adam(\n",
    "        model.trainable_params(),\n",
    "        learning_rate=config.learning_rate,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    \n",
    "    # 注意：piecewise_constant_lr 需要里程碑数量 = 学习率数量 - 1\n",
    "    # 但我们将在训练循环中手动实现学习率调度\n",
    "    \n",
    "    # 模型编译\n",
    "    net_with_loss = nn.WithLossCell(model, loss_fn)\n",
    "    train_net = nn.TrainOneStepCell(net_with_loss, optimizer)\n",
    "    \n",
    "    # 评估指标\n",
    "    metrics = {\n",
    "        'accuracy': nn.Accuracy(),\n",
    "        'loss': nn.Loss()\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ 损失函数: SoftmaxCrossEntropyWithLogits\")\n",
    "    print(f\"✓ 优化器: Adam (lr={config.learning_rate})\")\n",
    "    print(f\"✓ 学习率调度: 手动调整（每7个epoch减少10倍）\")\n",
    "    \n",
    "    return train_net, loss_fn, optimizer, metrics\n",
    "\n",
    "train_net, loss_fn, optimizer, metrics = setup_training(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "训练配置\n",
      "============================================================\n",
      "✓ 损失函数: SoftmaxCrossEntropyWithLogits\n",
      "✓ 优化器: Adam (lr=0.0001)\n",
      "✓ 学习率调度: 手动调整（每7个epoch减少10倍）\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "08882532-cba4-4200-a7b9-0118249700d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:38:07.465083018Z",
     "start_time": "2025-12-29T06:18:13.752066441Z"
    }
   },
   "source": [
    "def train_model(model, train_dataset, test_dataset):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"开始训练\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 初始化记录\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    # 创建评估模型\n",
    "    eval_net = nn.WithEvalCell(model, loss_fn, add_cast_fp32=False)\n",
    "    \n",
    "    # 创建 argmax 操作\n",
    "    argmax_op = ops.Argmax(output_type=ms.int32)\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(config.epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config.epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 学习率调整（每7个epoch减少10倍）\n",
    "        if epoch in [7, 14]:  # 第8和15个epoch调整学习率\n",
    "            current_lr = config.learning_rate / (10 ** (epoch // 7))\n",
    "            optimizer.learning_rate = Parameter(Tensor(current_lr, ms.float32), name='learning_rate')\n",
    "            print(f\"学习率调整为: {current_lr}\")\n",
    "        \n",
    "        # 训练阶段\n",
    "        model.set_train()\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        batch_iterator = train_dataset.create_tuple_iterator()\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(batch_iterator):\n",
    "            # 前向传播和反向传播\n",
    "            loss = train_net(images, labels)\n",
    "            \n",
    "            # 计算准确率\n",
    "            outputs = model(images)\n",
    "            predictions = argmax_op(outputs)\n",
    "            \n",
    "            correct += (predictions.asnumpy() == labels.asnumpy()).sum()\n",
    "            total += labels.shape[0]\n",
    "            epoch_loss += loss.asnumpy()\n",
    "            \n",
    "            # 进度显示\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                current_acc = correct / total if total > 0 else 0\n",
    "                current_loss = epoch_loss / (batch_idx + 1)\n",
    "                print(f\"  Batch {batch_idx+1}/{train_dataset.get_dataset_size()}, \"\n",
    "                      f\"Loss: {current_loss:.4f}, Acc: {current_acc:.4f}\")\n",
    "        \n",
    "        # 计算epoch指标\n",
    "        train_loss = epoch_loss / max(1, train_dataset.get_dataset_size())\n",
    "        train_acc = correct / total if total > 0 else 0\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        \n",
    "        # 评估阶段 - 修复：正确处理 eval_net 的输出\n",
    "        model.set_train(False)\n",
    "        test_loss = 0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        for images, labels in test_dataset.create_tuple_iterator():\n",
    "            # 计算损失 - 修复：eval_net 可能返回元组\n",
    "            eval_outputs = eval_net(images, labels)\n",
    "            \n",
    "            # 提取损失值\n",
    "            if isinstance(eval_outputs, tuple):\n",
    "                # 第一个元素通常是损失值\n",
    "                loss_value = eval_outputs[0]\n",
    "            else:\n",
    "                loss_value = eval_outputs\n",
    "            \n",
    "            test_loss += loss_value.asnumpy()\n",
    "            \n",
    "            # 计算准确率\n",
    "            outputs = model(images)\n",
    "            predictions = argmax_op(outputs)\n",
    "            test_correct += (predictions.asnumpy() == labels.asnumpy()).sum()\n",
    "            test_total += labels.shape[0]\n",
    "        \n",
    "        test_loss = test_loss / max(1, test_dataset.get_dataset_size())\n",
    "        test_acc = test_correct / test_total if test_total > 0 else 0\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # 输出epoch结果\n",
    "        print(f\"训练结果: 损失={train_loss:.4f}, 准确率={train_acc:.4f}\")\n",
    "        print(f\"测试结果: 损失={test_loss:.4f}, 准确率={test_acc:.4f}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if test_acc > best_accuracy:\n",
    "            best_accuracy = test_acc\n",
    "            save_checkpoint(model, config.model_path)\n",
    "            print(f\"✓ 保存最佳模型，准确率: {best_accuracy:.4f}\")\n",
    "    \n",
    "    # 保存训练指标\n",
    "    metrics_dict = {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accuracies': test_accuracies\n",
    "    }\n",
    "    np.save(config.metrics_path, metrics_dict)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"训练完成！最佳测试准确率: {best_accuracy:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies\n",
    "# 开始训练\n",
    "if train_dataset is not None:\n",
    "    print(f\"开始训练，共 {config.epochs} 个epoch\")\n",
    "    train_losses, train_accuracies, test_losses, test_accuracies = train_model(\n",
    "        model, train_dataset, test_dataset\n",
    "    )\n",
    "else:\n",
    "    print(\"✗ 数据集不可用，跳过训练\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练，共 20 个epoch\n",
      "============================================================\n",
      "开始训练\n",
      "============================================================\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(280126,79ff5f932600,python):2025-12-29-14:18:18.221.033 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_280126/3613542768.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 10/115, Loss: 1.5823, Acc: 0.3156\n",
      "  Batch 20/115, Loss: 1.5274, Acc: 0.4062\n",
      "  Batch 30/115, Loss: 1.4952, Acc: 0.4313\n",
      "  Batch 40/115, Loss: 1.4703, Acc: 0.4547\n",
      "  Batch 50/115, Loss: 1.4422, Acc: 0.4838\n",
      "  Batch 60/115, Loss: 1.4116, Acc: 0.5135\n",
      "  Batch 70/115, Loss: 1.3867, Acc: 0.5339\n",
      "  Batch 80/115, Loss: 1.3610, Acc: 0.5496\n",
      "  Batch 90/115, Loss: 1.3389, Acc: 0.5646\n",
      "  Batch 100/115, Loss: 1.3167, Acc: 0.5747\n",
      "  Batch 110/115, Loss: 1.2926, Acc: 0.5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(280126,79ff5f932600,python):2025-12-29-14:19:11.649.573 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_280126/3613542768.py]\n",
      "[ERROR] CORE(280126,79ff5f932600,python):2025-12-29-14:19:15.127.054 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_280126/3613542768.py]\n",
      "[ERROR] CORE(280126,79ff5f932600,python):2025-12-29-14:19:26.403.436 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_280126/3613542768.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练结果: 损失=1.2831, 准确率=0.5951\n",
      "测试结果: 损失=1.1099, 准确率=0.6472\n",
      "✓ 保存最佳模型，准确率: 0.6472\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 1.0095, Acc: 0.7469\n",
      "  Batch 20/115, Loss: 1.0060, Acc: 0.7422\n",
      "  Batch 30/115, Loss: 1.0206, Acc: 0.7250\n",
      "  Batch 40/115, Loss: 1.0147, Acc: 0.7234\n",
      "  Batch 50/115, Loss: 1.0002, Acc: 0.7306\n",
      "  Batch 60/115, Loss: 0.9891, Acc: 0.7349\n",
      "  Batch 70/115, Loss: 0.9808, Acc: 0.7344\n",
      "  Batch 80/115, Loss: 0.9698, Acc: 0.7383\n",
      "  Batch 90/115, Loss: 0.9603, Acc: 0.7441\n",
      "  Batch 100/115, Loss: 0.9481, Acc: 0.7481\n",
      "  Batch 110/115, Loss: 0.9406, Acc: 0.7497\n",
      "训练结果: 损失=0.9394, 准确率=0.7490\n",
      "测试结果: 损失=0.9242, 准确率=0.6687\n",
      "✓ 保存最佳模型，准确率: 0.6687\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.7919, Acc: 0.7500\n",
      "  Batch 20/115, Loss: 0.8236, Acc: 0.7406\n",
      "  Batch 30/115, Loss: 0.8258, Acc: 0.7438\n",
      "  Batch 40/115, Loss: 0.8104, Acc: 0.7594\n",
      "  Batch 50/115, Loss: 0.8064, Acc: 0.7675\n",
      "  Batch 60/115, Loss: 0.8041, Acc: 0.7682\n",
      "  Batch 70/115, Loss: 0.8056, Acc: 0.7643\n",
      "  Batch 80/115, Loss: 0.7963, Acc: 0.7699\n",
      "  Batch 90/115, Loss: 0.7935, Acc: 0.7701\n",
      "  Batch 100/115, Loss: 0.7851, Acc: 0.7747\n",
      "  Batch 110/115, Loss: 0.7875, Acc: 0.7705\n",
      "训练结果: 损失=0.7880, 准确率=0.7689\n",
      "测试结果: 损失=0.8382, 准确率=0.6933\n",
      "✓ 保存最佳模型，准确率: 0.6933\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.7166, Acc: 0.8125\n",
      "  Batch 20/115, Loss: 0.7328, Acc: 0.7875\n",
      "  Batch 30/115, Loss: 0.7369, Acc: 0.7740\n",
      "  Batch 40/115, Loss: 0.7181, Acc: 0.7883\n",
      "  Batch 50/115, Loss: 0.7176, Acc: 0.7844\n",
      "  Batch 60/115, Loss: 0.7221, Acc: 0.7844\n",
      "  Batch 70/115, Loss: 0.7110, Acc: 0.7897\n",
      "  Batch 80/115, Loss: 0.6990, Acc: 0.7949\n",
      "  Batch 90/115, Loss: 0.6946, Acc: 0.7969\n",
      "  Batch 100/115, Loss: 0.6961, Acc: 0.7966\n",
      "  Batch 110/115, Loss: 0.6947, Acc: 0.7963\n",
      "训练结果: 损失=0.6934, 准确率=0.7975\n",
      "测试结果: 损失=0.7889, 准确率=0.7009\n",
      "✓ 保存最佳模型，准确率: 0.7009\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.6372, Acc: 0.8281\n",
      "  Batch 20/115, Loss: 0.6343, Acc: 0.8250\n",
      "  Batch 30/115, Loss: 0.6369, Acc: 0.8125\n",
      "  Batch 40/115, Loss: 0.6400, Acc: 0.8102\n",
      "  Batch 50/115, Loss: 0.6384, Acc: 0.8106\n",
      "  Batch 60/115, Loss: 0.6365, Acc: 0.8125\n",
      "  Batch 70/115, Loss: 0.6492, Acc: 0.8058\n",
      "  Batch 80/115, Loss: 0.6467, Acc: 0.8059\n",
      "  Batch 90/115, Loss: 0.6448, Acc: 0.8059\n",
      "  Batch 100/115, Loss: 0.6389, Acc: 0.8072\n",
      "  Batch 110/115, Loss: 0.6362, Acc: 0.8091\n",
      "训练结果: 损失=0.6357, 准确率=0.8095\n",
      "测试结果: 损失=0.7410, 准确率=0.7117\n",
      "✓ 保存最佳模型，准确率: 0.7117\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.6469, Acc: 0.7969\n",
      "  Batch 20/115, Loss: 0.6238, Acc: 0.8203\n",
      "  Batch 30/115, Loss: 0.6351, Acc: 0.8115\n",
      "  Batch 40/115, Loss: 0.6267, Acc: 0.8070\n",
      "  Batch 50/115, Loss: 0.6218, Acc: 0.8113\n",
      "  Batch 60/115, Loss: 0.6203, Acc: 0.8109\n",
      "  Batch 70/115, Loss: 0.6220, Acc: 0.8089\n",
      "  Batch 80/115, Loss: 0.6136, Acc: 0.8113\n",
      "  Batch 90/115, Loss: 0.6086, Acc: 0.8167\n",
      "  Batch 100/115, Loss: 0.6080, Acc: 0.8153\n",
      "  Batch 110/115, Loss: 0.6079, Acc: 0.8151\n",
      "训练结果: 损失=0.6020, 准确率=0.8180\n",
      "测试结果: 损失=0.7075, 准确率=0.7239\n",
      "✓ 保存最佳模型，准确率: 0.7239\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.6101, Acc: 0.8000\n",
      "  Batch 20/115, Loss: 0.5924, Acc: 0.8125\n",
      "  Batch 30/115, Loss: 0.5796, Acc: 0.8240\n",
      "  Batch 40/115, Loss: 0.5786, Acc: 0.8242\n",
      "  Batch 50/115, Loss: 0.5722, Acc: 0.8294\n",
      "  Batch 60/115, Loss: 0.5650, Acc: 0.8297\n",
      "  Batch 70/115, Loss: 0.5631, Acc: 0.8321\n",
      "  Batch 80/115, Loss: 0.5632, Acc: 0.8285\n",
      "  Batch 90/115, Loss: 0.5611, Acc: 0.8295\n",
      "  Batch 100/115, Loss: 0.5637, Acc: 0.8263\n",
      "  Batch 110/115, Loss: 0.5624, Acc: 0.8259\n",
      "训练结果: 损失=0.5617, 准确率=0.8276\n",
      "测试结果: 损失=0.6856, 准确率=0.7439\n",
      "✓ 保存最佳模型，准确率: 0.7439\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "学习率调整为: 1e-05\n",
      "  Batch 10/115, Loss: 0.5531, Acc: 0.8281\n",
      "  Batch 20/115, Loss: 0.5463, Acc: 0.8266\n",
      "  Batch 30/115, Loss: 0.5554, Acc: 0.8250\n",
      "  Batch 40/115, Loss: 0.5578, Acc: 0.8242\n",
      "  Batch 50/115, Loss: 0.5537, Acc: 0.8269\n",
      "  Batch 60/115, Loss: 0.5492, Acc: 0.8271\n",
      "  Batch 70/115, Loss: 0.5484, Acc: 0.8295\n",
      "  Batch 80/115, Loss: 0.5413, Acc: 0.8309\n",
      "  Batch 90/115, Loss: 0.5365, Acc: 0.8323\n",
      "  Batch 100/115, Loss: 0.5362, Acc: 0.8341\n",
      "  Batch 110/115, Loss: 0.5375, Acc: 0.8335\n",
      "训练结果: 损失=0.5379, 准确率=0.8336\n",
      "测试结果: 损失=0.6694, 准确率=0.7500\n",
      "✓ 保存最佳模型，准确率: 0.7500\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.5293, Acc: 0.8281\n",
      "  Batch 20/115, Loss: 0.5202, Acc: 0.8359\n",
      "  Batch 30/115, Loss: 0.5230, Acc: 0.8417\n",
      "  Batch 40/115, Loss: 0.5106, Acc: 0.8500\n",
      "  Batch 50/115, Loss: 0.5070, Acc: 0.8488\n",
      "  Batch 60/115, Loss: 0.5073, Acc: 0.8474\n",
      "  Batch 70/115, Loss: 0.5088, Acc: 0.8473\n",
      "  Batch 80/115, Loss: 0.5035, Acc: 0.8516\n",
      "  Batch 90/115, Loss: 0.5027, Acc: 0.8510\n",
      "  Batch 100/115, Loss: 0.5028, Acc: 0.8522\n",
      "  Batch 110/115, Loss: 0.5050, Acc: 0.8477\n",
      "训练结果: 损失=0.5042, 准确率=0.8461\n",
      "测试结果: 损失=0.6498, 准确率=0.7577\n",
      "✓ 保存最佳模型，准确率: 0.7577\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.4821, Acc: 0.8656\n",
      "  Batch 20/115, Loss: 0.4885, Acc: 0.8438\n",
      "  Batch 30/115, Loss: 0.4867, Acc: 0.8521\n",
      "  Batch 40/115, Loss: 0.4960, Acc: 0.8477\n",
      "  Batch 50/115, Loss: 0.4898, Acc: 0.8538\n",
      "  Batch 60/115, Loss: 0.4994, Acc: 0.8495\n",
      "  Batch 70/115, Loss: 0.4994, Acc: 0.8482\n",
      "  Batch 80/115, Loss: 0.5032, Acc: 0.8453\n",
      "  Batch 90/115, Loss: 0.5035, Acc: 0.8455\n",
      "  Batch 100/115, Loss: 0.5046, Acc: 0.8456\n",
      "  Batch 110/115, Loss: 0.4993, Acc: 0.8463\n",
      "训练结果: 损失=0.4970, 准确率=0.8464\n",
      "测试结果: 损失=0.6335, 准确率=0.7669\n",
      "✓ 保存最佳模型，准确率: 0.7669\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.4766, Acc: 0.8406\n",
      "  Batch 20/115, Loss: 0.5117, Acc: 0.8234\n",
      "  Batch 30/115, Loss: 0.5059, Acc: 0.8333\n",
      "  Batch 40/115, Loss: 0.5006, Acc: 0.8367\n",
      "  Batch 50/115, Loss: 0.5045, Acc: 0.8363\n",
      "  Batch 60/115, Loss: 0.4942, Acc: 0.8427\n",
      "  Batch 70/115, Loss: 0.4889, Acc: 0.8446\n",
      "  Batch 80/115, Loss: 0.4860, Acc: 0.8457\n",
      "  Batch 90/115, Loss: 0.4847, Acc: 0.8438\n",
      "  Batch 100/115, Loss: 0.4845, Acc: 0.8431\n",
      "  Batch 110/115, Loss: 0.4813, Acc: 0.8463\n",
      "训练结果: 损失=0.4809, 准确率=0.8464\n",
      "测试结果: 损失=0.6257, 准确率=0.7607\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.5020, Acc: 0.8469\n",
      "  Batch 20/115, Loss: 0.4777, Acc: 0.8625\n",
      "  Batch 30/115, Loss: 0.4787, Acc: 0.8625\n",
      "  Batch 40/115, Loss: 0.4803, Acc: 0.8508\n",
      "  Batch 50/115, Loss: 0.4766, Acc: 0.8494\n",
      "  Batch 60/115, Loss: 0.4694, Acc: 0.8526\n",
      "  Batch 70/115, Loss: 0.4763, Acc: 0.8478\n",
      "  Batch 80/115, Loss: 0.4738, Acc: 0.8480\n",
      "  Batch 90/115, Loss: 0.4732, Acc: 0.8500\n",
      "  Batch 100/115, Loss: 0.4688, Acc: 0.8531\n",
      "  Batch 110/115, Loss: 0.4673, Acc: 0.8540\n",
      "训练结果: 损失=0.4636, 准确率=0.8546\n",
      "测试结果: 损失=0.6230, 准确率=0.7715\n",
      "✓ 保存最佳模型，准确率: 0.7715\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.4589, Acc: 0.8500\n",
      "  Batch 20/115, Loss: 0.4440, Acc: 0.8469\n",
      "  Batch 30/115, Loss: 0.4488, Acc: 0.8417\n",
      "  Batch 40/115, Loss: 0.4464, Acc: 0.8461\n",
      "  Batch 50/115, Loss: 0.4547, Acc: 0.8413\n",
      "  Batch 60/115, Loss: 0.4622, Acc: 0.8422\n",
      "  Batch 70/115, Loss: 0.4554, Acc: 0.8496\n",
      "  Batch 80/115, Loss: 0.4516, Acc: 0.8531\n",
      "  Batch 90/115, Loss: 0.4573, Acc: 0.8535\n",
      "  Batch 100/115, Loss: 0.4569, Acc: 0.8547\n",
      "  Batch 110/115, Loss: 0.4540, Acc: 0.8568\n",
      "训练结果: 损失=0.4540, 准确率=0.8568\n",
      "测试结果: 损失=0.6158, 准确率=0.7791\n",
      "✓ 保存最佳模型，准确率: 0.7791\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.4343, Acc: 0.8469\n",
      "  Batch 20/115, Loss: 0.4598, Acc: 0.8438\n",
      "  Batch 30/115, Loss: 0.4598, Acc: 0.8521\n",
      "  Batch 40/115, Loss: 0.4566, Acc: 0.8547\n",
      "  Batch 50/115, Loss: 0.4584, Acc: 0.8544\n",
      "  Batch 60/115, Loss: 0.4553, Acc: 0.8536\n",
      "  Batch 70/115, Loss: 0.4529, Acc: 0.8522\n",
      "  Batch 80/115, Loss: 0.4492, Acc: 0.8535\n",
      "  Batch 90/115, Loss: 0.4415, Acc: 0.8562\n",
      "  Batch 100/115, Loss: 0.4431, Acc: 0.8566\n",
      "  Batch 110/115, Loss: 0.4388, Acc: 0.8594\n",
      "训练结果: 损失=0.4425, 准确率=0.8576\n",
      "测试结果: 损失=0.6063, 准确率=0.7761\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "学习率调整为: 1e-06\n",
      "  Batch 10/115, Loss: 0.4294, Acc: 0.8531\n",
      "  Batch 20/115, Loss: 0.4306, Acc: 0.8500\n",
      "  Batch 30/115, Loss: 0.4223, Acc: 0.8646\n",
      "  Batch 40/115, Loss: 0.4269, Acc: 0.8633\n",
      "  Batch 50/115, Loss: 0.4258, Acc: 0.8625\n",
      "  Batch 60/115, Loss: 0.4304, Acc: 0.8583\n",
      "  Batch 70/115, Loss: 0.4286, Acc: 0.8580\n",
      "  Batch 80/115, Loss: 0.4339, Acc: 0.8570\n",
      "  Batch 90/115, Loss: 0.4360, Acc: 0.8559\n",
      "  Batch 100/115, Loss: 0.4378, Acc: 0.8550\n",
      "  Batch 110/115, Loss: 0.4364, Acc: 0.8565\n",
      "训练结果: 损失=0.4354, 准确率=0.8584\n",
      "测试结果: 损失=0.5945, 准确率=0.7837\n",
      "✓ 保存最佳模型，准确率: 0.7837\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.4413, Acc: 0.8406\n",
      "  Batch 20/115, Loss: 0.4352, Acc: 0.8469\n",
      "  Batch 30/115, Loss: 0.4438, Acc: 0.8490\n",
      "  Batch 40/115, Loss: 0.4286, Acc: 0.8547\n",
      "  Batch 50/115, Loss: 0.4181, Acc: 0.8631\n",
      "  Batch 60/115, Loss: 0.4163, Acc: 0.8646\n",
      "  Batch 70/115, Loss: 0.4173, Acc: 0.8652\n",
      "  Batch 80/115, Loss: 0.4144, Acc: 0.8660\n",
      "  Batch 90/115, Loss: 0.4176, Acc: 0.8653\n",
      "  Batch 100/115, Loss: 0.4205, Acc: 0.8634\n",
      "  Batch 110/115, Loss: 0.4183, Acc: 0.8648\n",
      "训练结果: 损失=0.4213, 准确率=0.8630\n",
      "测试结果: 损失=0.5889, 准确率=0.7837\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.4257, Acc: 0.8688\n",
      "  Batch 20/115, Loss: 0.4195, Acc: 0.8656\n",
      "  Batch 30/115, Loss: 0.4263, Acc: 0.8646\n",
      "  Batch 40/115, Loss: 0.4187, Acc: 0.8688\n",
      "  Batch 50/115, Loss: 0.4269, Acc: 0.8612\n",
      "  Batch 60/115, Loss: 0.4277, Acc: 0.8620\n",
      "  Batch 70/115, Loss: 0.4254, Acc: 0.8603\n",
      "  Batch 80/115, Loss: 0.4282, Acc: 0.8590\n",
      "  Batch 90/115, Loss: 0.4211, Acc: 0.8649\n",
      "  Batch 100/115, Loss: 0.4252, Acc: 0.8631\n",
      "  Batch 110/115, Loss: 0.4180, Acc: 0.8656\n",
      "训练结果: 损失=0.4152, 准确率=0.8668\n",
      "测试结果: 损失=0.5904, 准确率=0.7853\n",
      "✓ 保存最佳模型，准确率: 0.7853\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.4864, Acc: 0.8469\n",
      "  Batch 20/115, Loss: 0.4547, Acc: 0.8453\n",
      "  Batch 30/115, Loss: 0.4301, Acc: 0.8542\n",
      "  Batch 40/115, Loss: 0.4198, Acc: 0.8625\n",
      "  Batch 50/115, Loss: 0.4091, Acc: 0.8675\n",
      "  Batch 60/115, Loss: 0.4164, Acc: 0.8661\n",
      "  Batch 70/115, Loss: 0.4142, Acc: 0.8647\n",
      "  Batch 80/115, Loss: 0.4180, Acc: 0.8625\n",
      "  Batch 90/115, Loss: 0.4200, Acc: 0.8604\n",
      "  Batch 100/115, Loss: 0.4150, Acc: 0.8616\n",
      "  Batch 110/115, Loss: 0.4132, Acc: 0.8611\n",
      "训练结果: 损失=0.4115, 准确率=0.8617\n",
      "测试结果: 损失=0.5822, 准确率=0.7899\n",
      "✓ 保存最佳模型，准确率: 0.7899\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.3735, Acc: 0.8906\n",
      "  Batch 20/115, Loss: 0.4142, Acc: 0.8688\n",
      "  Batch 30/115, Loss: 0.4119, Acc: 0.8677\n",
      "  Batch 40/115, Loss: 0.4218, Acc: 0.8641\n",
      "  Batch 50/115, Loss: 0.4138, Acc: 0.8675\n",
      "  Batch 60/115, Loss: 0.4135, Acc: 0.8688\n",
      "  Batch 70/115, Loss: 0.4136, Acc: 0.8679\n",
      "  Batch 80/115, Loss: 0.4080, Acc: 0.8730\n",
      "  Batch 90/115, Loss: 0.4079, Acc: 0.8705\n",
      "  Batch 100/115, Loss: 0.4064, Acc: 0.8709\n",
      "  Batch 110/115, Loss: 0.4042, Acc: 0.8707\n",
      "训练结果: 损失=0.4030, 准确率=0.8712\n",
      "测试结果: 损失=0.5761, 准确率=0.7853\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.3939, Acc: 0.8812\n",
      "  Batch 20/115, Loss: 0.4002, Acc: 0.8844\n",
      "  Batch 30/115, Loss: 0.3969, Acc: 0.8823\n",
      "  Batch 40/115, Loss: 0.3849, Acc: 0.8867\n",
      "  Batch 50/115, Loss: 0.3807, Acc: 0.8844\n",
      "  Batch 60/115, Loss: 0.3818, Acc: 0.8839\n",
      "  Batch 70/115, Loss: 0.3875, Acc: 0.8804\n",
      "  Batch 80/115, Loss: 0.3833, Acc: 0.8836\n",
      "  Batch 90/115, Loss: 0.3903, Acc: 0.8778\n",
      "  Batch 100/115, Loss: 0.3909, Acc: 0.8762\n",
      "  Batch 110/115, Loss: 0.3922, Acc: 0.8741\n",
      "训练结果: 损失=0.3931, 准确率=0.8723\n",
      "测试结果: 损失=0.5708, 准确率=0.7899\n",
      "\n",
      "============================================================\n",
      "训练完成！最佳测试准确率: 0.7899\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:58:52.916259834Z",
     "start_time": "2025-12-29T06:58:52.867915985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FocalLoss(nn.Cell):\n",
    "    \"\"\"修正的Focal Loss实现\"\"\"\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "        self.softmax = nn.Softmax(axis=1)\n",
    "        self.onehot = nn.OneHot(depth=config.num_classes)\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.log = ops.Log()\n",
    "        self.pow = ops.Pow()\n",
    "\n",
    "    def construct(self, inputs, targets):\n",
    "        # 计算softmax概率\n",
    "        probs = self.softmax(inputs)\n",
    "\n",
    "        # 将targets转换为one-hot编码\n",
    "        targets_onehot = self.onehot(targets)\n",
    "\n",
    "        # 计算每个样本的类别概率 (B, num_classes) * (B, num_classes) -> (B,)\n",
    "        class_probs = self.reduce_sum(probs * targets_onehot, 1)\n",
    "\n",
    "        # 计算调制因子 (1 - pt)^gamma\n",
    "        modulating_factor = self.pow(1 - class_probs, self.gamma)\n",
    "\n",
    "        # 计算交叉熵\n",
    "        ce_loss = -self.log(class_probs + 1e-8)\n",
    "\n",
    "        # 计算focal loss\n",
    "        focal_loss = modulating_factor * ce_loss\n",
    "\n",
    "        # 应用类别权重（如果提供）\n",
    "        if self.alpha is not None:\n",
    "            alpha_factor = ops.gather(self.alpha, targets, 0)\n",
    "            focal_loss = alpha_factor * focal_loss\n",
    "\n",
    "        # 根据reduction参数返回结果\n",
    "        if self.reduction == 'mean':\n",
    "            return ops.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return ops.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ],
   "id": "ee75d63448487efd",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T07:03:53.628602075Z",
     "start_time": "2025-12-29T06:58:56.008275752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 新增单元格 - 直接加载检查点继续训练\n",
    "print(\"=\"*60)\n",
    "print(\"加载检查点并继续训练5个epoch\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "# 1. 加载检查点\n",
    "if os.path.exists(config.model_path):\n",
    "    try:\n",
    "        param_dict = load_checkpoint(config.model_path)\n",
    "        load_param_into_net(model, param_dict)\n",
    "        print(f\"✓ 检查点加载成功: {config.model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ 加载失败: {e}\")\n",
    "else:\n",
    "    print(f\"⚠ 检查点不存在: {config.model_path}\")\n",
    "\n",
    "# 2. 使用FocalLoss\n",
    "print(\"\\n使用FocalLoss训练...\")\n",
    "loss_fn = FocalLoss(gamma=2.0, reduction='mean')\n",
    "\n",
    "# 3. 直接调用原有train_model函数（只训练5个epoch）\n",
    "print(\"\\n开始训练5个epoch...\")\n",
    "\n",
    "# 保存原始epochs\n",
    "original_epochs = config.epochs\n",
    "config.epochs = 5\n",
    "\n",
    "# 运行训练\n",
    "if train_dataset is not None:\n",
    "    print(f\"开始训练，共 {config.epochs} 个epoch\")\n",
    "    train_losses, train_accuracies, test_losses, test_accuracies = train_model(\n",
    "        model, train_dataset, test_dataset\n",
    "    )\n",
    "else:\n",
    "    print(\"✗ 数据集不可用\")\n",
    "\n",
    "# 恢复原始epochs（可选）\n",
    "config.epochs = original_epochs"
   ],
   "id": "8e66fb7d519bcedf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "加载检查点并继续训练5个epoch\n",
      "============================================================\n",
      "✓ 检查点加载成功: best_flower_model.ckpt\n",
      "\n",
      "使用FocalLoss训练...\n",
      "\n",
      "开始训练5个epoch...\n",
      "开始训练，共 5 个epoch\n",
      "============================================================\n",
      "开始训练\n",
      "============================================================\n",
      "\n",
      "Epoch 1/5\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.3790, Acc: 0.8656\n",
      "  Batch 20/115, Loss: 0.4158, Acc: 0.8531\n",
      "  Batch 30/115, Loss: 0.4079, Acc: 0.8583\n",
      "  Batch 40/115, Loss: 0.4033, Acc: 0.8641\n",
      "  Batch 50/115, Loss: 0.4049, Acc: 0.8662\n",
      "  Batch 60/115, Loss: 0.4094, Acc: 0.8635\n",
      "  Batch 70/115, Loss: 0.4102, Acc: 0.8603\n",
      "  Batch 80/115, Loss: 0.4061, Acc: 0.8641\n",
      "  Batch 90/115, Loss: 0.4065, Acc: 0.8663\n",
      "  Batch 100/115, Loss: 0.4084, Acc: 0.8662\n",
      "  Batch 110/115, Loss: 0.4088, Acc: 0.8662\n",
      "训练结果: 损失=0.4078, 准确率=0.8677\n",
      "测试结果: 损失=0.3222, 准确率=0.7853\n",
      "✓ 保存最佳模型，准确率: 0.7853\n",
      "\n",
      "Epoch 2/5\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.3857, Acc: 0.8719\n",
      "  Batch 20/115, Loss: 0.4227, Acc: 0.8453\n",
      "  Batch 30/115, Loss: 0.4097, Acc: 0.8552\n",
      "  Batch 40/115, Loss: 0.4141, Acc: 0.8602\n",
      "  Batch 50/115, Loss: 0.4105, Acc: 0.8619\n",
      "  Batch 60/115, Loss: 0.4074, Acc: 0.8661\n",
      "  Batch 70/115, Loss: 0.4112, Acc: 0.8625\n",
      "  Batch 80/115, Loss: 0.4063, Acc: 0.8652\n",
      "  Batch 90/115, Loss: 0.4048, Acc: 0.8656\n",
      "  Batch 100/115, Loss: 0.4010, Acc: 0.8688\n",
      "  Batch 110/115, Loss: 0.4005, Acc: 0.8707\n",
      "训练结果: 损失=0.3986, 准确率=0.8709\n",
      "测试结果: 损失=0.3300, 准确率=0.7914\n",
      "✓ 保存最佳模型，准确率: 0.7914\n",
      "\n",
      "Epoch 3/5\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.3529, Acc: 0.8719\n",
      "  Batch 20/115, Loss: 0.3743, Acc: 0.8766\n",
      "  Batch 30/115, Loss: 0.3633, Acc: 0.8865\n",
      "  Batch 40/115, Loss: 0.3712, Acc: 0.8836\n",
      "  Batch 50/115, Loss: 0.3712, Acc: 0.8838\n",
      "  Batch 60/115, Loss: 0.3790, Acc: 0.8797\n",
      "  Batch 70/115, Loss: 0.3947, Acc: 0.8741\n",
      "  Batch 80/115, Loss: 0.3950, Acc: 0.8762\n",
      "  Batch 90/115, Loss: 0.3872, Acc: 0.8781\n",
      "  Batch 100/115, Loss: 0.3896, Acc: 0.8750\n",
      "  Batch 110/115, Loss: 0.3884, Acc: 0.8750\n",
      "训练结果: 损失=0.3882, 准确率=0.8753\n",
      "测试结果: 损失=0.3264, 准确率=0.7929\n",
      "✓ 保存最佳模型，准确率: 0.7929\n",
      "\n",
      "Epoch 4/5\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.3658, Acc: 0.9094\n",
      "  Batch 20/115, Loss: 0.3656, Acc: 0.8953\n",
      "  Batch 30/115, Loss: 0.3679, Acc: 0.8865\n",
      "  Batch 40/115, Loss: 0.3707, Acc: 0.8852\n",
      "  Batch 50/115, Loss: 0.3829, Acc: 0.8775\n",
      "  Batch 60/115, Loss: 0.3824, Acc: 0.8766\n",
      "  Batch 70/115, Loss: 0.3793, Acc: 0.8750\n",
      "  Batch 80/115, Loss: 0.3810, Acc: 0.8746\n",
      "  Batch 90/115, Loss: 0.3861, Acc: 0.8708\n",
      "  Batch 100/115, Loss: 0.3894, Acc: 0.8675\n",
      "  Batch 110/115, Loss: 0.3855, Acc: 0.8693\n",
      "训练结果: 损失=0.3860, 准确率=0.8685\n",
      "测试结果: 损失=0.3277, 准确率=0.7945\n",
      "✓ 保存最佳模型，准确率: 0.7945\n",
      "\n",
      "Epoch 5/5\n",
      "----------------------------------------\n",
      "  Batch 10/115, Loss: 0.3846, Acc: 0.8844\n",
      "  Batch 20/115, Loss: 0.3851, Acc: 0.8859\n",
      "  Batch 30/115, Loss: 0.3806, Acc: 0.8865\n",
      "  Batch 40/115, Loss: 0.3861, Acc: 0.8789\n",
      "  Batch 50/115, Loss: 0.3844, Acc: 0.8781\n",
      "  Batch 60/115, Loss: 0.3820, Acc: 0.8786\n",
      "  Batch 70/115, Loss: 0.3909, Acc: 0.8768\n",
      "  Batch 80/115, Loss: 0.3853, Acc: 0.8773\n",
      "  Batch 90/115, Loss: 0.3800, Acc: 0.8806\n",
      "  Batch 100/115, Loss: 0.3741, Acc: 0.8834\n",
      "  Batch 110/115, Loss: 0.3739, Acc: 0.8827\n",
      "训练结果: 损失=0.3747, 准确率=0.8827\n",
      "测试结果: 损失=0.3360, 准确率=0.7929\n",
      "\n",
      "============================================================\n",
      "训练完成！最佳测试准确率: 0.7945\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "7e85d13e-e576-43a1-8b2f-1a569c4d2c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:40:24.362989585Z",
     "start_time": "2025-12-29T06:40:23.663724912Z"
    }
   },
   "source": [
    "def visualize_results():\n",
    "    \"\"\"可视化训练结果\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"结果可视化\")\n",
    "    print(\"=\"*60)\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    # 检查是否有训练指标\n",
    "    if not os.path.exists(config.metrics_path):\n",
    "        print(f\"✗ 未找到训练指标文件: {config.metrics_path}\")\n",
    "        print(\"请先完成训练\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # 加载训练指标\n",
    "        metrics = np.load(config.metrics_path, allow_pickle=True).item()\n",
    "        train_losses = metrics['train_losses']\n",
    "        train_accuracies = metrics['train_accuracies']\n",
    "        test_losses = metrics['test_losses']\n",
    "        test_accuracies = metrics['test_accuracies']\n",
    "        \n",
    "        epochs = range(1, len(train_losses) + 1)\n",
    "        \n",
    "        # 创建图形 - 修复：使用更简单的方法设置中文字体\n",
    "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. 损失曲线\n",
    "        axes[0, 0].plot(epochs, train_losses, 'b-', label='Train Loss', marker='o', linewidth=2)\n",
    "        axes[0, 0].plot(epochs, test_losses, 'r-', label='Test Loss', marker='s', linewidth=2)\n",
    "        axes[0, 0].set_title('Training and Testing Loss', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. 准确率曲线\n",
    "        axes[0, 1].plot(epochs, train_accuracies, 'g-', label='Train Accuracy', marker='o', linewidth=2)\n",
    "        axes[0, 1].plot(epochs, test_accuracies, 'orange', label='Test Accuracy', marker='s', linewidth=2)\n",
    "        axes[0, 1].set_title('Training and Testing Accuracy', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].set_ylim([0, 1.0])\n",
    "        \n",
    "        # 3. 最终准确率对比\n",
    "        final_train_acc = train_accuracies[-1] if train_accuracies else 0\n",
    "        final_test_acc = test_accuracies[-1] if test_accuracies else 0\n",
    "        \n",
    "        axes[1, 0].bar(['Train', 'Test'], [final_train_acc, final_test_acc], \n",
    "                      color=['green', 'red'], alpha=0.7, width=0.5)\n",
    "        axes[1, 0].set_title('Final Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_ylabel('Accuracy')\n",
    "        axes[1, 0].set_ylim([0, 1.0])\n",
    "        axes[1, 0].text(0, final_train_acc + 0.02, f'{final_train_acc:.4f}', \n",
    "                       ha='center', fontweight='bold')\n",
    "        axes[1, 0].text(1, final_test_acc + 0.02, f'{final_test_acc:.4f}', \n",
    "                       ha='center', fontweight='bold')\n",
    "        \n",
    "        # 4. 类别分布\n",
    "        try:\n",
    "            # 统计训练集类别分布\n",
    "            train_counts = {}\n",
    "            train_dir = os.path.join(config.data_dir, \"train\")\n",
    "            for class_name in config.class_names:\n",
    "                class_dir = os.path.join(train_dir, class_name)\n",
    "                if os.path.exists(class_dir):\n",
    "                    count = len([f for f in os.listdir(class_dir) \n",
    "                               if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                    train_counts[class_name] = count\n",
    "                else:\n",
    "                    train_counts[class_name] = 0\n",
    "            \n",
    "            # 显示类别分布\n",
    "            class_values = [train_counts[cls] for cls in config.class_names]\n",
    "            colors = plt.cm.Set3(np.arange(len(config.class_names)) / len(config.class_names))\n",
    "            axes[1, 1].bar(range(len(config.class_names)), class_values, color=colors)\n",
    "            axes[1, 1].set_title('Training Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "            axes[1, 1].set_xlabel('Flower Class')\n",
    "            axes[1, 1].set_ylabel('Number of Samples')\n",
    "            axes[1, 1].set_xticks(range(len(config.class_names)))\n",
    "            axes[1, 1].set_xticklabels(config.class_names, rotation=15)\n",
    "            \n",
    "            # 添加数值标签\n",
    "            for i, count in enumerate(class_values):\n",
    "                axes[1, 1].text(i, count + max(class_values)*0.02, f'{count}', \n",
    "                               ha='center', fontweight='bold')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Class distribution failed: {e}\")\n",
    "            axes[1, 1].text(0.5, 0.5, 'Class distribution data\\nnot available', \n",
    "                          ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_results_2.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"✓ Visualization saved as 'training_results_2.png'\")\n",
    "        \n",
    "        # 显示关键指标\n",
    "        print(\"\\nKey Metrics Summary:\")\n",
    "        if train_accuracies:\n",
    "            print(f\"  Best Train Accuracy: {max(train_accuracies):.4f}\")\n",
    "        if test_accuracies:\n",
    "            print(f\"  Best Test Accuracy: {max(test_accuracies):.4f}\")\n",
    "            print(f\"  Final Test Accuracy: {final_test_acc:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Visualization failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "# 执行可视化\n",
    "visualize_results()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "结果可视化\n",
      "============================================================\n",
      "✓ Visualization saved as 'training_results_1.png'\n",
      "\n",
      "Key Metrics Summary:\n",
      "  Best Train Accuracy: 0.8723\n",
      "  Best Test Accuracy: 0.7899\n",
      "  Final Test Accuracy: 0.7899\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "6044c607-70ef-4846-b13f-3c6574a17508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:40:32.992177573Z",
     "start_time": "2025-12-29T06:40:28.305266462Z"
    }
   },
   "source": [
    "def evaluate_model():\n",
    "    \"\"\"评估模型性能\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"模型评估\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 检查模型文件\n",
    "    if not os.path.exists(config.model_path):\n",
    "        print(f\"✗ 模型文件不存在: {config.model_path}\")\n",
    "        print(\"请先训练模型或确保模型文件存在\")\n",
    "        return\n",
    "    \n",
    "    # 检查测试集\n",
    "    if test_dataset is None:\n",
    "        print(\"✗ 测试集不可用\")\n",
    "        return\n",
    "    \n",
    "    # 导入必要的函数\n",
    "    from mindspore import load_param_into_net\n",
    "    \n",
    "    # 加载模型\n",
    "    try:\n",
    "        model.set_train(False)\n",
    "        param_dict = ms.load_checkpoint(config.model_path)  # 使用 ms.load_checkpoint\n",
    "        \n",
    "        # 检查模型参数是否匹配\n",
    "        model_params = {p.name: p for p in model.get_parameters()}\n",
    "        load_success = True\n",
    "        for name, param in param_dict.items():\n",
    "            if name in model_params:\n",
    "                model_params[name].set_data(param)\n",
    "            else:\n",
    "                print(f\"Warning: Parameter {name} not in current model\")\n",
    "        \n",
    "        print(f\"✓ Model loaded successfully: {config.model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Model loading failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # 评估\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    class_correct = [0] * config.num_classes\n",
    "    class_total = [0] * config.num_classes\n",
    "    \n",
    "    print(\"\\n开始评估...\")\n",
    "    batch_count = 0\n",
    "    \n",
    "    # 创建 argmax 操作\n",
    "    argmax_op = ops.Argmax(output_type=ms.int32)\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(test_dataset.create_tuple_iterator()):\n",
    "        outputs = model(images)\n",
    "        predictions = argmax_op(outputs)\n",
    "        \n",
    "        # 整体统计\n",
    "        batch_correct = (predictions.asnumpy() == labels.asnumpy()).sum()\n",
    "        total_correct += batch_correct\n",
    "        total_samples += labels.shape[0]\n",
    "        \n",
    "        # 按类别统计\n",
    "        for i in range(labels.shape[0]):\n",
    "            label = labels.asnumpy()[i]\n",
    "            pred = predictions.asnumpy()[i]\n",
    "            class_total[label] += 1\n",
    "            if label == pred:\n",
    "                class_correct[label] += 1\n",
    "        \n",
    "        batch_count += 1\n",
    "        # 进度显示\n",
    "        if (batch_idx + 1) % 5 == 0:\n",
    "            current_acc = total_correct / total_samples if total_samples > 0 else 0\n",
    "            print(f\"  Batch {batch_idx+1}/{test_dataset.get_dataset_size()}, \"\n",
    "                  f\"Current Accuracy: {current_acc:.4f}\")\n",
    "    \n",
    "    # 计算最终指标\n",
    "    final_accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"Evaluation Results Summary\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total Test Samples: {total_samples}\")\n",
    "    print(f\"Correct Predictions: {total_correct}\")\n",
    "    print(f\"Overall Accuracy: {final_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nPer-Class Accuracy:\")\n",
    "    for i in range(config.num_classes):\n",
    "        if class_total[i] > 0:\n",
    "            class_acc = class_correct[i] / class_total[i]\n",
    "            print(f\"  {config.class_names[i]}: {class_acc:.4f} \"\n",
    "                  f\"({class_correct[i]}/{class_total[i]})\")\n",
    "        else:\n",
    "            print(f\"  {config.class_names[i]}: No test samples\")\n",
    "# 执行评估\n",
    "evaluate_model()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "模型评估\n",
      "============================================================\n",
      "✓ Model loaded successfully: best_flower_model.ckpt\n",
      "\n",
      "开始评估...\n",
      "  Batch 5/21, Current Accuracy: 0.8250\n",
      "  Batch 10/21, Current Accuracy: 0.8281\n",
      "  Batch 15/21, Current Accuracy: 0.7896\n",
      "  Batch 20/21, Current Accuracy: 0.7859\n",
      "\n",
      "========================================\n",
      "Evaluation Results Summary\n",
      "========================================\n",
      "Total Test Samples: 652\n",
      "Correct Predictions: 515\n",
      "Overall Accuracy: 0.7899\n",
      "\n",
      "Per-Class Accuracy:\n",
      "  daisy: 0.7907 (102/129)\n",
      "  dandelion: 0.8502 (193/227)\n",
      "  rose: 0.6264 (57/91)\n",
      "  sunflower: 0.7561 (62/82)\n",
      "  tulip: 0.8211 (101/123)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "e4162a0f-676b-453d-ae94-1033d86e44c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:40:39.058837252Z",
     "start_time": "2025-12-29T06:40:36.462983272Z"
    }
   },
   "source": [
    "def show_predictions():\n",
    "    \"\"\"显示预测示例\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"预测示例\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if test_dataset is None:\n",
    "        print(\"✗ 测试集不可用\")\n",
    "        return\n",
    "    \n",
    "    # 导入必要的函数\n",
    "    from mindspore import load_param_into_net\n",
    "    \n",
    "    # 加载模型\n",
    "    if not os.path.exists(config.model_path):\n",
    "        print(f\"✗ 模型文件不存在: {config.model_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        model.set_train(False)\n",
    "        param_dict = ms.load_checkpoint(config.model_path)\n",
    "        \n",
    "        # 检查模型参数是否匹配\n",
    "        model_params = {p.name: p for p in model.get_parameters()}\n",
    "        for name, param in param_dict.items():\n",
    "            if name in model_params:\n",
    "                model_params[name].set_data(param)\n",
    "        \n",
    "        print(f\"✓ Model loaded successfully: {config.model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Model loading failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 获取一批测试数据\n",
    "    test_iter = test_dataset.create_tuple_iterator()\n",
    "    images, labels = next(test_iter)\n",
    "    \n",
    "    # 预测\n",
    "    outputs = model(images[:10])  # 只取前10个\n",
    "    argmax_op = ops.Argmax(output_type=ms.int32)\n",
    "    predictions = argmax_op(outputs)\n",
    "    probabilities = ops.softmax(outputs, axis=1)\n",
    "    \n",
    "    # 创建可视化\n",
    "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 7))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(10):\n",
    "        # 反标准化图像显示\n",
    "        img = images[i].asnumpy().transpose(1, 2, 0)\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        true_label = labels.asnumpy()[i]\n",
    "        pred_label = predictions.asnumpy()[i]\n",
    "        confidence = probabilities.asnumpy()[i][pred_label]\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # 颜色标注\n",
    "        if true_label == pred_label:\n",
    "            color = 'green'\n",
    "            title = f'✓ {config.class_names[pred_label]}\\n({confidence:.2f})'\n",
    "        else:\n",
    "            color = 'red'\n",
    "            title = f'{config.class_names[true_label]}→{config.class_names[pred_label]}\\n({confidence:.2f})'\n",
    "        \n",
    "        axes[i].set_title(title, color=color, fontsize=10)\n",
    "        \n",
    "        # 错误预测加红框\n",
    "        if true_label != pred_label:\n",
    "            for spine in axes[i].spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(3)\n",
    "    \n",
    "    plt.suptitle('Flower Classification Examples (Green=Correct, Red=Wrong)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_examples_1.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Prediction examples saved as 'prediction_examples_2.png'\")\n",
    "\n",
    "show_predictions()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "预测示例\n",
      "============================================================\n",
      "✓ Model loaded successfully: best_flower_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(280126,79ff5f932600,python):2025-12-29-14:40:37.770.934 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_280126/3613542768.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Prediction examples saved as 'prediction_examples_1.png'\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "210e9259-301e-42cf-a214-5ca582f3bb90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:11:38.880550485Z",
     "start_time": "2025-12-29T06:11:38.860476976Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore (GPU)",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
