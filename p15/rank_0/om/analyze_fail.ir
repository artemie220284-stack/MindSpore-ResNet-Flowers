# ===============================================================================================
# The following shows the last analyze fail log message.
# ===============================================================================================

----------------------------------------------------
- Caught exception:
----------------------------------------------------
For 'ReduceSum', the second input type should be tensor or scalar, but got invalid abstract type:AbstractKeywordArg.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/op_utils.cc:264 CheckAndGetAxisValue

----------------------------------------------------
- The Traceback of Net Construct Code:
----------------------------------------------------
# 0 In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:842
        if self.add_cast_fp32:
# 1 In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:845
        loss = self._loss_fn(outputs, label)
               ^
# 2 In file /tmp/ipykernel_280126/1697004305.py:31
# 3 In file /tmp/ipykernel_280126/1697004305.py:19

# ===============================================================================================
# The following shows the IR when the function graphs evaluation fails to help locate the problem.
# You can search the last ------------------------> to the node which is evaluated failure.
# Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.ir to get more instructions.
# ===============================================================================================

# IR entry: @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163
# Total subgraphs: 437

# Total params: 155
# Params:
%para1_data : <null>
%para2_label : <null>
%para3_classifier.bias : <Ref[Tensor[Float32]], (5), ref_key=:classifier.bias>  :  has_default
%para4_backbone.conv1.weight : <Ref[Tensor[Float32]], (64, 3, 7, 7), ref_key=:backbone.conv1.weight>  :  has_default
%para5_classifier.weight : <Ref[Tensor[Float32]], (5, 2048), ref_key=:classifier.weight>  :  has_default
%para6_backbone.gn.beta : <Ref[Tensor[Float32]], (2048), ref_key=:backbone.gn.beta>  :  has_default
%para7_backbone.gn.gamma : <Ref[Tensor[Float32]], (2048), ref_key=:backbone.gn.gamma>  :  has_default
%para8_backbone.layer4.0.conv3.weight : <Ref[Tensor[Float32]], (2048, 512, 1, 1), ref_key=:backbone.layer4.0.conv3.weight>  :  has_default
%para9_backbone.layer4.1.conv3.weight : <Ref[Tensor[Float32]], (2048, 512, 1, 1), ref_key=:backbone.layer4.1.conv3.weight>  :  has_default
%para10_backbone.layer4.2.conv3.weight : <Ref[Tensor[Float32]], (2048, 512, 1, 1), ref_key=:backbone.layer4.2.conv3.weight>  :  has_default
%para11_backbone.layer3.0.conv3.weight : <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.0.conv3.weight>  :  has_default
%para12_backbone.layer3.1.conv3.weight : <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.1.conv3.weight>  :  has_default
%para13_backbone.layer3.2.conv3.weight : <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.2.conv3.weight>  :  has_default
%para14_backbone.layer3.3.conv3.weight : <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.3.conv3.weight>  :  has_default
%para15_backbone.layer3.4.conv3.weight : <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.4.conv3.weight>  :  has_default
%para16_backbone.layer3.5.conv3.weight : <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.5.conv3.weight>  :  has_default
%para17_backbone.layer2.0.conv3.weight : <Ref[Tensor[Float32]], (512, 128, 1, 1), ref_key=:backbone.layer2.0.conv3.weight>  :  has_default
%para18_backbone.layer2.1.conv3.weight : <Ref[Tensor[Float32]], (512, 128, 1, 1), ref_key=:backbone.layer2.1.conv3.weight>  :  has_default
%para19_backbone.layer2.2.conv3.weight : <Ref[Tensor[Float32]], (512, 128, 1, 1), ref_key=:backbone.layer2.2.conv3.weight>  :  has_default
%para20_backbone.layer2.3.conv3.weight : <Ref[Tensor[Float32]], (512, 128, 1, 1), ref_key=:backbone.layer2.3.conv3.weight>  :  has_default
%para21_backbone.layer4.0.conv2.weight : <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:backbone.layer4.0.conv2.weight>  :  has_default
%para22_backbone.layer4.1.conv2.weight : <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:backbone.layer4.1.conv2.weight>  :  has_default
%para23_backbone.layer4.2.conv2.weight : <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:backbone.layer4.2.conv2.weight>  :  has_default
%para24_backbone.layer1.0.conv3.weight : <Ref[Tensor[Float32]], (256, 64, 1, 1), ref_key=:backbone.layer1.0.conv3.weight>  :  has_default
%para25_backbone.layer1.1.conv3.weight : <Ref[Tensor[Float32]], (256, 64, 1, 1), ref_key=:backbone.layer1.1.conv3.weight>  :  has_default
%para26_backbone.layer1.2.conv3.weight : <Ref[Tensor[Float32]], (256, 64, 1, 1), ref_key=:backbone.layer1.2.conv3.weight>  :  has_default
%para27_backbone.layer3.0.conv2.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.0.conv2.weight>  :  has_default
%para28_backbone.layer3.1.conv2.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.1.conv2.weight>  :  has_default
%para29_backbone.layer3.2.conv2.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.2.conv2.weight>  :  has_default
%para30_backbone.layer3.3.conv2.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.3.conv2.weight>  :  has_default
%para31_backbone.layer3.4.conv2.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.4.conv2.weight>  :  has_default
%para32_backbone.layer3.5.conv2.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.5.conv2.weight>  :  has_default
%para33_backbone.layer2.0.conv2.weight : <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.0.conv2.weight>  :  has_default
%para34_backbone.layer2.1.conv2.weight : <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.1.conv2.weight>  :  has_default
%para35_backbone.layer2.2.conv2.weight : <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.2.conv2.weight>  :  has_default
%para36_backbone.layer2.3.conv2.weight : <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.3.conv2.weight>  :  has_default
%para37_backbone.layer4.0.gn3.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.0.gn3.beta>  :  has_default
%para38_backbone.layer4.0.conv1.weight : <Ref[Tensor[Float32]], (512, 1024, 1, 1), ref_key=:backbone.layer4.0.conv1.weight>  :  has_default
%para39_backbone.layer4.1.gn3.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.1.gn3.beta>  :  has_default
%para40_backbone.layer4.1.conv1.weight : <Ref[Tensor[Float32]], (512, 2048, 1, 1), ref_key=:backbone.layer4.1.conv1.weight>  :  has_default
%para41_backbone.layer4.2.gn3.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.2.gn3.beta>  :  has_default
%para42_backbone.layer4.2.conv1.weight : <Ref[Tensor[Float32]], (512, 2048, 1, 1), ref_key=:backbone.layer4.2.conv1.weight>  :  has_default
%para43_backbone.layer1.0.conv2.weight : <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:backbone.layer1.0.conv2.weight>  :  has_default
%para44_backbone.layer1.1.conv2.weight : <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:backbone.layer1.1.conv2.weight>  :  has_default
%para45_backbone.layer1.2.conv2.weight : <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:backbone.layer1.2.conv2.weight>  :  has_default
%para46_backbone.layer4.0.gn3.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.0.gn3.gamma>  :  has_default
%para47_backbone.layer4.0.gn1.beta : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer4.0.gn1.beta>  :  has_default
%para48_backbone.layer4.1.gn3.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.1.gn3.gamma>  :  has_default
%para49_backbone.layer4.1.gn1.beta : <Ref[Tensor[Float32]], (2048), ref_key=:backbone.layer4.1.gn1.beta>  :  has_default
%para50_backbone.layer4.2.gn3.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.2.gn3.gamma>  :  has_default
%para51_backbone.layer4.2.gn1.beta : <Ref[Tensor[Float32]], (2048), ref_key=:backbone.layer4.2.gn1.beta>  :  has_default
%para52_backbone.layer3.0.gn3.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.0.gn3.beta>  :  has_default
%para53_backbone.layer3.0.conv1.weight : <Ref[Tensor[Float32]], (256, 512, 1, 1), ref_key=:backbone.layer3.0.conv1.weight>  :  has_default
%para54_backbone.layer3.1.gn3.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.1.gn3.beta>  :  has_default
%para55_backbone.layer3.1.conv1.weight : <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.1.conv1.weight>  :  has_default
%para56_backbone.layer3.2.gn3.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.2.gn3.beta>  :  has_default
%para57_backbone.layer3.2.conv1.weight : <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.2.conv1.weight>  :  has_default
%para58_backbone.layer3.3.gn3.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.3.gn3.beta>  :  has_default
%para59_backbone.layer3.3.conv1.weight : <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.3.conv1.weight>  :  has_default
%para60_backbone.layer3.4.gn3.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.4.gn3.beta>  :  has_default
%para61_backbone.layer3.4.conv1.weight : <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.4.conv1.weight>  :  has_default
%para62_backbone.layer3.5.gn3.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.5.gn3.beta>  :  has_default
%para63_backbone.layer3.5.conv1.weight : <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.5.conv1.weight>  :  has_default
%para64_backbone.layer4.0.gn1.gamma : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer4.0.gn1.gamma>  :  has_default
%para65_backbone.layer4.1.gn1.gamma : <Ref[Tensor[Float32]], (2048), ref_key=:backbone.layer4.1.gn1.gamma>  :  has_default
%para66_backbone.layer4.2.gn1.gamma : <Ref[Tensor[Float32]], (2048), ref_key=:backbone.layer4.2.gn1.gamma>  :  has_default
%para67_backbone.layer3.0.gn3.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.0.gn3.gamma>  :  has_default
%para68_backbone.layer3.0.gn1.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer3.0.gn1.beta>  :  has_default
%para69_backbone.layer3.1.gn3.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.1.gn3.gamma>  :  has_default
%para70_backbone.layer3.1.gn1.beta : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.1.gn1.beta>  :  has_default
%para71_backbone.layer3.2.gn3.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.2.gn3.gamma>  :  has_default
%para72_backbone.layer3.2.gn1.beta : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.2.gn1.beta>  :  has_default
%para73_backbone.layer3.3.gn3.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.3.gn3.gamma>  :  has_default
%para74_backbone.layer3.3.gn1.beta : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.3.gn1.beta>  :  has_default
%para75_backbone.layer3.4.gn3.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.4.gn3.gamma>  :  has_default
%para76_backbone.layer3.4.gn1.beta : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.4.gn1.beta>  :  has_default
%para77_backbone.layer3.5.gn3.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.5.gn3.gamma>  :  has_default
%para78_backbone.layer3.5.gn1.beta : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.5.gn1.beta>  :  has_default
%para79_backbone.layer2.0.gn3.beta : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.0.gn3.beta>  :  has_default
%para80_backbone.layer2.0.conv1.weight : <Ref[Tensor[Float32]], (128, 256, 1, 1), ref_key=:backbone.layer2.0.conv1.weight>  :  has_default
%para81_backbone.layer2.1.gn3.beta : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.1.gn3.beta>  :  has_default
%para82_backbone.layer2.1.conv1.weight : <Ref[Tensor[Float32]], (128, 512, 1, 1), ref_key=:backbone.layer2.1.conv1.weight>  :  has_default
%para83_backbone.layer2.2.gn3.beta : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.2.gn3.beta>  :  has_default
%para84_backbone.layer2.2.conv1.weight : <Ref[Tensor[Float32]], (128, 512, 1, 1), ref_key=:backbone.layer2.2.conv1.weight>  :  has_default
%para85_backbone.layer2.3.gn3.beta : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.3.gn3.beta>  :  has_default
%para86_backbone.layer2.3.conv1.weight : <Ref[Tensor[Float32]], (128, 512, 1, 1), ref_key=:backbone.layer2.3.conv1.weight>  :  has_default
%para87_backbone.layer4.0.gn2.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.0.gn2.beta>  :  has_default
%para88_backbone.layer4.1.gn2.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.1.gn2.beta>  :  has_default
%para89_backbone.layer4.2.gn2.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.2.gn2.beta>  :  has_default
%para90_backbone.layer3.0.gn1.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer3.0.gn1.gamma>  :  has_default
%para91_backbone.layer3.1.gn1.gamma : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.1.gn1.gamma>  :  has_default
%para92_backbone.layer3.2.gn1.gamma : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.2.gn1.gamma>  :  has_default
%para93_backbone.layer3.3.gn1.gamma : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.3.gn1.gamma>  :  has_default
%para94_backbone.layer3.4.gn1.gamma : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.4.gn1.gamma>  :  has_default
%para95_backbone.layer3.5.gn1.gamma : <Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.5.gn1.gamma>  :  has_default
%para96_backbone.layer2.0.gn3.gamma : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.0.gn3.gamma>  :  has_default
%para97_backbone.layer2.0.gn1.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer2.0.gn1.beta>  :  has_default
%para98_backbone.layer2.1.gn3.gamma : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.1.gn3.gamma>  :  has_default
%para99_backbone.layer2.1.gn1.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.1.gn1.beta>  :  has_default
%para100_backbone.layer2.2.gn3.gamma : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.2.gn3.gamma>  :  has_default
%para101_backbone.layer2.2.gn1.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.2.gn1.beta>  :  has_default
%para102_backbone.layer2.3.gn3.gamma : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.3.gn3.gamma>  :  has_default
%para103_backbone.layer2.3.gn1.beta : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.3.gn1.beta>  :  has_default
%para104_backbone.layer1.0.gn3.beta : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn3.beta>  :  has_default
%para105_backbone.layer1.0.conv1.weight : <Ref[Tensor[Float32]], (64, 64, 1, 1), ref_key=:backbone.layer1.0.conv1.weight>  :  has_default
%para106_backbone.layer1.1.gn3.beta : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.1.gn3.beta>  :  has_default
%para107_backbone.layer1.1.conv1.weight : <Ref[Tensor[Float32]], (64, 256, 1, 1), ref_key=:backbone.layer1.1.conv1.weight>  :  has_default
%para108_backbone.layer1.2.gn3.beta : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.2.gn3.beta>  :  has_default
%para109_backbone.layer1.2.conv1.weight : <Ref[Tensor[Float32]], (64, 256, 1, 1), ref_key=:backbone.layer1.2.conv1.weight>  :  has_default
%para110_backbone.layer4.0.gn2.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.0.gn2.gamma>  :  has_default
%para111_backbone.layer4.0.down_sample.0.weight : <Ref[Tensor[Float32]], (2048, 1024, 1, 1), ref_key=:backbone.layer4.0.down_sample.0.weight>  :  has_default
%para112_backbone.layer4.1.gn2.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.1.gn2.gamma>  :  has_default
%para113_backbone.layer4.2.gn2.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.2.gn2.gamma>  :  has_default
%para114_backbone.layer3.0.gn2.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.0.gn2.beta>  :  has_default
%para115_backbone.layer3.1.gn2.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.1.gn2.beta>  :  has_default
%para116_backbone.layer3.2.gn2.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.2.gn2.beta>  :  has_default
%para117_backbone.layer3.3.gn2.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.3.gn2.beta>  :  has_default
%para118_backbone.layer3.4.gn2.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.4.gn2.beta>  :  has_default
%para119_backbone.layer3.5.gn2.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.5.gn2.beta>  :  has_default
%para120_backbone.layer2.0.gn1.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer2.0.gn1.gamma>  :  has_default
%para121_backbone.layer2.1.gn1.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.1.gn1.gamma>  :  has_default
%para122_backbone.layer2.2.gn1.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.2.gn1.gamma>  :  has_default
%para123_backbone.layer2.3.gn1.gamma : <Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.3.gn1.gamma>  :  has_default
%para124_backbone.layer1.0.gn3.gamma : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn3.gamma>  :  has_default
%para125_backbone.layer1.0.gn1.beta : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn1.beta>  :  has_default
%para126_backbone.layer1.1.gn3.gamma : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.1.gn3.gamma>  :  has_default
%para127_backbone.layer1.1.gn1.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer1.1.gn1.beta>  :  has_default
%para128_backbone.layer1.2.gn3.gamma : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.2.gn3.gamma>  :  has_default
%para129_backbone.layer1.2.gn1.beta : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer1.2.gn1.beta>  :  has_default
%para130_backbone.layer3.0.gn2.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.0.gn2.gamma>  :  has_default
%para131_backbone.layer3.0.down_sample.0.weight : <Ref[Tensor[Float32]], (1024, 512, 1, 1), ref_key=:backbone.layer3.0.down_sample.0.weight>  :  has_default
%para132_backbone.layer3.1.gn2.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.1.gn2.gamma>  :  has_default
%para133_backbone.layer3.2.gn2.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.2.gn2.gamma>  :  has_default
%para134_backbone.layer3.3.gn2.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.3.gn2.gamma>  :  has_default
%para135_backbone.layer3.4.gn2.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.4.gn2.gamma>  :  has_default
%para136_backbone.layer3.5.gn2.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.5.gn2.gamma>  :  has_default
%para137_backbone.layer2.0.gn2.beta : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.0.gn2.beta>  :  has_default
%para138_backbone.layer2.1.gn2.beta : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.1.gn2.beta>  :  has_default
%para139_backbone.layer2.2.gn2.beta : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.2.gn2.beta>  :  has_default
%para140_backbone.layer2.3.gn2.beta : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.3.gn2.beta>  :  has_default
%para141_backbone.layer1.0.gn1.gamma : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn1.gamma>  :  has_default
%para142_backbone.layer1.1.gn1.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer1.1.gn1.gamma>  :  has_default
%para143_backbone.layer1.2.gn1.gamma : <Ref[Tensor[Float32]], (256), ref_key=:backbone.layer1.2.gn1.gamma>  :  has_default
%para144_backbone.layer2.0.gn2.gamma : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.0.gn2.gamma>  :  has_default
%para145_backbone.layer2.0.down_sample.0.weight : <Ref[Tensor[Float32]], (512, 256, 1, 1), ref_key=:backbone.layer2.0.down_sample.0.weight>  :  has_default
%para146_backbone.layer2.1.gn2.gamma : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.1.gn2.gamma>  :  has_default
%para147_backbone.layer2.2.gn2.gamma : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.2.gn2.gamma>  :  has_default
%para148_backbone.layer2.3.gn2.gamma : <Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.3.gn2.gamma>  :  has_default
%para149_backbone.layer1.0.gn2.beta : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn2.beta>  :  has_default
%para150_backbone.layer1.1.gn2.beta : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.1.gn2.beta>  :  has_default
%para151_backbone.layer1.2.gn2.beta : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.2.gn2.beta>  :  has_default
%para152_backbone.layer1.0.gn2.gamma : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn2.gamma>  :  has_default
%para153_backbone.layer1.0.down_sample.0.weight : <Ref[Tensor[Float32]], (256, 64, 1, 1), ref_key=:backbone.layer1.0.down_sample.0.weight>  :  has_default
%para154_backbone.layer1.1.gn2.gamma : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.1.gn2.gamma>  :  has_default
%para155_backbone.layer1.2.gn2.gamma : <Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.2.gn2.gamma>  :  has_default

subgraph attr:
subgraph instance: mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163 : 0x56198fe3d200
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:840/    def construct(self, data, label):/
subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163(%para1_data, %para2_label, %para3_classifier.bias, %para4_backbone.conv1.weight, %para5_classifier.weight, %para6_backbone.gn.beta, %para7_backbone.gn.gamma, %para8_backbone.layer4.0.conv3.weight, %para9_backbone.layer4.1.conv3.weight, %para10_backbone.layer4.2.conv3.weight, %para11_backbone.layer3.0.conv3.weight, %para12_backbone.layer3.1.conv3.weight, %para13_backbone.layer3.2.conv3.weight, %para14_backbone.layer3.3.conv3.weight, %para15_backbone.layer3.4.conv3.weight, %para16_backbone.layer3.5.conv3.weight, %para17_backbone.layer2.0.conv3.weight, %para18_backbone.layer2.1.conv3.weight, %para19_backbone.layer2.2.conv3.weight, %para20_backbone.layer2.3.conv3.weight, %para21_backbone.layer4.0.conv2.weight, %para22_backbone.layer4.1.conv2.weight, %para23_backbone.layer4.2.conv2.weight, %para24_backbone.layer1.0.conv3.weight, %para25_backbone.layer1.1.conv3.weight, %para26_backbone.layer1.2.conv3.weight, %para27_backbone.layer3.0.conv2.weight, %para28_backbone.layer3.1.conv2.weight, %para29_backbone.layer3.2.conv2.weight, %para30_backbone.layer3.3.conv2.weight, %para31_backbone.layer3.4.conv2.weight, %para32_backbone.layer3.5.conv2.weight, %para33_backbone.layer2.0.conv2.weight, %para34_backbone.layer2.1.conv2.weight, %para35_backbone.layer2.2.conv2.weight, %para36_backbone.layer2.3.conv2.weight, %para37_backbone.layer4.0.gn3.beta, %para38_backbone.layer4.0.conv1.weight, %para39_backbone.layer4.1.gn3.beta, %para40_backbone.layer4.1.conv1.weight, %para41_backbone.layer4.2.gn3.beta, %para42_backbone.layer4.2.conv1.weight, %para43_backbone.layer1.0.conv2.weight, %para44_backbone.layer1.1.conv2.weight, %para45_backbone.layer1.2.conv2.weight, %para46_backbone.layer4.0.gn3.gamma, %para47_backbone.layer4.0.gn1.beta, %para48_backbone.layer4.1.gn3.gamma, %para49_backbone.layer4.1.gn1.beta, %para50_backbone.layer4.2.gn3.gamma, %para51_backbone.layer4.2.gn1.beta, %para52_backbone.layer3.0.gn3.beta, %para53_backbone.layer3.0.conv1.weight, %para54_backbone.layer3.1.gn3.beta, %para55_backbone.layer3.1.conv1.weight, %para56_backbone.layer3.2.gn3.beta, %para57_backbone.layer3.2.conv1.weight, %para58_backbone.layer3.3.gn3.beta, %para59_backbone.layer3.3.conv1.weight, %para60_backbone.layer3.4.gn3.beta, %para61_backbone.layer3.4.conv1.weight, %para62_backbone.layer3.5.gn3.beta, %para63_backbone.layer3.5.conv1.weight, %para64_backbone.layer4.0.gn1.gamma, %para65_backbone.layer4.1.gn1.gamma, %para66_backbone.layer4.2.gn1.gamma, %para67_backbone.layer3.0.gn3.gamma, %para68_backbone.layer3.0.gn1.beta, %para69_backbone.layer3.1.gn3.gamma, %para70_backbone.layer3.1.gn1.beta, %para71_backbone.layer3.2.gn3.gamma, %para72_backbone.layer3.2.gn1.beta, %para73_backbone.layer3.3.gn3.gamma, %para74_backbone.layer3.3.gn1.beta, %para75_backbone.layer3.4.gn3.gamma, %para76_backbone.layer3.4.gn1.beta, %para77_backbone.layer3.5.gn3.gamma, %para78_backbone.layer3.5.gn1.beta, %para79_backbone.layer2.0.gn3.beta, %para80_backbone.layer2.0.conv1.weight, %para81_backbone.layer2.1.gn3.beta, %para82_backbone.layer2.1.conv1.weight, %para83_backbone.layer2.2.gn3.beta, %para84_backbone.layer2.2.conv1.weight, %para85_backbone.layer2.3.gn3.beta, %para86_backbone.layer2.3.conv1.weight, %para87_backbone.layer4.0.gn2.beta, %para88_backbone.layer4.1.gn2.beta, %para89_backbone.layer4.2.gn2.beta, %para90_backbone.layer3.0.gn1.gamma, %para91_backbone.layer3.1.gn1.gamma, %para92_backbone.layer3.2.gn1.gamma, %para93_backbone.layer3.3.gn1.gamma, %para94_backbone.layer3.4.gn1.gamma, %para95_backbone.layer3.5.gn1.gamma, %para96_backbone.layer2.0.gn3.gamma, %para97_backbone.layer2.0.gn1.beta, %para98_backbone.layer2.1.gn3.gamma, %para99_backbone.layer2.1.gn1.beta, %para100_backbone.layer2.2.gn3.gamma, %para101_backbone.layer2.2.gn1.beta, %para102_backbone.layer2.3.gn3.gamma, %para103_backbone.layer2.3.gn1.beta, %para104_backbone.layer1.0.gn3.beta, %para105_backbone.layer1.0.conv1.weight, %para106_backbone.layer1.1.gn3.beta, %para107_backbone.layer1.1.conv1.weight, %para108_backbone.layer1.2.gn3.beta, %para109_backbone.layer1.2.conv1.weight, %para110_backbone.layer4.0.gn2.gamma, %para111_backbone.layer4.0.down_sample.0.weight, %para112_backbone.layer4.1.gn2.gamma, %para113_backbone.layer4.2.gn2.gamma, %para114_backbone.layer3.0.gn2.beta, %para115_backbone.layer3.1.gn2.beta, %para116_backbone.layer3.2.gn2.beta, %para117_backbone.layer3.3.gn2.beta, %para118_backbone.layer3.4.gn2.beta, %para119_backbone.layer3.5.gn2.beta, %para120_backbone.layer2.0.gn1.gamma, %para121_backbone.layer2.1.gn1.gamma, %para122_backbone.layer2.2.gn1.gamma, %para123_backbone.layer2.3.gn1.gamma, %para124_backbone.layer1.0.gn3.gamma, %para125_backbone.layer1.0.gn1.beta, %para126_backbone.layer1.1.gn3.gamma, %para127_backbone.layer1.1.gn1.beta, %para128_backbone.layer1.2.gn3.gamma, %para129_backbone.layer1.2.gn1.beta, %para130_backbone.layer3.0.gn2.gamma, %para131_backbone.layer3.0.down_sample.0.weight, %para132_backbone.layer3.1.gn2.gamma, %para133_backbone.layer3.2.gn2.gamma, %para134_backbone.layer3.3.gn2.gamma, %para135_backbone.layer3.4.gn2.gamma, %para136_backbone.layer3.5.gn2.gamma, %para137_backbone.layer2.0.gn2.beta, %para138_backbone.layer2.1.gn2.beta, %para139_backbone.layer2.2.gn2.beta, %para140_backbone.layer2.3.gn2.beta, %para141_backbone.layer1.0.gn1.gamma, %para142_backbone.layer1.1.gn1.gamma, %para143_backbone.layer1.2.gn1.gamma, %para144_backbone.layer2.0.gn2.gamma, %para145_backbone.layer2.0.down_sample.0.weight, %para146_backbone.layer2.1.gn2.gamma, %para147_backbone.layer2.2.gn2.gamma, %para148_backbone.layer2.3.gn2.gamma, %para149_backbone.layer1.0.gn2.beta, %para150_backbone.layer1.1.gn2.beta, %para151_backbone.layer1.2.gn2.beta, %para152_backbone.layer1.0.gn2.gamma, %para153_backbone.layer1.0.down_sample.0.weight, %para154_backbone.layer1.1.gn2.gamma, %para155_backbone.layer1.2.gn2.gamma) {

#------------------------> 0
  %1(CNode_4178) = call @✗mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4170()
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:842/        if self.add_cast_fp32:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:842/        if self.add_cast_fp32:/
}
# Order:
#   1: @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163:outputs{[0]: ValueNode<FuncGraph> __main___fix_bit_model_simple__locals__FixedBitModel_construct_4179, [1]: param_data}
#   2: @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163:CNode_4178{[0]: ValueNode<FuncGraph> ✗mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4170}
#   3: @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163:CNode_4180{[0]: ValueNode<Primitive> Return, [1]: CNode_4178}


subgraph attr:
subgraph instance: ✗mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4170 : 0x56198bc71800
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:840/    def construct(self, data, label):/
subgraph @✗mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4170 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163]() {

#------------------------> 1
  %1(CNode_4181) = call @↓mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4171()
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:842/        if self.add_cast_fp32:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:842/        if self.add_cast_fp32:/
}
# Order:
#   1: @✗mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4170:CNode_4181{[0]: ValueNode<FuncGraph> ↓mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4171}
#   2: @✗mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4170:CNode_4182{[0]: ValueNode<Primitive> Return, [1]: CNode_4181}


subgraph attr:
subgraph instance: ↓mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4171 : 0x561a21fc6bd0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:840/    def construct(self, data, label):/
subgraph @↓mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4171 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163]() {
  %1(outputs) = $(mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163):call @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179(%para1_data)
      : (<Tensor[Float32], (32, 3, 224, 224)>) -> (<Tensor[Float32], (32, 5)>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:841/        outputs = self._network(data)/

#------------------------> 2
  %2(loss) = call @__main___FocalLoss_construct_4172(%1, %para2_label)
      : (<Tensor[Float32], (32, 5)>, <Tensor[Int32], (32)>) -> (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:845/        loss = self._loss_fn(outputs, label)/
  %3(CNode_4183) = S_Prim_MakeTuple(%2, %1, %para2_label)
      : (<null>, <Tensor[Float32], (32, 5)>, <Tensor[Int32], (32)>) -> (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:846/        return loss, outputs, label/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:846/        return loss, outputs, label/
}
# Order:
#   1: @↓mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4171:loss{[0]: ValueNode<FuncGraph> __main___FocalLoss_construct_4172, [1]: outputs, [2]: param_label}
#   2: @↓mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4171:CNode_4183{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: loss, [2]: outputs, [3]: param_label}
#   3: @↓mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4171:CNode_4184{[0]: ValueNode<Primitive> Return, [1]: CNode_4183}


subgraph attr:
subgraph instance: __main___FocalLoss_construct_4172 : 0x561a21f91630
# In file /tmp/ipykernel_280126/1697004305.py:11/
subgraph @__main___FocalLoss_construct_4172(%para156_inputs, %para157_targets) {
  %1(CNode_4185) = S_Prim_is_not(None, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:31/
  %2(CNode_4186) = Cond(%1, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:31/
  %3(CNode_4187) = Switch(%2, @✓__main___FocalLoss_construct_4188, @✗__main___FocalLoss_construct_4173)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:31/

#------------------------> 3
  %4(CNode_4189) = %3()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:31/
  %5(CNode_4191) = call @↓__main___FocalLoss_construct_4190(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:845/        loss = self._loss_fn(outputs, label)/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:31/
}
# Order:
#   1: @__main___FocalLoss_construct_4172:probs{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_Softmax_construct_4192, [1]: param_inputs}
#   2: @__main___FocalLoss_construct_4172:targets_onehot{[0]: ValueNode<FuncGraph> mindspore_nn_layer_basic_OneHot_construct_4193, [1]: param_targets}
#   3: @__main___FocalLoss_construct_4172:CNode_4194{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: probs, [2]: targets_onehot}
#   4: @__main___FocalLoss_construct_4172:CNode_4195{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4194}
#   5: @__main___FocalLoss_construct_4172:CNode_4196{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> axis}
#   6: @__main___FocalLoss_construct_4172:CNode_4197{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1}
#   7: @__main___FocalLoss_construct_4172:CNode_4198{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_4196, [2]: CNode_4197}
#   8: @__main___FocalLoss_construct_4172:class_probs{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.4199, [1]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [2]: CNode_4195, [3]: CNode_4198}
#   9: @__main___FocalLoss_construct_4172:CNode_4200{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: ValueNode<Int64Imm> 1, [2]: class_probs}
#  10: @__main___FocalLoss_construct_4172:modulating_factor{[0]: ValueNode<FuncGraph> pow_4201, [1]: CNode_4200, [2]: ValueNode<FP32Imm> 2}
#  11: @__main___FocalLoss_construct_4172:CNode_4202{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: class_probs, [2]: ValueNode<FP32Imm> 1e-08}
#  12: @__main___FocalLoss_construct_4172:CNode_4203{[0]: ValueNode<FuncGraph> log_4204, [1]: CNode_4202}
#  13: @__main___FocalLoss_construct_4172:ce_loss{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: CNode_4203}
#  14: @__main___FocalLoss_construct_4172:focal_loss{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: modulating_factor, [2]: ce_loss}
#  15: @__main___FocalLoss_construct_4172:CNode_4185{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  16: @__main___FocalLoss_construct_4172:CNode_4186{[0]: ValueNode<Primitive> Cond, [1]: CNode_4185, [2]: ValueNode<BoolImm> false}
#  17: @__main___FocalLoss_construct_4172:CNode_4187{[0]: ValueNode<Primitive> Switch, [1]: CNode_4186, [2]: ValueNode<FuncGraph> ✓__main___FocalLoss_construct_4188, [3]: ValueNode<FuncGraph> ✗__main___FocalLoss_construct_4173}
#  18: @__main___FocalLoss_construct_4172:CNode_4189{[0]: CNode_4187}
#  19: @__main___FocalLoss_construct_4172:CNode_4191{[0]: ValueNode<FuncGraph> ↓__main___FocalLoss_construct_4190, [1]: CNode_4189}
#  20: @__main___FocalLoss_construct_4172:CNode_4205{[0]: ValueNode<Primitive> Return, [1]: CNode_4191}


subgraph attr:
subgraph instance: ✗__main___FocalLoss_construct_4173 : 0x561a21cf8480
# In file /tmp/ipykernel_280126/1697004305.py:11/
subgraph @✗__main___FocalLoss_construct_4173 parent: [subgraph @__main___FocalLoss_construct_4172]() {
  %1(probs) = $(__main___FocalLoss_construct_4172):call @mindspore_nn_layer_activation_Softmax_construct_4192(%para156_inputs)
      : (<Tensor[Float32], (32, 5)>) -> (<Tensor[Float32], (32, 5)>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:13/
  %2(targets_onehot) = $(__main___FocalLoss_construct_4172):call @mindspore_nn_layer_basic_OneHot_construct_4193(%para157_targets)
      : (<Tensor[Int32], (32)>) -> (<Tensor[Float32], (32, 5)>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:16/
  %3(CNode_4194) = $(__main___FocalLoss_construct_4172):S_Prim_mul(%1, %2)
      : (<Tensor[Float32], (32, 5)>, <Tensor[Float32], (32, 5)>) -> (<Tensor[Float32], (32, 5)>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %4(CNode_4195) = $(__main___FocalLoss_construct_4172):S_Prim_MakeTuple(%3)
      : (<Tensor[Float32], (32, 5)>) -> (<Tuple[Tensor[Float32]], TupleShape((32, 5))>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %5(CNode_4196) = $(__main___FocalLoss_construct_4172):S_Prim_MakeTuple("axis")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %6(CNode_4197) = $(__main___FocalLoss_construct_4172):S_Prim_MakeTuple(I64(1))
      : (<Int64, NoShape>) -> (<Tuple[Int64], TupleShape(NoShape)>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %7(CNode_4198) = $(__main___FocalLoss_construct_4172):S_Prim_make_dict(%5, %6)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Int64], TupleShape(NoShape)>) -> (<Dictionary[[axis,],[Int64]], NoShape>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/

#------------------------> 4
  %8(class_probs) = $(__main___FocalLoss_construct_4172):UnpackCall_unpack_call(S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(0), input_names: ["input_x", "axis"], skip_mode: Bool(0)], %4, %7)
      : (<Func, NoShape>, <Tuple[Tensor[Float32]], TupleShape((32, 5))>, <Dictionary[[axis,],[Int64]], NoShape>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %9(CNode_4200) = $(__main___FocalLoss_construct_4172):S_Prim_sub(I64(1), %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:22/
  %10(modulating_factor) = $(__main___FocalLoss_construct_4172):call @pow_4201(%9, F32(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:22/
  %11(CNode_4202) = $(__main___FocalLoss_construct_4172):S_Prim_add(%8, F32(1e-08))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:25/
  %12(CNode_4203) = $(__main___FocalLoss_construct_4172):call @log_4204(%11)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:25/
  %13(ce_loss) = $(__main___FocalLoss_construct_4172):S_Prim_negative(%12)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:25/
  %14(focal_loss) = $(__main___FocalLoss_construct_4172):S_Prim_mul(%10, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:28/
  Return(%14)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:31/
}
# Order:
#   1: @✗__main___FocalLoss_construct_4173:CNode_4206{[0]: ValueNode<Primitive> Return, [1]: focal_loss}


subgraph attr:
core : 1
subgraph instance: UnpackCall_4174 : 0x561a17f326a0
# In file /tmp/ipykernel_280126/1697004305.py:19/
subgraph @UnpackCall_4174(%para158_, %para159_, %para160_) {
  %1(class_probs) = TupleGetItem(%para159_4176, I64(0))
      : (<Tuple[Tensor[Float32]], TupleShape((32, 5))>, <Int64, NoShape>) -> (<Tensor[Float32], (32, 5)>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %2(class_probs) = dict_getitem(%para160_4177, "axis")
      : (<Dictionary[[axis,],[Int64]], NoShape>, <String, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %3(class_probs) = make_keyword_arg("axis", %2)
      : (<String, NoShape>, <Int64, NoShape>) -> (<Keyword[key : axis, value : Int64], NoShape>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/

#------------------------> 5
  %4(class_probs) = %para158_4175(%1, %3)
      : (<Tensor[Float32], (32, 5)>, <Keyword[key : axis, value : Int64], NoShape>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  Return(%4)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
}
# Order:
#   1: @UnpackCall_4174:class_probs{[0]: param_4175, [1]: class_probs, [2]: class_probs}
#   2: @UnpackCall_4174:class_probs{[0]: ValueNode<Primitive> Return, [1]: class_probs}


# ===============================================================================================
# The total of function graphs in evaluation stack: 6/7 (Ignored 1 internal frames).
# ===============================================================================================


# ===============================================================================================
# The rest function graphs are the following:
# ===============================================================================================
subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: __main___fix_bit_model_simple__locals__FixedBitModel_construct_4179 : 0x561a2120d860
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para161_x) {
  %1(x) = call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  %2(CNode_4208) = getattr(%1, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:39/
  %3(CNode_4209) = S_Prim_inner_len(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:39/
  %4(CNode_4210) = S_Prim_equal(%3, I64(4))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:39/
  %5(CNode_4211) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:39/
  %6(CNode_4212) = Switch(%5, @✓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4213, @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:39/
  %7(CNode_4215) = %6()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:39/
  %8(CNode_4217) = call @↓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4216(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:841/        outputs = self._network(data)/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:39/
}
# Order:
#   1: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:x{[0]: ValueNode<FuncGraph> mindcv_models_bit_BiT_ResNet_construct_4207, [1]: param_x}
#   2: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:CNode_4208{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> shape}
#   3: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:CNode_4209{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_4208}
#   4: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:CNode_4210{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_4209, [2]: ValueNode<Int64Imm> 4}
#   5: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:CNode_4211{[0]: ValueNode<Primitive> Cond, [1]: CNode_4210, [2]: ValueNode<BoolImm> false}
#   6: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:CNode_4212{[0]: ValueNode<Primitive> Switch, [1]: CNode_4211, [2]: ValueNode<FuncGraph> ✓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4213, [3]: ValueNode<FuncGraph> ✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214}
#   7: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:CNode_4215{[0]: CNode_4212}
#   8: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:CNode_4217{[0]: ValueNode<FuncGraph> ↓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4216, [1]: CNode_4215}
#   9: @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179:CNode_4218{[0]: ValueNode<Primitive> Return, [1]: CNode_4217}


subgraph attr:
after_block : 1
training : 0
ge_sync_data : 0
subgraph instance: ↓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4216 : 0x561a1dd67fb0
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @↓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4216 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para162_) {
  %1(x) = call @mindspore_nn_layer_basic_Dense_construct_4219(%para162_фx)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:53/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:54/
}
# Order:
#   1: @↓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4216:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_basic_Dense_construct_4219, [1]: param_фx}
#   2: @↓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4216:CNode_4220{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: ✓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4213 : 0x561a218f6f10
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @✓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4213 parent: [subgraph @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179]() {
  %1(x) = $(__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179):call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  %2(CNode_4221) = S_Prim_MakeTuple(I64(2), I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:41/
  %3(x) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(0), input_names: ["input_x", "axis"]](%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:41/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:41/
}
# Order:
#   1: @✓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4213:CNode_4221{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 2, [2]: ValueNode<Int64Imm> 3}
#   2: @✓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4213:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: CNode_4221}
#   3: @✓__main___fix_bit_model_simple__locals__FixedBitModel_construct_4213:CNode_4222{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: ✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214 : 0x561a212ef100
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214 parent: [subgraph @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179]() {
  %1(x) = $(__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179):call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  %2(CNode_4223) = getattr(%1, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:42/
  %3(CNode_4224) = S_Prim_inner_len(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:42/
  %4(CNode_4225) = S_Prim_equal(%3, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:42/
  %5(CNode_4226) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:42/
  %6(CNode_4227) = Switch(%5, @✓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4228, @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:42/
  %7(CNode_4230) = %6()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:42/
  %8(CNode_4232) = call @↓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4231(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:841/        outputs = self._network(data)/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:42/
}
# Order:
#   1: @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214:CNode_4223{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> shape}
#   2: @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214:CNode_4224{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_4223}
#   3: @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214:CNode_4225{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_4224, [2]: ValueNode<Int64Imm> 2}
#   4: @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214:CNode_4226{[0]: ValueNode<Primitive> Cond, [1]: CNode_4225, [2]: ValueNode<BoolImm> false}
#   5: @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214:CNode_4227{[0]: ValueNode<Primitive> Switch, [1]: CNode_4226, [2]: ValueNode<FuncGraph> ✓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4228, [3]: ValueNode<FuncGraph> 2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229}
#   6: @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214:CNode_4230{[0]: CNode_4227}
#   7: @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214:CNode_4232{[0]: ValueNode<FuncGraph> ↓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4231, [1]: CNode_4230}
#   8: @✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4214:CNode_4233{[0]: ValueNode<Primitive> Return, [1]: CNode_4232}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_BiT_ResNet_construct_4207 : 0x561a1d749960
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:262/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_BiT_ResNet_construct_4207 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para163_x) {
  %1(x) = call @root_4234(%para163_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:263/        x = self.root(x)/
  %2(x) = call @forward_features_4235(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:264/        x = self.forward_features(x)/
  %3(x) = call @forward_head_4236(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:265/        x = self.forward_head(x)/
  %4(CNode_4237) = getattr(%3, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  %5(CNode_4238) = S_Prim_negative(I64(2))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  %6(CNode_4239) = S_Prim_make_slice(%5, None, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  %7(CNode_4240) = S_Prim_getitem(%4, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  %8(CNode_4241) = S_Prim_MakeTuple(I64(1), I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  %9(CNode_4242) = S_Prim_equal(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  %10(CNode_4243) = Cond(%9, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  %11(assert_mindcv_models_bit_BiT_ResNet_construct) = Switch(%10, @assert_mindcv_models_bit_BiT_ResNet_construct_4244, @assert_mindcv_models_bit_BiT_ResNet_construct_4245)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  %12(assert_mindcv_models_bit_BiT_ResNet_construct) = %11()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  Return(%12)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
}
# Order:
#   1: @mindcv_models_bit_BiT_ResNet_construct_4207:x{[0]: ValueNode<FuncGraph> root_4234, [1]: param_x}
#   2: @mindcv_models_bit_BiT_ResNet_construct_4207:x{[0]: ValueNode<FuncGraph> forward_features_4235, [1]: x}
#   3: @mindcv_models_bit_BiT_ResNet_construct_4207:x{[0]: ValueNode<FuncGraph> forward_head_4236, [1]: x}
#   4: @mindcv_models_bit_BiT_ResNet_construct_4207:CNode_4237{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> shape}
#   5: @mindcv_models_bit_BiT_ResNet_construct_4207:CNode_4238{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 2}
#   6: @mindcv_models_bit_BiT_ResNet_construct_4207:CNode_4239{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: CNode_4238, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   7: @mindcv_models_bit_BiT_ResNet_construct_4207:CNode_4240{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4237, [2]: CNode_4239}
#   8: @mindcv_models_bit_BiT_ResNet_construct_4207:CNode_4241{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 1}
#   9: @mindcv_models_bit_BiT_ResNet_construct_4207:CNode_4242{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_4240, [2]: CNode_4241}
#  10: @mindcv_models_bit_BiT_ResNet_construct_4207:CNode_4243{[0]: ValueNode<Primitive> Cond, [1]: CNode_4242, [2]: ValueNode<BoolImm> false}
#  11: @mindcv_models_bit_BiT_ResNet_construct_4207:assert_mindcv_models_bit_BiT_ResNet_construct{[0]: ValueNode<Primitive> Switch, [1]: CNode_4243, [2]: ValueNode<FuncGraph> assert_mindcv_models_bit_BiT_ResNet_construct_4244, [3]: ValueNode<FuncGraph> assert_mindcv_models_bit_BiT_ResNet_construct_4245}
#  12: @mindcv_models_bit_BiT_ResNet_construct_4207:assert_mindcv_models_bit_BiT_ResNet_construct{[0]: assert_mindcv_models_bit_BiT_ResNet_construct}
#  13: @mindcv_models_bit_BiT_ResNet_construct_4207:assert_mindcv_models_bit_BiT_ResNet_construct{[0]: ValueNode<Primitive> Return, [1]: assert_mindcv_models_bit_BiT_ResNet_construct}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_basic_Dense_construct_4219 : 0x561a1f05ba10
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @mindspore_nn_layer_basic_Dense_construct_4219 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para164_x) {
  %1(x_shape) = S_Prim_Shape(%para164_x)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623/        x_shape = self.shape_op(x)/
  %2(CNode_4246) = S_Prim_check_dense_input_shape[constexpr_prim: Bool(1)](%1, "Dense")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:624/        check_dense_input_shape(x_shape, self.cls_name)/
  %3(CNode_4247) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
  %4(CNode_4248) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %5(CNode_4249) = S_Prim_not_equal(%4, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %6(CNode_4250) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %7(CNode_4251) = Switch(%6, @✓mindspore_nn_layer_basic_Dense_construct_4252, @✗mindspore_nn_layer_basic_Dense_construct_4253)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %8(CNode_4254) = %7()
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %9(CNode_4256) = call @↓mindspore_nn_layer_basic_Dense_construct_4255(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:53/
  %10(CNode_4257) = Depend[side_effect_propagate: I64(1)](%9, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:53/
  Return(%10)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
}
# Order:
#   1: @mindspore_nn_layer_basic_Dense_construct_4219:x_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4246{[0]: ValueNode<DoSignaturePrimitive> S_Prim_check_dense_input_shape, [1]: x_shape, [2]: ValueNode<StringImm> Dense}
#   3: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4248{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: x_shape}
#   4: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4249{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_4248, [2]: ValueNode<Int64Imm> 2}
#   5: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4250{[0]: ValueNode<Primitive> Cond, [1]: CNode_4249, [2]: ValueNode<BoolImm> false}
#   6: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4251{[0]: ValueNode<Primitive> Switch, [1]: CNode_4250, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_basic_Dense_construct_4252, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_basic_Dense_construct_4253}
#   7: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4254{[0]: CNode_4251}
#   8: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4256{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_basic_Dense_construct_4255, [1]: CNode_4254}
#   9: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4257{[0]: ValueNode<Primitive> Depend, [1]: CNode_4256, [2]: CNode_4247}
#  10: @mindspore_nn_layer_basic_Dense_construct_4219:CNode_4258{[0]: ValueNode<Primitive> Return, [1]: CNode_4257}


subgraph attr:
after_block : 1
training : 0
ge_sync_data : 0
subgraph instance: ↓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4231 : 0x5619939b6760
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @↓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4231(%para165_) {
  Return(%para165_фx)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:42/
}
# Order:
#   1: @↓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4231:CNode_4259{[0]: ValueNode<Primitive> Return, [1]: param_фx}


subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: ✓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4228 : 0x561a2131e090
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @✓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4228 parent: [subgraph @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179]() {
  %1(x) = $(__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179):call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:44/
}
# Order:
#   1: @✓✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4228:CNode_4260{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: 2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229 : 0x56198fe215a0
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229 parent: [subgraph @__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179]() {
  %1(x) = $(__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179):call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  %2(CNode_4261) = getattr(%1, "reshape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %3(CNode_4262) = getattr(%1, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %4(CNode_4263) = S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %5(CNode_4264) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %6(x) = %2(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %7(CNode_4265) = getattr(%6, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:48/
  %8(CNode_4266) = S_Prim_getitem(%7, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:48/
  %9(CNode_4267) = S_Prim_not_equal(%8, I64(2048))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:48/
  %10(CNode_4268) = Cond(%9, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:48/
  %11(CNode_4269) = Switch(%10, @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270, @3✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4271)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:48/
  %12(CNode_4272) = %11()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:48/
  %13(CNode_4274) = call @↓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4273(%12)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:841/        outputs = self._network(data)/
  Return(%13)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:48/
}
# Order:
#   1: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4261{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> reshape}
#   2: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4262{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> shape}
#   3: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4263{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4262, [2]: ValueNode<Int64Imm> 0}
#   4: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4264{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   5: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:x{[0]: CNode_4261, [1]: CNode_4263, [2]: CNode_4264}
#   6: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4265{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> shape}
#   7: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4266{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4265, [2]: ValueNode<Int64Imm> 1}
#   8: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4267{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_4266, [2]: ValueNode<Int64Imm> 2048}
#   9: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4268{[0]: ValueNode<Primitive> Cond, [1]: CNode_4267, [2]: ValueNode<BoolImm> false}
#  10: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4269{[0]: ValueNode<Primitive> Switch, [1]: CNode_4268, [2]: ValueNode<FuncGraph> ✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270, [3]: ValueNode<FuncGraph> 3✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4271}
#  11: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4272{[0]: CNode_4269}
#  12: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4274{[0]: ValueNode<FuncGraph> ↓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4273, [1]: CNode_4272}
#  13: @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229:CNode_4275{[0]: ValueNode<Primitive> Return, [1]: CNode_4274}


subgraph attr:
training : 0
subgraph instance: assert_mindcv_models_bit_BiT_ResNet_construct_4244 : 0x561990020f90
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
subgraph @assert_mindcv_models_bit_BiT_ResNet_construct_4244 parent: [subgraph @mindcv_models_bit_BiT_ResNet_construct_4207]() {
  %1(assert_mindcv_models_bit_BiT_ResNet_construct) = call @assert_mindcv_models_bit_BiT_ResNet_construct_4276()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
}
# Order:
#   1: @assert_mindcv_models_bit_BiT_ResNet_construct_4244:assert_mindcv_models_bit_BiT_ResNet_construct{[0]: ValueNode<FuncGraph> assert_mindcv_models_bit_BiT_ResNet_construct_4276}
#   2: @assert_mindcv_models_bit_BiT_ResNet_construct_4244:assert_mindcv_models_bit_BiT_ResNet_construct{[0]: ValueNode<Primitive> Return, [1]: assert_mindcv_models_bit_BiT_ResNet_construct}


subgraph attr:
training : 0
subgraph instance: assert_mindcv_models_bit_BiT_ResNet_construct_4245 : 0x561a1ccfbd50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
subgraph @assert_mindcv_models_bit_BiT_ResNet_construct_4245() {
  %1(assert_mindcv_models_bit_BiT_ResNet_construct) = raise[side_effect_io: Bool(1)]("AssertionError", "None")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
}
# Order:
#   1: @assert_mindcv_models_bit_BiT_ResNet_construct_4245:assert_mindcv_models_bit_BiT_ResNet_construct{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> AssertionError, [2]: ValueNode<StringImm> None}
#   2: @assert_mindcv_models_bit_BiT_ResNet_construct_4245:assert_mindcv_models_bit_BiT_ResNet_construct{[0]: ValueNode<Primitive> Return, [1]: assert_mindcv_models_bit_BiT_ResNet_construct}


subgraph attr:
training : 0
subgraph instance: forward_head_4236 : 0x561a1da86420
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:255/    def forward_head(self, x: Tensor) -> Tensor:/
subgraph @forward_head_4236 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para166_x) {
  %1(x) = call @mindspore_nn_layer_normalization_GroupNorm_construct_4277(%para166_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:256/        x = self.gn(x)/
  %2(x) = call @mindspore_nn_layer_activation_ReLU_construct_4278(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:257/        x = self.relu(x)/
  %3(x) = call @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:258/        x = self.pool(x)/
  %4(x) = call @mindspore_nn_layer_basic_Identity_construct_4280(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:259/        x = self.classifier(x)/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:260/        return x/
}
# Order:
#   1: @forward_head_4236:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4277, [1]: param_x}
#   2: @forward_head_4236:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4278, [1]: x}
#   3: @forward_head_4236:x{[0]: ValueNode<FuncGraph> mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279, [1]: x}
#   4: @forward_head_4236:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_basic_Identity_construct_4280, [1]: x}
#   5: @forward_head_4236:CNode_4281{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
subgraph instance: forward_features_4235 : 0x561a1d82bbd0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:247/    def forward_features(self, x: Tensor) -> Tensor:/
subgraph @forward_features_4235 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para167_x) {
  %1(x) = call @mindspore_nn_layer_container_SequentialCell_construct_4282(%para167_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:249/        x = self.layer1(x)/
  %2(x) = call @mindspore_nn_layer_container_SequentialCell_construct_4283(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:250/        x = self.layer2(x)/
  %3(x) = call @mindspore_nn_layer_container_SequentialCell_construct_4284(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:251/        x = self.layer3(x)/
  %4(x) = call @mindspore_nn_layer_container_SequentialCell_construct_4285(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:252/        x = self.layer4(x)/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:253/        return x/
}
# Order:
#   1: @forward_features_4235:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4282, [1]: param_x}
#   2: @forward_features_4235:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4283, [1]: x}
#   3: @forward_features_4235:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4284, [1]: x}
#   4: @forward_features_4235:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4285, [1]: x}
#   5: @forward_features_4235:CNode_4286{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
subgraph instance: root_4234 : 0x561a1d5ac200
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:241/    def root(self, x: Tensor) -> Tensor:/
subgraph @root_4234 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para168_x) {
  %1(x) = call @mindcv_models_bit_StdConv2d_construct_4287(%para168_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:242/        x = self.conv1(x)/
  %2(x) = call @mindspore_nn_layer_padding_ConstantPad2d_construct_4288(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:243/        x = self.pad(x)/
  %3(x) = call @mindspore_nn_layer_pooling_MaxPool2d_construct_4289(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:244/        x = self.max_pool(x)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:245/        return x/
}
# Order:
#   1: @root_4234:x{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4287, [1]: param_x}
#   2: @root_4234:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_padding_ConstantPad2d_construct_4288, [1]: x}
#   3: @root_4234:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_pooling_MaxPool2d_construct_4289, [1]: x}
#   4: @root_4234:CNode_4290{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
after_block : 1
subgraph instance: ↓__main___FocalLoss_construct_4190 : 0x561a21bcd780
# In file /tmp/ipykernel_280126/1697004305.py:11/
subgraph @↓__main___FocalLoss_construct_4190(%para169_) {
  %1(CNode_4291) = S_Prim_equal("mean", "mean")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:36/
  %2(CNode_4292) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:36/
  %3(CNode_4293) = Switch(%2, @✓↓__main___FocalLoss_construct_4294, @✗↓__main___FocalLoss_construct_4295)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:36/
  %4(CNode_4296) = %3()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:36/
  Return(%4)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:36/
}
# Order:
#   1: @↓__main___FocalLoss_construct_4190:CNode_4291{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: ValueNode<StringImm> mean, [2]: ValueNode<StringImm> mean}
#   2: @↓__main___FocalLoss_construct_4190:CNode_4292{[0]: ValueNode<Primitive> Cond, [1]: CNode_4291, [2]: ValueNode<BoolImm> false}
#   3: @↓__main___FocalLoss_construct_4190:CNode_4293{[0]: ValueNode<Primitive> Switch, [1]: CNode_4292, [2]: ValueNode<FuncGraph> ✓↓__main___FocalLoss_construct_4294, [3]: ValueNode<FuncGraph> ✗↓__main___FocalLoss_construct_4295}
#   4: @↓__main___FocalLoss_construct_4190:CNode_4296{[0]: CNode_4293}
#   5: @↓__main___FocalLoss_construct_4190:CNode_4297{[0]: ValueNode<Primitive> Return, [1]: CNode_4296}


subgraph attr:
subgraph instance: ✓__main___FocalLoss_construct_4188 : 0x561986c384e0
# In file /tmp/ipykernel_280126/1697004305.py:11/
subgraph @✓__main___FocalLoss_construct_4188 parent: [subgraph @__main___FocalLoss_construct_4172]() {
  %1(alpha_factor) = call @gather_4298(None, %para157_targets, I64(0))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:32/
  %2(probs) = $(__main___FocalLoss_construct_4172):call @mindspore_nn_layer_activation_Softmax_construct_4192(%para156_inputs)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:13/
  %3(targets_onehot) = $(__main___FocalLoss_construct_4172):call @mindspore_nn_layer_basic_OneHot_construct_4193(%para157_targets)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:16/
  %4(CNode_4194) = $(__main___FocalLoss_construct_4172):S_Prim_mul(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %5(CNode_4195) = $(__main___FocalLoss_construct_4172):S_Prim_MakeTuple(%4)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %6(CNode_4196) = $(__main___FocalLoss_construct_4172):S_Prim_MakeTuple("axis")
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %7(CNode_4197) = $(__main___FocalLoss_construct_4172):S_Prim_MakeTuple(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %8(CNode_4198) = $(__main___FocalLoss_construct_4172):S_Prim_make_dict(%6, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %9(class_probs) = $(__main___FocalLoss_construct_4172):UnpackCall_unpack_call(S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(0), input_names: ["input_x", "axis"], skip_mode: Bool(0)], %5, %8)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:19/
  %10(CNode_4200) = $(__main___FocalLoss_construct_4172):S_Prim_sub(I64(1), %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:22/
  %11(modulating_factor) = $(__main___FocalLoss_construct_4172):call @pow_4201(%10, F32(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:22/
  %12(CNode_4202) = $(__main___FocalLoss_construct_4172):S_Prim_add(%9, F32(1e-08))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:25/
  %13(CNode_4203) = $(__main___FocalLoss_construct_4172):call @log_4204(%12)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:25/
  %14(ce_loss) = $(__main___FocalLoss_construct_4172):S_Prim_negative(%13)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:25/
  %15(focal_loss) = $(__main___FocalLoss_construct_4172):S_Prim_mul(%11, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:28/
  %16(focal_loss) = S_Prim_mul(%1, %15)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:33/
  Return(%16)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:32/
}
# Order:
#   1: @✓__main___FocalLoss_construct_4188:alpha_factor{[0]: ValueNode<FuncGraph> gather_4298, [1]: ValueNode<None> None, [2]: param_targets, [3]: ValueNode<Int64Imm> 0}
#   2: @✓__main___FocalLoss_construct_4188:focal_loss{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: alpha_factor, [2]: focal_loss}
#   3: @✓__main___FocalLoss_construct_4188:CNode_4299{[0]: ValueNode<Primitive> Return, [1]: focal_loss}


subgraph attr:
subgraph instance: log_4204 : 0x561a1cc25070
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1432/def log(input):/
subgraph @log_4204(%para170_input) {
  %1(CNode_4300) = S_Prim_Log[output_names: ["y"], shift: F32(0), scale: F32(1), cust_aicpu: "Log", input_names: ["x"], base: F32(-1)](%para170_input)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1464/    return log_(input)/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1464/    return log_(input)/
}
# Order:
#   1: @log_4204:CNode_4300{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Log, [1]: param_input}
#   2: @log_4204:CNode_4301{[0]: ValueNode<Primitive> Return, [1]: CNode_4300}


subgraph attr:
subgraph instance: pow_4201 : 0x56198dddcca0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1259/def pow(input, exponent):/
subgraph @pow_4201(%para171_input, %para172_exponent) {
  %1(CNode_4302) = S_Prim_Pow[output_names: ["y"], input_names: ["x1", "x2"]](%para171_input, %para172_exponent)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1310/    return tensor_pow(input, exponent)/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1310/    return tensor_pow(input, exponent)/
}
# Order:
#   1: @pow_4201:CNode_4302{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Pow, [1]: param_input, [2]: param_exponent}
#   2: @pow_4201:CNode_4303{[0]: ValueNode<Primitive> Return, [1]: CNode_4302}


subgraph attr:
subgraph instance: mindspore_nn_layer_activation_Softmax_construct_4192 : 0x56198fe862b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:277/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_Softmax_construct_4192(%para173_x) {
  %1(CNode_4304) = S_Prim_Softmax[output_names: ["output"], input_names: ["x"], axis: (I64(1))](%para173_x)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss/softmax-Softmax)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:278/        return self.softmax(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss/softmax-Softmax)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:278/        return self.softmax(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_Softmax_construct_4192:CNode_4304{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Softmax, [1]: param_x}
#   2: @mindspore_nn_layer_activation_Softmax_construct_4192:CNode_4305{[0]: ValueNode<Primitive> Return, [1]: CNode_4304}


subgraph attr:
subgraph instance: mindspore_nn_layer_basic_OneHot_construct_4193 : 0x56198a7d83a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:774/    def construct(self, indices):/
subgraph @mindspore_nn_layer_basic_OneHot_construct_4193(%para174_indices) {
  %1(CNode_4306) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](F32(1), F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss/onehot-OneHot)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:775/        return self.onehot(indices, self.depth, F.cast(self.on_value, self.dtype), F.cast(self.off_value, self.dtype))/
  %2(CNode_4307) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](F32(0), F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss/onehot-OneHot)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:775/        return self.onehot(indices, self.depth, F.cast(self.on_value, self.dtype), F.cast(self.off_value, self.dtype))/
  %3(CNode_4308) = S_Prim_OneHot[output_names: ["output"], input_names: ["indices", "depth", "on_value", "off_value"], axis: I64(-1)](%para174_indices, I64(5), %1, %2)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss/onehot-OneHot)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:775/        return self.onehot(indices, self.depth, F.cast(self.on_value, self.dtype), F.cast(self.off_value, self.dtype))/
  Return(%3)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss/onehot-OneHot)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:775/        return self.onehot(indices, self.depth, F.cast(self.on_value, self.dtype), F.cast(self.off_value, self.dtype))/
}
# Order:
#   1: @mindspore_nn_layer_basic_OneHot_construct_4193:CNode_4306{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: ValueNode<FP32Imm> 1, [2]: ValueNode<Float> Float32}
#   2: @mindspore_nn_layer_basic_OneHot_construct_4193:CNode_4307{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: ValueNode<FP32Imm> 0, [2]: ValueNode<Float> Float32}
#   3: @mindspore_nn_layer_basic_OneHot_construct_4193:CNode_4308{[0]: ValueNode<DoSignaturePrimitive> S_Prim_OneHot, [1]: param_indices, [2]: ValueNode<Int64Imm> 5, [3]: CNode_4306, [4]: CNode_4307}
#   4: @mindspore_nn_layer_basic_OneHot_construct_4193:CNode_4309{[0]: ValueNode<Primitive> Return, [1]: CNode_4308}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindspore_nn_layer_basic_Dense_construct_4255 : 0x561a1dfd6600
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_basic_Dense_construct_4255 parent: [subgraph @mindspore_nn_layer_basic_Dense_construct_4219](%para175_) {
  %1(CNode_4311) = call @✓↓mindspore_nn_layer_basic_Dense_construct_4310()
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:628/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:628/        if self.has_bias:/
}
# Order:
#   1: @↓mindspore_nn_layer_basic_Dense_construct_4255:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MatMul, [1]: param_фx, [2]: param_classifier.weight}
#   2: @↓mindspore_nn_layer_basic_Dense_construct_4255:CNode_4311{[0]: ValueNode<FuncGraph> ✓↓mindspore_nn_layer_basic_Dense_construct_4310}
#   3: @↓mindspore_nn_layer_basic_Dense_construct_4255:CNode_4312{[0]: ValueNode<Primitive> Return, [1]: CNode_4311}


subgraph attr:
training : 0
subgraph instance: ✓mindspore_nn_layer_basic_Dense_construct_4252 : 0x561a1e3e8f30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @✓mindspore_nn_layer_basic_Dense_construct_4252 parent: [subgraph @mindspore_nn_layer_basic_Dense_construct_4219]() {
  %1(CNode_4313) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  %2(x_shape) = $(mindspore_nn_layer_basic_Dense_construct_4219):S_Prim_Shape(%para164_x)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623/        x_shape = self.shape_op(x)/
  %3(CNode_4314) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  %4(CNode_4315) = S_Prim_getitem(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  %5(CNode_4316) = S_Prim_MakeTuple(%1, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  %6(x) = S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para164_x, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  Return(%6)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
}
# Order:
#   1: @✓mindspore_nn_layer_basic_Dense_construct_4252:CNode_4313{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @✓mindspore_nn_layer_basic_Dense_construct_4252:CNode_4314{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   3: @✓mindspore_nn_layer_basic_Dense_construct_4252:CNode_4315{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_4314}
#   4: @✓mindspore_nn_layer_basic_Dense_construct_4252:CNode_4316{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4313, [2]: CNode_4315}
#   5: @✓mindspore_nn_layer_basic_Dense_construct_4252:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: param_x, [2]: CNode_4316}
#   6: @✓mindspore_nn_layer_basic_Dense_construct_4252:CNode_4317{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
subgraph instance: ✗mindspore_nn_layer_basic_Dense_construct_4253 : 0x561a1dfda1f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_basic_Dense_construct_4253 parent: [subgraph @mindspore_nn_layer_basic_Dense_construct_4219]() {
  Return(%para164_x)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
}
# Order:
#   1: @✗mindspore_nn_layer_basic_Dense_construct_4253:CNode_4318{[0]: ValueNode<Primitive> Return, [1]: param_x}


subgraph attr:
after_block : 1
training : 0
ge_sync_data : 0
subgraph instance: ↓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4273 : 0x5619939cf430
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @↓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4273(%para176_) {
  Return(%para176_фx)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
}
# Order:
#   1: @↓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4273:CNode_4319{[0]: ValueNode<Primitive> Return, [1]: param_фx}


subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: ✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270 : 0x561a1d020a50
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270 parent: [subgraph @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229]() {
  %1(x) = $(__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179):call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  %2(CNode_4261) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):getattr(%1, "reshape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %3(CNode_4262) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):getattr(%1, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %4(CNode_4263) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %5(CNode_4264) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %6(x) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):%2(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %7(CNode_4320) = getattr(%6, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %8(CNode_4321) = S_Prim_getitem(%7, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %9(CNode_4322) = S_Prim_greater(%8, I64(2048))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %10(CNode_4323) = Cond(%9, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %11(CNode_4324) = Switch(%10, @↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325, @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %12(x) = %11()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%12)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
}
# Order:
#   1: @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270:CNode_4320{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> shape}
#   2: @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270:CNode_4321{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4320, [2]: ValueNode<Int64Imm> 1}
#   3: @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270:CNode_4322{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: CNode_4321, [2]: ValueNode<Int64Imm> 2048}
#   4: @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270:CNode_4323{[0]: ValueNode<Primitive> Cond, [1]: CNode_4322, [2]: ValueNode<BoolImm> false}
#   5: @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270:CNode_4324{[0]: ValueNode<Primitive> Switch, [1]: CNode_4323, [2]: ValueNode<FuncGraph> ↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325, [3]: ValueNode<FuncGraph> ↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326}
#   6: @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270:x{[0]: CNode_4324}
#   7: @✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4270:CNode_4327{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: 3✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4271 : 0x561a20b3f180
# In file /tmp/ipykernel_280126/3613542768.py:34/
subgraph @3✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4271 parent: [subgraph @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229]() {
  %1(x) = $(__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179):call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  %2(CNode_4261) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):getattr(%1, "reshape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %3(CNode_4262) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):getattr(%1, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %4(CNode_4263) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %5(CNode_4264) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %6(x) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):%2(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  Return(%6)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:48/
}
# Order:
#   1: @3✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4271:CNode_4328{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
subgraph instance: assert_mindcv_models_bit_BiT_ResNet_construct_4276 : 0x561988019570
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:266/        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left./
subgraph @assert_mindcv_models_bit_BiT_ResNet_construct_4276 parent: [subgraph @mindcv_models_bit_BiT_ResNet_construct_4207]() {
  %1(x) = $(mindcv_models_bit_BiT_ResNet_construct_4207):call @root_4234(%para163_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:263/        x = self.root(x)/
  %2(x) = $(mindcv_models_bit_BiT_ResNet_construct_4207):call @forward_features_4235(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:264/        x = self.forward_features(x)/
  %3(x) = $(mindcv_models_bit_BiT_ResNet_construct_4207):call @forward_head_4236(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:265/        x = self.forward_head(x)/
  %4(CNode_4329) = S_Prim_MakeTuple(Ellipsis[Ellipsis], I64(0), I64(0))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:267/        return x[..., 0, 0]/
  %5(CNode_4330) = S_Prim_getitem(%3, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:267/        return x[..., 0, 0]/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:267/        return x[..., 0, 0]/
}
# Order:
#   1: @assert_mindcv_models_bit_BiT_ResNet_construct_4276:CNode_4329{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Ellipsis> Ellipsis, [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<Int64Imm> 0}
#   2: @assert_mindcv_models_bit_BiT_ResNet_construct_4276:CNode_4330{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x, [2]: CNode_4329}
#   3: @assert_mindcv_models_bit_BiT_ResNet_construct_4276:CNode_4331{[0]: ValueNode<Primitive> Return, [1]: CNode_4330}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_basic_Identity_construct_4280 : 0x561a1c498770
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:505/    def construct(self, x):/
subgraph @mindspore_nn_layer_basic_Identity_construct_4280(%para177_x) {
  Return(%para177_x)
      : (<null>)
      #scope: (Default/backbone-BiT_ResNet/classifier-Identity)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:506/        return x/
}
# Order:
#   1: @mindspore_nn_layer_basic_Identity_construct_4280:CNode_4332{[0]: ValueNode<Primitive> Return, [1]: param_x}


subgraph attr:
training : 0
subgraph instance: mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279 : 0x561993d606a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/layers/pooling.py:14/    def construct(self, x):/
subgraph @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279(%para178_x) {
  %1(CNode_4333) = S_Prim_MakeTuple(%para178_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pool-GlobalAvgPooling)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/layers/pooling.py:15/        x = ops.mean(x, axis=(2, 3), keep_dims=self.keep_dims)/
  %2(CNode_4334) = S_Prim_MakeTuple("axis", "keep_dims")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pool-GlobalAvgPooling)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/layers/pooling.py:15/        x = ops.mean(x, axis=(2, 3), keep_dims=self.keep_dims)/
  %3(CNode_4335) = S_Prim_MakeTuple(I64(2), I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pool-GlobalAvgPooling)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/layers/pooling.py:15/        x = ops.mean(x, axis=(2, 3), keep_dims=self.keep_dims)/
  %4(CNode_4336) = S_Prim_MakeTuple(%3, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pool-GlobalAvgPooling)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/layers/pooling.py:15/        x = ops.mean(x, axis=(2, 3), keep_dims=self.keep_dims)/
  %5(CNode_4337) = S_Prim_make_dict(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pool-GlobalAvgPooling)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/layers/pooling.py:15/        x = ops.mean(x, axis=(2, 3), keep_dims=self.keep_dims)/
  %6(x) = UnpackCall_unpack_call(@mean_4338, %1, %5)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pool-GlobalAvgPooling)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/layers/pooling.py:15/        x = ops.mean(x, axis=(2, 3), keep_dims=self.keep_dims)/
  Return(%6)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pool-GlobalAvgPooling)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/layers/pooling.py:16/        return x/
}
# Order:
#   1: @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279:CNode_4333{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_x}
#   2: @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279:CNode_4335{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 2, [2]: ValueNode<Int64Imm> 3}
#   3: @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279:CNode_4334{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> axis, [2]: ValueNode<StringImm> keep_dims}
#   4: @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279:CNode_4336{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4335, [2]: ValueNode<BoolImm> true}
#   5: @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279:CNode_4337{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_4334, [2]: CNode_4336}
#   6: @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279:x{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.4339, [1]: ValueNode<FuncGraph> mean_4338, [2]: CNode_4333, [3]: CNode_4337}
#   7: @mindcv_models_layers_pooling_GlobalAvgPooling_construct_4279:CNode_4340{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4278 : 0x561a1f7bb100
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4278(%para179_x) {
  %1(CNode_4341) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para179_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4278:CNode_4341{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4278:CNode_4342{[0]: ValueNode<Primitive> Return, [1]: CNode_4341}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4277 : 0x561a21afac50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4277 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para180_x) {
  %1(CNode_4344) = call @shape_4343(%para180_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4345) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4346) = getattr(%para180_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4347) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4348) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4349) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4350) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4351(%para180_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4352) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4277:CNode_4344{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4277:CNode_4345{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4344, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4277:CNode_4346{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4277:CNode_4347{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4277:CNode_4348{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4346, [2]: CNode_4347, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4277:output{[0]: ValueNode<FuncGraph> _cal_output_4351, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4277:CNode_4353{[0]: ValueNode<Primitive> Return, [1]: CNode_4352}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_4285 : 0x561987489310
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_4285 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para181_input_data) {
  %1(CNode_4355) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4354(I64(0), %para181_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_4285:CNode_4356{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_4357}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_4285:CNode_4355{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4354, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_4285:CNode_4358{[0]: ValueNode<Primitive> Return, [1]: CNode_4355}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_4284 : 0x561a1ffac770
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_4284 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para182_input_data) {
  %1(CNode_4360) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4359(I64(0), %para182_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_4284:CNode_4361{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_4362}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_4284:CNode_4360{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4359, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_4284:CNode_4363{[0]: ValueNode<Primitive> Return, [1]: CNode_4360}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_4283 : 0x561a20ab4fe0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_4283 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para183_input_data) {
  %1(CNode_4365) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4364(I64(0), %para183_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_4283:CNode_4366{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_4367}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_4283:CNode_4365{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4364, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_4283:CNode_4368{[0]: ValueNode<Primitive> Return, [1]: CNode_4365}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_4282 : 0x561a17a67970
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_4282 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para184_input_data) {
  %1(CNode_4370) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4369(I64(0), %para184_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_4282:CNode_4371{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_4372}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_4282:CNode_4370{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4369, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_4282:CNode_4373{[0]: ValueNode<Primitive> Return, [1]: CNode_4370}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_pooling_MaxPool2d_construct_4289 : 0x561a1cc17310
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @mindspore_nn_layer_pooling_MaxPool2d_construct_4289(%para185_x) {
  %1(CNode_4374) = getattr(%para185_x, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  %2(CNode_4375) = S_Prim_equal(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  %3(CNode_4376) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  %4(CNode_4377) = Switch(%3, @✓mindspore_nn_layer_pooling_MaxPool2d_construct_4378, @✗mindspore_nn_layer_pooling_MaxPool2d_construct_4379)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  %5(CNode_4380) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
}
# Order:
#   1: @mindspore_nn_layer_pooling_MaxPool2d_construct_4289:CNode_4374{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> ndim}
#   2: @mindspore_nn_layer_pooling_MaxPool2d_construct_4289:CNode_4375{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_4374, [2]: ValueNode<Int64Imm> 3}
#   3: @mindspore_nn_layer_pooling_MaxPool2d_construct_4289:CNode_4376{[0]: ValueNode<Primitive> Cond, [1]: CNode_4375, [2]: ValueNode<BoolImm> false}
#   4: @mindspore_nn_layer_pooling_MaxPool2d_construct_4289:CNode_4377{[0]: ValueNode<Primitive> Switch, [1]: CNode_4376, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_pooling_MaxPool2d_construct_4378, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_pooling_MaxPool2d_construct_4379}
#   5: @mindspore_nn_layer_pooling_MaxPool2d_construct_4289:CNode_4380{[0]: CNode_4377}
#   6: @mindspore_nn_layer_pooling_MaxPool2d_construct_4289:CNode_4381{[0]: ValueNode<Primitive> Return, [1]: CNode_4380}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_padding_ConstantPad2d_construct_4288 : 0x561a1efbbf80
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:214/    def construct(self, x):/
subgraph @mindspore_nn_layer_padding_ConstantPad2d_construct_4288(%para186_x) {
  %1(slice_op) = ClassType()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:225/        slice_op = ops.Slice()/
  %2(CNode_4382) = ClassType()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:224/        output = ops.Add()(ops.Mul()(mask, output), ops.Mul()(ops.Sub()(ones, mask), value))/
  %3(CNode_4383) = ClassType()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:224/        output = ops.Add()(ops.Mul()(mask, output), ops.Mul()(ops.Sub()(ones, mask), value))/
  %4(input_shape) = getattr(%para186_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:216/        input_shape = x.shape/
  %5(padding) = S_Prim__check[constexpr_prim: Bool(1)](%4, [[I64(1), I64(1)], [I64(1), I64(1)]], "ConstantPad2d")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:217/        padding = _check(input_shape, self.padding, self._name)/
  %6(CNode_4384) = S_Prim__get_new_padding[constexpr_prim: Bool(1)](%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:218/        new_padding, start, end = _get_new_padding(padding)/
  %7(new_padding) = S_Prim_getitem(%6, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:218/        new_padding, start, end = _get_new_padding(padding)/
  %8(CNode_4385) = ClassType(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:221/        mask = ops.Pad(new_padding)(mask)/
  %9(CNode_4386) = ClassType()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:219/        mask = ops.OnesLike()(x)/
  %10(mask) = %9(%para186_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:219/        mask = ops.OnesLike()(x)/
  %11(mask) = %8(%10)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:221/        mask = ops.Pad(new_padding)(mask)/
  %12(CNode_4387) = ClassType(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:220/        output = ops.Pad(new_padding)(x)/
  %13(output) = %12(%para186_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:220/        output = ops.Pad(new_padding)(x)/
  %14(CNode_4388) = %3(%11, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:224/        output = ops.Add()(ops.Mul()(mask, output), ops.Mul()(ops.Sub()(ones, mask), value))/
  %15(CNode_4389) = ClassType()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:224/        output = ops.Add()(ops.Mul()(mask, output), ops.Mul()(ops.Sub()(ones, mask), value))/
  %16(CNode_4390) = ClassType()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:224/        output = ops.Add()(ops.Mul()(mask, output), ops.Mul()(ops.Sub()(ones, mask), value))/
  %17(CNode_4391) = ClassType()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:222/        ones = ops.OnesLike()(output)/
  %18(ones) = %17(%13)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:222/        ones = ops.OnesLike()(output)/
  %19(CNode_4392) = %16(%18, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:224/        output = ops.Add()(ops.Mul()(mask, output), ops.Mul()(ops.Sub()(ones, mask), value))/
  %20(CNode_4393) = getattr(%13, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:223/        value = ops.fill(output.dtype, output.shape, self.value)/
  %21(CNode_4394) = getattr(%13, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:223/        value = ops.fill(output.dtype, output.shape, self.value)/
  %22(value) = call @fill_4395(%20, %21, I64(0))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:223/        value = ops.fill(output.dtype, output.shape, self.value)/
  %23(CNode_4396) = %15(%19, %22)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:224/        output = ops.Add()(ops.Mul()(mask, output), ops.Mul()(ops.Sub()(ones, mask), value))/
  %24(output) = %2(%14, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:224/        output = ops.Add()(ops.Mul()(mask, output), ops.Mul()(ops.Sub()(ones, mask), value))/
  %25(CNode_4397) = getattr(%24, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:226/        begin, size = _get_begin_size(output.shape, start, end)/
  %26(start) = S_Prim_getitem(%6, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:218/        new_padding, start, end = _get_new_padding(padding)/
  %27(end) = S_Prim_getitem(%6, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:218/        new_padding, start, end = _get_new_padding(padding)/
  %28(CNode_4398) = S_Prim__get_begin_size[constexpr_prim: Bool(1)](%25, %26, %27)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:226/        begin, size = _get_begin_size(output.shape, start, end)/
  %29(begin) = S_Prim_getitem(%28, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:226/        begin, size = _get_begin_size(output.shape, start, end)/
  %30(size) = S_Prim_getitem(%28, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:226/        begin, size = _get_begin_size(output.shape, start, end)/
  %31(output) = %1(%24, %29, %30)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:227/        output = slice_op(output, begin, size)/
  Return(%31)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/padding.py:228/        return output/
}
# Order:
#   1: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:input_shape{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:padding{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check, [1]: input_shape, [2]: ValueNode<ValueList> [[1, 1], [1, 1]], [3]: ValueNode<StringImm> ConstantPad2d}
#   3: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4384{[0]: ValueNode<DoSignaturePrimitive> S_Prim__get_new_padding, [1]: padding}
#   4: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:new_padding{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4384, [2]: ValueNode<Int64Imm> 0}
#   5: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:start{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4384, [2]: ValueNode<Int64Imm> 1}
#   6: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:end{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4384, [2]: ValueNode<Int64Imm> 2}
#   7: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4386{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.OnesLike'}
#   8: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:mask{[0]: CNode_4386, [1]: param_x}
#   9: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4387{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.nn_ops.Pad', [1]: new_padding}
#  10: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:output{[0]: CNode_4387, [1]: param_x}
#  11: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4385{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.nn_ops.Pad', [1]: new_padding}
#  12: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:mask{[0]: CNode_4385, [1]: mask}
#  13: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4391{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.OnesLike'}
#  14: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:ones{[0]: CNode_4391, [1]: output}
#  15: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4393{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> dtype}
#  16: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4394{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> shape}
#  17: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:value{[0]: ValueNode<FuncGraph> fill_4395, [1]: CNode_4393, [2]: CNode_4394, [3]: ValueNode<Int64Imm> 0}
#  18: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4382{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.Add'}
#  19: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4383{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.Mul'}
#  20: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4388{[0]: CNode_4383, [1]: mask, [2]: output}
#  21: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4389{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.Mul'}
#  22: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4390{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.Sub'}
#  23: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4392{[0]: CNode_4390, [1]: ones, [2]: mask}
#  24: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4396{[0]: CNode_4389, [1]: CNode_4392, [2]: value}
#  25: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:output{[0]: CNode_4382, [1]: CNode_4388, [2]: CNode_4396}
#  26: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:slice_op{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.Slice'}
#  27: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4397{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> shape}
#  28: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4398{[0]: ValueNode<DoSignaturePrimitive> S_Prim__get_begin_size, [1]: CNode_4397, [2]: start, [3]: end}
#  29: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:begin{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4398, [2]: ValueNode<Int64Imm> 0}
#  30: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:size{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4398, [2]: ValueNode<Int64Imm> 1}
#  31: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:output{[0]: slice_op, [1]: output, [2]: begin, [3]: size}
#  32: @mindspore_nn_layer_padding_ConstantPad2d_construct_4288:CNode_4399{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4287 : 0x561a1edea5e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4287 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para187_x) {
  %1(CNode_4400) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para4_backbone.conv1.weight, %1)
      : (<Ref[Tensor[Float32]], (64, 3, 7, 7), ref_key=:backbone.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_4401) = S_Prim_sub(%para4_backbone.conv1.weight, %2)
      : (<Ref[Tensor[Float32]], (64, 3, 7, 7), ref_key=:backbone.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_4402) = getattr(%para4_backbone.conv1.weight, "var")
      : (<Ref[Tensor[Float32]], (64, 3, 7, 7), ref_key=:backbone.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_4403) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_4404) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_4405) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_4406) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_4407) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_4408) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_4410) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(7), I64(7)), mode: I64(1), out_channel: I64(64), input_names: ["x", "w"], pad: (I64(3), I64(3), I64(3), I64(3)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(3), I64(3), I64(3), I64(3)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para187_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4400{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_4287:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.conv1.weight, [2]: CNode_4400}
#   3: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4402{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4403{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4404{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4403}
#   6: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4405{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4406{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4407{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_4405, [2]: CNode_4406}
#   9: @mindcv_models_bit_StdConv2d_construct_4287:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.4411, [1]: CNode_4402, [2]: CNode_4404, [3]: CNode_4407}
#  10: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4401{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.conv1.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4408{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4410{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_4408}
#  13: @mindcv_models_bit_StdConv2d_construct_4287:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_4401, [2]: CNode_4410}
#  14: @mindcv_models_bit_StdConv2d_construct_4287:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_4287:CNode_4412{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
subgraph instance: ✓↓__main___FocalLoss_construct_4294 : 0x561a1780bf90
# In file /tmp/ipykernel_280126/1697004305.py:11/
subgraph @✓↓__main___FocalLoss_construct_4294 parent: [subgraph @↓__main___FocalLoss_construct_4190]() {
  %1(CNode_4413) = call @mean_4338(%para169_фfocal_loss)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:37/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:37/
}
# Order:
#   1: @✓↓__main___FocalLoss_construct_4294:CNode_4413{[0]: ValueNode<FuncGraph> mean_4338, [1]: param_фfocal_loss}
#   2: @✓↓__main___FocalLoss_construct_4294:CNode_4414{[0]: ValueNode<Primitive> Return, [1]: CNode_4413}


subgraph attr:
subgraph instance: ✗↓__main___FocalLoss_construct_4295 : 0x561a21ac4310
# In file /tmp/ipykernel_280126/1697004305.py:11/
subgraph @✗↓__main___FocalLoss_construct_4295 parent: [subgraph @↓__main___FocalLoss_construct_4190]() {
  %1(CNode_4415) = S_Prim_equal("mean", "sum")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:38/
  %2(CNode_4416) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:38/
  %3(CNode_4417) = Switch(%2, @✓✗↓__main___FocalLoss_construct_4418, @2✗↓__main___FocalLoss_construct_4419)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:38/
  %4(CNode_4420) = %3()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:38/
  Return(%4)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:38/
}
# Order:
#   1: @✗↓__main___FocalLoss_construct_4295:CNode_4415{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: ValueNode<StringImm> mean, [2]: ValueNode<StringImm> sum}
#   2: @✗↓__main___FocalLoss_construct_4295:CNode_4416{[0]: ValueNode<Primitive> Cond, [1]: CNode_4415, [2]: ValueNode<BoolImm> false}
#   3: @✗↓__main___FocalLoss_construct_4295:CNode_4417{[0]: ValueNode<Primitive> Switch, [1]: CNode_4416, [2]: ValueNode<FuncGraph> ✓✗↓__main___FocalLoss_construct_4418, [3]: ValueNode<FuncGraph> 2✗↓__main___FocalLoss_construct_4419}
#   4: @✗↓__main___FocalLoss_construct_4295:CNode_4420{[0]: CNode_4417}
#   5: @✗↓__main___FocalLoss_construct_4295:CNode_4421{[0]: ValueNode<Primitive> Return, [1]: CNode_4420}


subgraph attr:
subgraph instance: gather_4298 : 0x561a21bed6a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:3485/def gather(input_params, input_indices, axis, batch_dims=0):/
subgraph @gather_4298(%para188_input_params, %para189_input_indices, %para190_axis, %para191_batch_dims) {
  %1(CNode_4423) = call @_get_cache_prim_4422(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:3566/    _gather = _get_cache_prim(P.Gather)(batch_dims)/
  %2(_gather) = %1(%para191_batch_dims)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:3566/    _gather = _get_cache_prim(P.Gather)(batch_dims)/
  %3(CNode_4424) = %2(%para188_input_params, %para189_input_indices, %para190_axis)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:3567/    return _gather(input_params, input_indices, axis)/
  Return(%3)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:3567/    return _gather(input_params, input_indices, axis)/
}
# Order:
#   1: @gather_4298:CNode_4423{[0]: ValueNode<FuncGraph> _get_cache_prim_4422, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.Gather'}
#   2: @gather_4298:_gather{[0]: CNode_4423, [1]: param_batch_dims}
#   3: @gather_4298:CNode_4424{[0]: _gather, [1]: param_input_params, [2]: param_input_indices, [3]: param_axis}
#   4: @gather_4298:CNode_4425{[0]: ValueNode<Primitive> Return, [1]: CNode_4424}


subgraph attr:
training : 0
subgraph instance: ✓↓mindspore_nn_layer_basic_Dense_construct_4310 : 0x561a1decb560
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @✓↓mindspore_nn_layer_basic_Dense_construct_4310 parent: [subgraph @↓mindspore_nn_layer_basic_Dense_construct_4255]() {
  %1(CNode_4427) = call @2↓mindspore_nn_layer_basic_Dense_construct_4426()
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:629/            x = self.bias_add(x, self.bias)/
  Return(%1)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:629/            x = self.bias_add(x, self.bias)/
}
# Order:
#   1: @✓↓mindspore_nn_layer_basic_Dense_construct_4310:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BiasAdd, [1]: x, [2]: param_classifier.bias}
#   2: @✓↓mindspore_nn_layer_basic_Dense_construct_4310:CNode_4427{[0]: ValueNode<FuncGraph> 2↓mindspore_nn_layer_basic_Dense_construct_4426}
#   3: @✓↓mindspore_nn_layer_basic_Dense_construct_4310:CNode_4428{[0]: ValueNode<Primitive> Return, [1]: CNode_4427}


subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: ↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325 : 0x561a20599f20
# In file /tmp/ipykernel_280126/3613542768.py:50/
subgraph @↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325 parent: [subgraph @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229]() {
  %1(x) = $(__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179):call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  %2(CNode_4261) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):getattr(%1, "reshape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %3(CNode_4262) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):getattr(%1, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %4(CNode_4263) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %5(CNode_4264) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %6(x) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):%2(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %7(CNode_4429) = S_Prim_make_slice(None, None, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %8(CNode_4430) = S_Prim_make_slice(None, I64(2048), None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %9(CNode_4431) = S_Prim_MakeTuple(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %10(CNode_4432) = S_Prim_getitem(%6, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
}
# Order:
#   1: @↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325:CNode_4429{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   2: @↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325:CNode_4430{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<Int64Imm> 2048, [3]: ValueNode<None> None}
#   3: @↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325:CNode_4431{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4429, [2]: CNode_4430}
#   4: @↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325:CNode_4432{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x, [2]: CNode_4431}
#   5: @↰✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4325:CNode_4433{[0]: ValueNode<Primitive> Return, [1]: CNode_4432}


subgraph attr:
training : 0
ge_sync_data : 0
subgraph instance: ↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326 : 0x561a1f4fa490
# In file /tmp/ipykernel_280126/3613542768.py:50/
subgraph @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326 parent: [subgraph @2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229]() {
  %1(x) = $(__main___fix_bit_model_simple__locals__FixedBitModel_construct_4179):call @mindcv_models_bit_BiT_ResNet_construct_4207(%para161_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:36/
  %2(CNode_4261) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):getattr(%1, "reshape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %3(CNode_4262) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):getattr(%1, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %4(CNode_4263) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %5(CNode_4264) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %6(x) = $(2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4229):%2(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:47/
  %7(CNode_4434) = S_Prim_MakeTuple(I64(0), I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %8(CNode_4435) = getattr(%6, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %9(CNode_4436) = S_Prim_getitem(%8, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %10(CNode_4437) = S_Prim_sub(I64(2048), %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %11(CNode_4438) = S_Prim_MakeTuple(I64(0), %10)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %12(CNode_4439) = S_Prim_MakeTuple(%7, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %13(CNode_4441) = call @pad_4440(%6, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%13)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
}
# Order:
#   1: @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326:CNode_4434{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 0}
#   2: @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326:CNode_4435{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> shape}
#   3: @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326:CNode_4436{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4435, [2]: ValueNode<Int64Imm> 1}
#   4: @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326:CNode_4437{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: ValueNode<Int64Imm> 2048, [2]: CNode_4436}
#   5: @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326:CNode_4438{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0, [2]: CNode_4437}
#   6: @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326:CNode_4439{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4434, [2]: CNode_4438}
#   7: @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326:CNode_4441{[0]: ValueNode<FuncGraph> pad_4440, [1]: x, [2]: CNode_4439}
#   8: @↱✓2✗__main___fix_bit_model_simple__locals__FixedBitModel_construct_4326:CNode_4442{[0]: ValueNode<Primitive> Return, [1]: CNode_4441}


subgraph attr:
subgraph instance: mean_4338 : 0x561a1ca7a630
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8364/def mean(x, axis=None, keep_dims=False):/
subgraph @mean_4338(%para192_x, %para193_axis, %para194_keep_dims) {
  %1(CNode_4443) = S_Prim_is_(%para193_axis, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8441/    if axis is None:/
  %2(CNode_4444) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8441/    if axis is None:/
  %3(CNode_4445) = Switch(%2, @✓mean_4446, @✗mean_4447)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8441/    if axis is None:/
  %4(CNode_4448) = %3()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8441/    if axis is None:/
  %5(CNode_4450) = call @↓mean_4449(%4)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:37/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8441/    if axis is None:/
}
# Order:
#   1: @mean_4338:CNode_4443{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: param_axis, [2]: ValueNode<None> None}
#   2: @mean_4338:CNode_4444{[0]: ValueNode<Primitive> Cond, [1]: CNode_4443, [2]: ValueNode<BoolImm> false}
#   3: @mean_4338:CNode_4445{[0]: ValueNode<Primitive> Switch, [1]: CNode_4444, [2]: ValueNode<FuncGraph> ✓mean_4446, [3]: ValueNode<FuncGraph> ✗mean_4447}
#   4: @mean_4338:CNode_4448{[0]: CNode_4445}
#   5: @mean_4338:CNode_4450{[0]: ValueNode<FuncGraph> ↓mean_4449, [1]: CNode_4448}
#   6: @mean_4338:CNode_4451{[0]: ValueNode<Primitive> Return, [1]: CNode_4450}


subgraph attr:
training : 0
subgraph instance: _cal_output_4351 : 0x561a1ed932a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4351 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para195_x) {
  %1(CNode_4452) = call @shape_4343(%para195_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_4453) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(2048), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_4454) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_4455) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_4456) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para195_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_4459) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_4460) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_4462) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_4463) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_4464) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_4465) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_4466) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_4468) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_4469) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_4470) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_4471) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_4472) = call @reshape_4457(%para7_backbone.gn.gamma, %26)
      : (<Ref[Tensor[Float32]], (2048), ref_key=:backbone.gn.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_4473) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_4474) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_4475) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_4476) = call @reshape_4457(%para6_backbone.gn.beta, %30)
      : (<Ref[Tensor[Float32]], (2048), ref_key=:backbone.gn.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_4478) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4351:CNode_4452{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4351:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4452, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4351:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4452, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4351:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4452, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4351:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4452, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4351:CNode_4453{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 2048, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4351:CNode_4455{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4351:CNode_4456{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_4455}
#   9: @_cal_output_4351:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_4456}
#  10: @_cal_output_4351:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4351:CNode_4460{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4351:CNode_4462{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_4460}
#  13: @_cal_output_4351:CNode_4463{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_4462, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4351:CNode_4464{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4351:CNode_4465{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_4464, [2]: width}
#  16: @_cal_output_4351:CNode_4466{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_4465, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4351:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_4463, [2]: CNode_4466}
#  18: @_cal_output_4351:CNode_4468{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4351:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_4468}
#  20: @_cal_output_4351:CNode_4459{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4351:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_4459, [2]: std}
#  22: @_cal_output_4351:CNode_4469{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4351:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_4469}
#  24: @_cal_output_4351:CNode_4470{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4351:CNode_4471{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4470, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4351:CNode_4472{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.gn.gamma, [2]: CNode_4471}
#  27: @_cal_output_4351:CNode_4473{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_4472}
#  28: @_cal_output_4351:CNode_4474{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4351:CNode_4475{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4474, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4351:CNode_4476{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.gn.beta, [2]: CNode_4475}
#  31: @_cal_output_4351:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_4473, [2]: CNode_4476}
#  32: @_cal_output_4351:CNode_4479{[0]: ValueNode<Primitive> Return, [1]: CNode_4478}


subgraph attr:
subgraph instance: shape_4343 : 0x56198e4e4880
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1483/def shape(input_x):/
subgraph @shape_4343(%para196_input_x) {
  %1(CNode_4480) = S_Prim_Shape(%para196_input_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1509/    return shape_(input_x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1509/    return shape_(input_x)/
}
# Order:
#   1: @shape_4343:CNode_4480{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_input_x}
#   2: @shape_4343:CNode_4481{[0]: ValueNode<Primitive> Return, [1]: CNode_4480}


subgraph attr:
training : 0
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_4354 : 0x561993cb9350
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4354 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_4285](%para197_, %para198_) {
  %1(CNode_4357) = $(mindspore_nn_layer_container_SequentialCell_construct_4285):MakeTuple(@mindcv_models_bit_Bottleneck_construct_4482, @mindcv_models_bit_Bottleneck_construct_4483, @mindcv_models_bit_Bottleneck_construct_4484)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_4356) = $(mindspore_nn_layer_container_SequentialCell_construct_4285):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_4485) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para197_@CNode_4486, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_4487) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_4488, @↓mindspore_nn_layer_container_SequentialCell_construct_4489)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_4490) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_4354:CNode_4485{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.10, [1]: param_@CNode_4486, [2]: CNode_4356}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_4354:CNode_4487{[0]: ValueNode<Primitive> Switch, [1]: CNode_4485, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_4488, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_4489}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_4354:CNode_4490{[0]: CNode_4487}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_4354:CNode_4491{[0]: ValueNode<Primitive> Return, [1]: CNode_4490}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4482 : 0x561a1ed2f200
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4482 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para199_x) {
  %1(CNode_4492) = S_Prim_is_not(@mindspore_nn_layer_container_SequentialCell_construct_4493, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4494) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4495) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4496, @✗mindcv_models_bit_Bottleneck_construct_4497)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4498) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4500) = call @↓mindcv_models_bit_Bottleneck_construct_4499(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4482:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4501, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4482:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4502, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4482:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4503, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4482:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4504, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4482:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4502, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4482:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4505, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4482:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4506, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4482:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4502, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4482:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4507, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4482:CNode_4492{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4493, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4482:CNode_4494{[0]: ValueNode<Primitive> Cond, [1]: CNode_4492, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4482:CNode_4495{[0]: ValueNode<Primitive> Switch, [1]: CNode_4494, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4496, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4497}
#  13: @mindcv_models_bit_Bottleneck_construct_4482:CNode_4498{[0]: CNode_4495}
#  14: @mindcv_models_bit_Bottleneck_construct_4482:CNode_4500{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4499, [1]: CNode_4498}
#  15: @mindcv_models_bit_Bottleneck_construct_4482:CNode_4508{[0]: ValueNode<Primitive> Return, [1]: CNode_4500}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4483 : 0x561a1ecd7210
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4483 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para200_x) {
  %1(CNode_4509) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4510) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4511) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4512, @✗mindcv_models_bit_Bottleneck_construct_4513)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4514) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4516) = call @↓mindcv_models_bit_Bottleneck_construct_4515(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4483:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4517, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4483:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4518, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4483:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4519, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4483:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4520, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4483:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4518, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4483:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4521, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4483:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4522, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4483:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4518, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4483:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4523, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4483:CNode_4509{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4483:CNode_4510{[0]: ValueNode<Primitive> Cond, [1]: CNode_4509, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4483:CNode_4511{[0]: ValueNode<Primitive> Switch, [1]: CNode_4510, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4512, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4513}
#  13: @mindcv_models_bit_Bottleneck_construct_4483:CNode_4514{[0]: CNode_4511}
#  14: @mindcv_models_bit_Bottleneck_construct_4483:CNode_4516{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4515, [1]: CNode_4514}
#  15: @mindcv_models_bit_Bottleneck_construct_4483:CNode_4524{[0]: ValueNode<Primitive> Return, [1]: CNode_4516}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4484 : 0x561a12c911a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4484 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para201_x) {
  %1(CNode_4525) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4526) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4527) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4528, @✗mindcv_models_bit_Bottleneck_construct_4529)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4530) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4532) = call @↓mindcv_models_bit_Bottleneck_construct_4531(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4484:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4533, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4484:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4534, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4484:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4535, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4484:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4536, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4484:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4534, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4484:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4537, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4484:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4538, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4484:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4534, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4484:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4539, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4484:CNode_4525{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4484:CNode_4526{[0]: ValueNode<Primitive> Cond, [1]: CNode_4525, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4484:CNode_4527{[0]: ValueNode<Primitive> Switch, [1]: CNode_4526, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4528, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4529}
#  13: @mindcv_models_bit_Bottleneck_construct_4484:CNode_4530{[0]: CNode_4527}
#  14: @mindcv_models_bit_Bottleneck_construct_4484:CNode_4532{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4531, [1]: CNode_4530}
#  15: @mindcv_models_bit_Bottleneck_construct_4484:CNode_4540{[0]: ValueNode<Primitive> Return, [1]: CNode_4532}


subgraph attr:
training : 0
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_4359 : 0x561a218ceca0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4359 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_4284](%para202_, %para203_) {
  %1(CNode_4362) = $(mindspore_nn_layer_container_SequentialCell_construct_4284):MakeTuple(@mindcv_models_bit_Bottleneck_construct_4541, @mindcv_models_bit_Bottleneck_construct_4542, @mindcv_models_bit_Bottleneck_construct_4543, @mindcv_models_bit_Bottleneck_construct_4544, @mindcv_models_bit_Bottleneck_construct_4545, @mindcv_models_bit_Bottleneck_construct_4546)
      : (<null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_4361) = $(mindspore_nn_layer_container_SequentialCell_construct_4284):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_4547) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para202_@CNode_4548, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_4549) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_4550, @↓mindspore_nn_layer_container_SequentialCell_construct_4551)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_4552) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_4359:CNode_4547{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.10, [1]: param_@CNode_4548, [2]: CNode_4361}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_4359:CNode_4549{[0]: ValueNode<Primitive> Switch, [1]: CNode_4547, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_4550, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_4551}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_4359:CNode_4552{[0]: CNode_4549}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_4359:CNode_4553{[0]: ValueNode<Primitive> Return, [1]: CNode_4552}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4541 : 0x561a24e948d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4541 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para204_x) {
  %1(CNode_4554) = S_Prim_is_not(@mindspore_nn_layer_container_SequentialCell_construct_4555, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4556) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4557) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4558, @✗mindcv_models_bit_Bottleneck_construct_4559)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4560) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4562) = call @↓mindcv_models_bit_Bottleneck_construct_4561(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4541:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4563, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4541:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4564, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4541:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4565, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4541:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4566, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4541:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4564, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4541:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4567, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4541:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4568, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4541:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4564, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4541:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4569, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4541:CNode_4554{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4555, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4541:CNode_4556{[0]: ValueNode<Primitive> Cond, [1]: CNode_4554, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4541:CNode_4557{[0]: ValueNode<Primitive> Switch, [1]: CNode_4556, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4558, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4559}
#  13: @mindcv_models_bit_Bottleneck_construct_4541:CNode_4560{[0]: CNode_4557}
#  14: @mindcv_models_bit_Bottleneck_construct_4541:CNode_4562{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4561, [1]: CNode_4560}
#  15: @mindcv_models_bit_Bottleneck_construct_4541:CNode_4570{[0]: ValueNode<Primitive> Return, [1]: CNode_4562}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4542 : 0x561a199bd400
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4542 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para205_x) {
  %1(CNode_4571) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4572) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4573) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4574, @✗mindcv_models_bit_Bottleneck_construct_4575)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4576) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4578) = call @↓mindcv_models_bit_Bottleneck_construct_4577(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4542:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4579, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4542:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4580, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4542:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4581, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4542:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4582, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4542:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4580, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4542:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4583, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4542:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4584, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4542:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4580, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4542:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4585, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4542:CNode_4571{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4542:CNode_4572{[0]: ValueNode<Primitive> Cond, [1]: CNode_4571, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4542:CNode_4573{[0]: ValueNode<Primitive> Switch, [1]: CNode_4572, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4574, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4575}
#  13: @mindcv_models_bit_Bottleneck_construct_4542:CNode_4576{[0]: CNode_4573}
#  14: @mindcv_models_bit_Bottleneck_construct_4542:CNode_4578{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4577, [1]: CNode_4576}
#  15: @mindcv_models_bit_Bottleneck_construct_4542:CNode_4586{[0]: ValueNode<Primitive> Return, [1]: CNode_4578}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4543 : 0x561a1dec30d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4543 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para206_x) {
  %1(CNode_4587) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4588) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4589) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4590, @✗mindcv_models_bit_Bottleneck_construct_4591)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4592) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4594) = call @↓mindcv_models_bit_Bottleneck_construct_4593(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4543:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4595, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4543:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4596, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4543:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4597, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4543:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4598, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4543:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4596, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4543:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4599, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4543:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4600, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4543:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4596, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4543:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4601, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4543:CNode_4587{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4543:CNode_4588{[0]: ValueNode<Primitive> Cond, [1]: CNode_4587, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4543:CNode_4589{[0]: ValueNode<Primitive> Switch, [1]: CNode_4588, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4590, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4591}
#  13: @mindcv_models_bit_Bottleneck_construct_4543:CNode_4592{[0]: CNode_4589}
#  14: @mindcv_models_bit_Bottleneck_construct_4543:CNode_4594{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4593, [1]: CNode_4592}
#  15: @mindcv_models_bit_Bottleneck_construct_4543:CNode_4602{[0]: ValueNode<Primitive> Return, [1]: CNode_4594}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4544 : 0x561986926f80
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4544 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para207_x) {
  %1(CNode_4603) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4604) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4605) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4606, @✗mindcv_models_bit_Bottleneck_construct_4607)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4608) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4610) = call @↓mindcv_models_bit_Bottleneck_construct_4609(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4544:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4611, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4544:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4612, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4544:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4613, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4544:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4614, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4544:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4612, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4544:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4615, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4544:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4616, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4544:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4612, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4544:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4617, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4544:CNode_4603{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4544:CNode_4604{[0]: ValueNode<Primitive> Cond, [1]: CNode_4603, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4544:CNode_4605{[0]: ValueNode<Primitive> Switch, [1]: CNode_4604, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4606, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4607}
#  13: @mindcv_models_bit_Bottleneck_construct_4544:CNode_4608{[0]: CNode_4605}
#  14: @mindcv_models_bit_Bottleneck_construct_4544:CNode_4610{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4609, [1]: CNode_4608}
#  15: @mindcv_models_bit_Bottleneck_construct_4544:CNode_4618{[0]: ValueNode<Primitive> Return, [1]: CNode_4610}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4545 : 0x56198a7d26f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4545 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para208_x) {
  %1(CNode_4619) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4620) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4621) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4622, @✗mindcv_models_bit_Bottleneck_construct_4623)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4624) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4626) = call @↓mindcv_models_bit_Bottleneck_construct_4625(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4545:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4627, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4545:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4628, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4545:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4629, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4545:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4630, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4545:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4628, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4545:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4631, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4545:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4632, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4545:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4628, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4545:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4633, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4545:CNode_4619{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4545:CNode_4620{[0]: ValueNode<Primitive> Cond, [1]: CNode_4619, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4545:CNode_4621{[0]: ValueNode<Primitive> Switch, [1]: CNode_4620, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4622, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4623}
#  13: @mindcv_models_bit_Bottleneck_construct_4545:CNode_4624{[0]: CNode_4621}
#  14: @mindcv_models_bit_Bottleneck_construct_4545:CNode_4626{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4625, [1]: CNode_4624}
#  15: @mindcv_models_bit_Bottleneck_construct_4545:CNode_4634{[0]: ValueNode<Primitive> Return, [1]: CNode_4626}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4546 : 0x56198770fcb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4546 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para209_x) {
  %1(CNode_4635) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4636) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4637) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4638, @✗mindcv_models_bit_Bottleneck_construct_4639)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4640) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4642) = call @↓mindcv_models_bit_Bottleneck_construct_4641(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4546:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4643, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4546:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4644, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4546:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4645, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4546:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4646, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4546:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4644, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4546:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4647, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4546:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4648, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4546:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4644, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4546:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4649, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4546:CNode_4635{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4546:CNode_4636{[0]: ValueNode<Primitive> Cond, [1]: CNode_4635, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4546:CNode_4637{[0]: ValueNode<Primitive> Switch, [1]: CNode_4636, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4638, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4639}
#  13: @mindcv_models_bit_Bottleneck_construct_4546:CNode_4640{[0]: CNode_4637}
#  14: @mindcv_models_bit_Bottleneck_construct_4546:CNode_4642{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4641, [1]: CNode_4640}
#  15: @mindcv_models_bit_Bottleneck_construct_4546:CNode_4650{[0]: ValueNode<Primitive> Return, [1]: CNode_4642}


subgraph attr:
training : 0
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_4364 : 0x561a255095d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4364 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_4283](%para210_, %para211_) {
  %1(CNode_4367) = $(mindspore_nn_layer_container_SequentialCell_construct_4283):MakeTuple(@mindcv_models_bit_Bottleneck_construct_4651, @mindcv_models_bit_Bottleneck_construct_4652, @mindcv_models_bit_Bottleneck_construct_4653, @mindcv_models_bit_Bottleneck_construct_4654)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_4366) = $(mindspore_nn_layer_container_SequentialCell_construct_4283):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_4655) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para210_@CNode_4656, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_4657) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_4658, @↓mindspore_nn_layer_container_SequentialCell_construct_4659)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_4660) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_4364:CNode_4655{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.10, [1]: param_@CNode_4656, [2]: CNode_4366}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_4364:CNode_4657{[0]: ValueNode<Primitive> Switch, [1]: CNode_4655, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_4658, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_4659}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_4364:CNode_4660{[0]: CNode_4657}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_4364:CNode_4661{[0]: ValueNode<Primitive> Return, [1]: CNode_4660}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4651 : 0x561a220a0020
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4651 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para212_x) {
  %1(CNode_4662) = S_Prim_is_not(@mindspore_nn_layer_container_SequentialCell_construct_4663, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4664) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4665) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4666, @✗mindcv_models_bit_Bottleneck_construct_4667)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4668) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4670) = call @↓mindcv_models_bit_Bottleneck_construct_4669(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4651:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4671, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4651:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4672, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4651:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4673, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4651:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4674, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4651:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4672, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4651:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4675, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4651:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4676, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4651:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4672, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4651:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4677, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4651:CNode_4662{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4663, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4651:CNode_4664{[0]: ValueNode<Primitive> Cond, [1]: CNode_4662, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4651:CNode_4665{[0]: ValueNode<Primitive> Switch, [1]: CNode_4664, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4666, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4667}
#  13: @mindcv_models_bit_Bottleneck_construct_4651:CNode_4668{[0]: CNode_4665}
#  14: @mindcv_models_bit_Bottleneck_construct_4651:CNode_4670{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4669, [1]: CNode_4668}
#  15: @mindcv_models_bit_Bottleneck_construct_4651:CNode_4678{[0]: ValueNode<Primitive> Return, [1]: CNode_4670}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4652 : 0x561985d8dad0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4652 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para213_x) {
  %1(CNode_4679) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4680) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4681) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4682, @✗mindcv_models_bit_Bottleneck_construct_4683)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4684) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4686) = call @↓mindcv_models_bit_Bottleneck_construct_4685(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4652:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4687, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4652:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4688, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4652:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4689, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4652:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4690, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4652:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4688, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4652:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4691, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4652:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4692, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4652:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4688, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4652:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4693, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4652:CNode_4679{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4652:CNode_4680{[0]: ValueNode<Primitive> Cond, [1]: CNode_4679, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4652:CNode_4681{[0]: ValueNode<Primitive> Switch, [1]: CNode_4680, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4682, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4683}
#  13: @mindcv_models_bit_Bottleneck_construct_4652:CNode_4684{[0]: CNode_4681}
#  14: @mindcv_models_bit_Bottleneck_construct_4652:CNode_4686{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4685, [1]: CNode_4684}
#  15: @mindcv_models_bit_Bottleneck_construct_4652:CNode_4694{[0]: ValueNode<Primitive> Return, [1]: CNode_4686}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4653 : 0x561a193c64e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4653 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para214_x) {
  %1(CNode_4695) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4696) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4697) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4698, @✗mindcv_models_bit_Bottleneck_construct_4699)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4700) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4702) = call @↓mindcv_models_bit_Bottleneck_construct_4701(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4653:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4703, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4653:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4704, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4653:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4705, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4653:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4706, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4653:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4704, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4653:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4707, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4653:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4708, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4653:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4704, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4653:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4709, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4653:CNode_4695{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4653:CNode_4696{[0]: ValueNode<Primitive> Cond, [1]: CNode_4695, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4653:CNode_4697{[0]: ValueNode<Primitive> Switch, [1]: CNode_4696, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4698, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4699}
#  13: @mindcv_models_bit_Bottleneck_construct_4653:CNode_4700{[0]: CNode_4697}
#  14: @mindcv_models_bit_Bottleneck_construct_4653:CNode_4702{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4701, [1]: CNode_4700}
#  15: @mindcv_models_bit_Bottleneck_construct_4653:CNode_4710{[0]: ValueNode<Primitive> Return, [1]: CNode_4702}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4654 : 0x561a201fa6c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4654 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para215_x) {
  %1(CNode_4711) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4712) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4713) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4714, @✗mindcv_models_bit_Bottleneck_construct_4715)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4716) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4718) = call @↓mindcv_models_bit_Bottleneck_construct_4717(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4654:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4719, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4654:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4720, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4654:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4721, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4654:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4722, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4654:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4720, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4654:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4723, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4654:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4724, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4654:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4720, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4654:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4725, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4654:CNode_4711{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4654:CNode_4712{[0]: ValueNode<Primitive> Cond, [1]: CNode_4711, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4654:CNode_4713{[0]: ValueNode<Primitive> Switch, [1]: CNode_4712, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4714, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4715}
#  13: @mindcv_models_bit_Bottleneck_construct_4654:CNode_4716{[0]: CNode_4713}
#  14: @mindcv_models_bit_Bottleneck_construct_4654:CNode_4718{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4717, [1]: CNode_4716}
#  15: @mindcv_models_bit_Bottleneck_construct_4654:CNode_4726{[0]: ValueNode<Primitive> Return, [1]: CNode_4718}


subgraph attr:
training : 0
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_4369 : 0x561a17a343f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4369 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_4282](%para216_, %para217_) {
  %1(CNode_4372) = $(mindspore_nn_layer_container_SequentialCell_construct_4282):MakeTuple(@mindcv_models_bit_Bottleneck_construct_4727, @mindcv_models_bit_Bottleneck_construct_4728, @mindcv_models_bit_Bottleneck_construct_4729)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_4371) = $(mindspore_nn_layer_container_SequentialCell_construct_4282):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_4730) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para216_@CNode_4731, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_4732) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_4733, @↓mindspore_nn_layer_container_SequentialCell_construct_4734)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_4735) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_4369:CNode_4730{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.10, [1]: param_@CNode_4731, [2]: CNode_4371}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_4369:CNode_4732{[0]: ValueNode<Primitive> Switch, [1]: CNode_4730, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_4733, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_4734}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_4369:CNode_4735{[0]: CNode_4732}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_4369:CNode_4736{[0]: ValueNode<Primitive> Return, [1]: CNode_4735}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4727 : 0x561a210cf350
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4727 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para218_x) {
  %1(CNode_4737) = S_Prim_is_not(@mindspore_nn_layer_container_SequentialCell_construct_4738, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4739) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4740) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4741, @✗mindcv_models_bit_Bottleneck_construct_4742)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4743) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4745) = call @↓mindcv_models_bit_Bottleneck_construct_4744(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4727:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4746, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4727:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4747, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4727:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4748, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4727:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4749, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4727:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4747, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4727:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4750, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4727:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4751, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4727:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4747, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4727:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4752, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4727:CNode_4737{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4738, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4727:CNode_4739{[0]: ValueNode<Primitive> Cond, [1]: CNode_4737, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4727:CNode_4740{[0]: ValueNode<Primitive> Switch, [1]: CNode_4739, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4741, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4742}
#  13: @mindcv_models_bit_Bottleneck_construct_4727:CNode_4743{[0]: CNode_4740}
#  14: @mindcv_models_bit_Bottleneck_construct_4727:CNode_4745{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4744, [1]: CNode_4743}
#  15: @mindcv_models_bit_Bottleneck_construct_4727:CNode_4753{[0]: ValueNode<Primitive> Return, [1]: CNode_4745}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4728 : 0x561a1ee0d0f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4728 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para219_x) {
  %1(CNode_4754) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4755) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4756) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4757, @✗mindcv_models_bit_Bottleneck_construct_4758)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4759) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4761) = call @↓mindcv_models_bit_Bottleneck_construct_4760(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4728:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4762, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4728:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4763, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4728:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4764, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4728:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4765, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4728:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4763, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4728:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4766, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4728:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4767, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4728:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4763, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4728:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4768, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4728:CNode_4754{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4728:CNode_4755{[0]: ValueNode<Primitive> Cond, [1]: CNode_4754, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4728:CNode_4756{[0]: ValueNode<Primitive> Switch, [1]: CNode_4755, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4757, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4758}
#  13: @mindcv_models_bit_Bottleneck_construct_4728:CNode_4759{[0]: CNode_4756}
#  14: @mindcv_models_bit_Bottleneck_construct_4728:CNode_4761{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4760, [1]: CNode_4759}
#  15: @mindcv_models_bit_Bottleneck_construct_4728:CNode_4769{[0]: ValueNode<Primitive> Return, [1]: CNode_4761}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_Bottleneck_construct_4729 : 0x561a201e3720
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @mindcv_models_bit_Bottleneck_construct_4729 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para220_x) {
  %1(CNode_4770) = S_Prim_is_not(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %2(CNode_4771) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %3(CNode_4772) = Switch(%2, @✓mindcv_models_bit_Bottleneck_construct_4773, @✗mindcv_models_bit_Bottleneck_construct_4774)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %4(CNode_4775) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
  %5(CNode_4777) = call @↓mindcv_models_bit_Bottleneck_construct_4776(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @mindcv_models_bit_Bottleneck_construct_4729:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4778, [1]: param_identity}
#   2: @mindcv_models_bit_Bottleneck_construct_4729:residual{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4779, [1]: out}
#   3: @mindcv_models_bit_Bottleneck_construct_4729:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4780, [1]: residual}
#   4: @mindcv_models_bit_Bottleneck_construct_4729:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4781, [1]: out}
#   5: @mindcv_models_bit_Bottleneck_construct_4729:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4779, [1]: out}
#   6: @mindcv_models_bit_Bottleneck_construct_4729:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4782, [1]: out}
#   7: @mindcv_models_bit_Bottleneck_construct_4729:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_GroupNorm_construct_4783, [1]: out}
#   8: @mindcv_models_bit_Bottleneck_construct_4729:out{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_4779, [1]: out}
#   9: @mindcv_models_bit_Bottleneck_construct_4729:out{[0]: ValueNode<FuncGraph> mindcv_models_bit_StdConv2d_construct_4784, [1]: out}
#  10: @mindcv_models_bit_Bottleneck_construct_4729:CNode_4770{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#  11: @mindcv_models_bit_Bottleneck_construct_4729:CNode_4771{[0]: ValueNode<Primitive> Cond, [1]: CNode_4770, [2]: ValueNode<BoolImm> false}
#  12: @mindcv_models_bit_Bottleneck_construct_4729:CNode_4772{[0]: ValueNode<Primitive> Switch, [1]: CNode_4771, [2]: ValueNode<FuncGraph> ✓mindcv_models_bit_Bottleneck_construct_4773, [3]: ValueNode<FuncGraph> ✗mindcv_models_bit_Bottleneck_construct_4774}
#  13: @mindcv_models_bit_Bottleneck_construct_4729:CNode_4775{[0]: CNode_4772}
#  14: @mindcv_models_bit_Bottleneck_construct_4729:CNode_4777{[0]: ValueNode<FuncGraph> ↓mindcv_models_bit_Bottleneck_construct_4776, [1]: CNode_4775}
#  15: @mindcv_models_bit_Bottleneck_construct_4729:CNode_4785{[0]: ValueNode<Primitive> Return, [1]: CNode_4777}


subgraph attr:
training : 0
subgraph instance: ✓mindspore_nn_layer_pooling_MaxPool2d_construct_4378 : 0x561a1d333de0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✓mindspore_nn_layer_pooling_MaxPool2d_construct_4378 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool2d_construct_4289]() {
  %1(CNode_4786) = getattr(%para185_x, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:571/            x = x.unsqueeze(0)/
  %2(x) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:571/            x = x.unsqueeze(0)/
  %3(CNode_4788) = call @↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787(%2, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:244/        x = self.max_pool(x)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:571/            x = x.unsqueeze(0)/
}
# Order:
#   1: @✓mindspore_nn_layer_pooling_MaxPool2d_construct_4378:CNode_4786{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> unsqueeze}
#   2: @✓mindspore_nn_layer_pooling_MaxPool2d_construct_4378:x{[0]: CNode_4786, [1]: ValueNode<Int64Imm> 0}
#   3: @✓mindspore_nn_layer_pooling_MaxPool2d_construct_4378:CNode_4789{[0]: ValueNode<Primitive> Return, [1]: CNode_4788}
#   4: @✓mindspore_nn_layer_pooling_MaxPool2d_construct_4378:CNode_4788{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787, [1]: x, [2]: ValueNode<BoolImm> true}


subgraph attr:
training : 0
subgraph instance: ✗mindspore_nn_layer_pooling_MaxPool2d_construct_4379 : 0x561a18dc7390
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_pooling_MaxPool2d_construct_4379 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool2d_construct_4289]() {
  %1(CNode_4790) = call @↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787(%para185_x, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:244/        x = self.max_pool(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
}
# Order:
#   1: @✗mindspore_nn_layer_pooling_MaxPool2d_construct_4379:CNode_4791{[0]: ValueNode<Primitive> Return, [1]: CNode_4790}
#   2: @✗mindspore_nn_layer_pooling_MaxPool2d_construct_4379:CNode_4790{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787, [1]: param_x, [2]: ValueNode<BoolImm> false}


subgraph attr:
subgraph instance: fill_4395 : 0x561a1ed8d3e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:711/def fill(type, shape, value):  # pylint: disable=redefined-outer-name/
subgraph @fill_4395(%para221_type, %para222_shape, %para223_value) {
  %1(CNode_4792) = call @_get_cache_prim_4422(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:745/    return _get_cache_prim(P.FillV2)()(shape, value)/
  %2(CNode_4793) = %1()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:745/    return _get_cache_prim(P.FillV2)()(shape, value)/
  %3(value) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: I64, DstT: F32](%para223_value, %para221_type)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:744/    value = cast_(value, type)/
  %4(CNode_4794) = %2(%para222_shape, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:745/    return _get_cache_prim(P.FillV2)()(shape, value)/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/pad-ConstantPad2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:745/    return _get_cache_prim(P.FillV2)()(shape, value)/
}
# Order:
#   1: @fill_4395:value{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_value, [2]: param_type}
#   2: @fill_4395:CNode_4792{[0]: ValueNode<FuncGraph> _get_cache_prim_4422, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.FillV2'}
#   3: @fill_4395:CNode_4793{[0]: CNode_4792}
#   4: @fill_4395:CNode_4794{[0]: CNode_4793, [1]: param_shape, [2]: value}
#   5: @fill_4395:CNode_4795{[0]: ValueNode<Primitive> Return, [1]: CNode_4794}


subgraph attr:
subgraph instance: sqrt_4409 : 0x561a1e023f70
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @sqrt_4409(%para224_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para224_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @sqrt_4409:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @sqrt_4409:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
subgraph instance: ✓✗↓__main___FocalLoss_construct_4418 : 0x561a215a2ec0
# In file /tmp/ipykernel_280126/1697004305.py:11/
subgraph @✓✗↓__main___FocalLoss_construct_4418 parent: [subgraph @↓__main___FocalLoss_construct_4190]() {
  %1(CNode_4799) = call @sum_4798(%para169_фfocal_loss)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:39/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:39/
}
# Order:
#   1: @✓✗↓__main___FocalLoss_construct_4418:CNode_4799{[0]: ValueNode<FuncGraph> sum_4798, [1]: param_фfocal_loss}
#   2: @✓✗↓__main___FocalLoss_construct_4418:CNode_4800{[0]: ValueNode<Primitive> Return, [1]: CNode_4799}


subgraph attr:
subgraph instance: 2✗↓__main___FocalLoss_construct_4419 : 0x561a212bd650
# In file /tmp/ipykernel_280126/1697004305.py:11/
subgraph @2✗↓__main___FocalLoss_construct_4419 parent: [subgraph @↓__main___FocalLoss_construct_4190]() {
  Return(%para169_фfocal_loss)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:41/
}
# Order:
#   1: @2✗↓__main___FocalLoss_construct_4419:CNode_4801{[0]: ValueNode<Primitive> Return, [1]: param_фfocal_loss}


subgraph attr:
subgraph instance: _get_cache_prim_4422 : 0x56198e5e80a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:35/def _get_cache_prim(cls: Primitive) -> Primitive:/
subgraph @_get_cache_prim_4422(%para225_cls) {
  %1(CNode_4803) = call @✓_get_cache_prim_4802()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:88/    if _is_need_compile(_temp_func): # @jit.cond: True/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:88/    if _is_need_compile(_temp_func): # @jit.cond: True/
}
# Order:
#   1: @_get_cache_prim_4422:CNode_4803{[0]: ValueNode<FuncGraph> ✓_get_cache_prim_4802}
#   2: @_get_cache_prim_4422:CNode_4804{[0]: ValueNode<Primitive> Return, [1]: CNode_4803}


subgraph attr:
training : 0
subgraph instance: 2↓mindspore_nn_layer_basic_Dense_construct_4426 : 0x561a1de95660
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @2↓mindspore_nn_layer_basic_Dense_construct_4426 parent: [subgraph @✓↓mindspore_nn_layer_basic_Dense_construct_4310]() {
  %1(CNode_4806) = call @✗2↓mindspore_nn_layer_basic_Dense_construct_4805()
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:630/        if self.activation_flag:/
  Return(%1)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:630/        if self.activation_flag:/
}
# Order:
#   1: @2↓mindspore_nn_layer_basic_Dense_construct_4426:CNode_4806{[0]: ValueNode<FuncGraph> ✗2↓mindspore_nn_layer_basic_Dense_construct_4805}
#   2: @2↓mindspore_nn_layer_basic_Dense_construct_4426:CNode_4807{[0]: ValueNode<Primitive> Return, [1]: CNode_4806}


subgraph attr:
subgraph instance: pad_4440 : 0x5619a1396770
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @pad_4440(%para226_input_x, %para227_padding, %para228_mode, %para229_value) {
  %1(CNode_4808) = S_Prim_isinstance(%para226_input_x, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3392/    if not isinstance(input_x, Tensor):/
  %2(CNode_4809) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3392/    if not isinstance(input_x, Tensor):/
  %3(CNode_4810) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3392/    if not isinstance(input_x, Tensor):/
  %4(CNode_4811) = Switch(%3, @✓pad_4812, @✗pad_4813)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3392/    if not isinstance(input_x, Tensor):/
  %5(CNode_4814) = %4()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3392/    if not isinstance(input_x, Tensor):/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3392/    if not isinstance(input_x, Tensor):/
}
# Order:
#   1: @pad_4440:CNode_4808{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_input_x, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   2: @pad_4440:CNode_4809{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_4808}
#   3: @pad_4440:CNode_4810{[0]: ValueNode<Primitive> Cond, [1]: CNode_4809, [2]: ValueNode<BoolImm> false}
#   4: @pad_4440:CNode_4811{[0]: ValueNode<Primitive> Switch, [1]: CNode_4810, [2]: ValueNode<FuncGraph> ✓pad_4812, [3]: ValueNode<FuncGraph> ✗pad_4813}
#   5: @pad_4440:CNode_4814{[0]: CNode_4811}
#   6: @pad_4440:CNode_4815{[0]: ValueNode<Primitive> Return, [1]: CNode_4814}


subgraph attr:
after_block : 1
subgraph instance: ↓mean_4449 : 0x561a1bd15850
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8364/def mean(x, axis=None, keep_dims=False):/
subgraph @↓mean_4449 parent: [subgraph @mean_4338](%para230_) {
  %1(CNode_4816) = call @_get_cache_prim_4422(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8443/    return _get_cache_prim(P.ReduceMean)(keep_dims)(x, axis)/
  %2(CNode_4817) = %1(%para194_keep_dims)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8443/    return _get_cache_prim(P.ReduceMean)(keep_dims)(x, axis)/
  %3(CNode_4818) = %2(%para192_x, %para230_фaxis)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8443/    return _get_cache_prim(P.ReduceMean)(keep_dims)(x, axis)/
  Return(%3)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8443/    return _get_cache_prim(P.ReduceMean)(keep_dims)(x, axis)/
}
# Order:
#   1: @↓mean_4449:CNode_4816{[0]: ValueNode<FuncGraph> _get_cache_prim_4422, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.ReduceMean'}
#   2: @↓mean_4449:CNode_4817{[0]: CNode_4816, [1]: param_keep_dims}
#   3: @↓mean_4449:CNode_4818{[0]: CNode_4817, [1]: param_x, [2]: param_фaxis}
#   4: @↓mean_4449:CNode_4819{[0]: ValueNode<Primitive> Return, [1]: CNode_4818}


subgraph attr:
subgraph instance: ✓mean_4446 : 0x561a1c7a2a50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8364/def mean(x, axis=None, keep_dims=False):/
subgraph @✓mean_4446() {
  Return(())
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8442/        axis = ()/
}
# Order:
#   1: @✓mean_4446:CNode_4820{[0]: ValueNode<Primitive> Return, [1]: ValueNode<ValueTuple> ()}


subgraph attr:
subgraph instance: ✗mean_4447 : 0x561a1bfddf30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8364/def mean(x, axis=None, keep_dims=False):/
subgraph @✗mean_4447 parent: [subgraph @mean_4338]() {
  Return(%para193_axis)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:8441/    if axis is None:/
}
# Order:
#   1: @✗mean_4447:CNode_4821{[0]: ValueNode<Primitive> Return, [1]: param_axis}


subgraph attr:
subgraph instance: reshape_4457 : 0x561a21dec3e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1573/def reshape(input, shape):/
subgraph @reshape_4457(%para231_input, %para232_shape) {
  %1(CNode_4822) = S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para231_input, %para232_shape)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1607/    return reshape_(input, shape)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1607/    return reshape_(input, shape)/
}
# Order:
#   1: @reshape_4457:CNode_4822{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: param_input, [2]: param_shape}
#   2: @reshape_4457:CNode_4823{[0]: ValueNode<Primitive> Return, [1]: CNode_4822}


subgraph attr:
subgraph instance: sub_4458 : 0x56198bf88140
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:874/def sub(input, other):/
subgraph @sub_4458(%para233_input, %para234_other) {
  %1(CNode_4824) = S_Prim_Sub[output_names: ["output"], input_names: ["x", "y"]](%para233_input, %para234_other)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:919/    return tensor_sub(input, other)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:919/    return tensor_sub(input, other)/
}
# Order:
#   1: @sub_4458:CNode_4824{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sub, [1]: param_input, [2]: param_other}
#   2: @sub_4458:CNode_4825{[0]: ValueNode<Primitive> Return, [1]: CNode_4824}


subgraph attr:
subgraph instance: square_4461 : 0x56198bd854e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6081/def square(input):/
subgraph @square_4461(%para235_input) {
  %1(CNode_4826) = S_Prim_Square[output_names: ["output"], input_names: ["input_x"]](%para235_input)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6110/    return square_(input)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6110/    return square_(input)/
}
# Order:
#   1: @square_4461:CNode_4826{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Square, [1]: param_input}
#   2: @square_4461:CNode_4827{[0]: ValueNode<Primitive> Return, [1]: CNode_4826}


subgraph attr:
subgraph instance: div_4467 : 0x561a20fa6130
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @div_4467(%para236_input, %para237_other, %para238_rounding_mode) {
  %1(CNode_4828) = S_Prim_is_not(%para238_rounding_mode, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  %2(CNode_4829) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  %3(CNode_4830) = Switch(%2, @↰div_4831, @↱div_4832)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  %4(CNode_4833) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  %5(CNode_4834) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  %6(CNode_4835) = Switch(%5, @✓div_4836, @✗div_4837)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  %7(CNode_4838) = %6()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  Return(%7)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
}
# Order:
#   1: @div_4467:CNode_4828{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: param_rounding_mode, [2]: ValueNode<None> None}
#   2: @div_4467:CNode_4829{[0]: ValueNode<Primitive> Cond, [1]: CNode_4828, [2]: ValueNode<BoolImm> false}
#   3: @div_4467:CNode_4830{[0]: ValueNode<Primitive> Switch, [1]: CNode_4829, [2]: ValueNode<FuncGraph> ↰div_4831, [3]: ValueNode<FuncGraph> ↱div_4832}
#   4: @div_4467:CNode_4833{[0]: CNode_4830}
#   5: @div_4467:CNode_4834{[0]: ValueNode<Primitive> Cond, [1]: CNode_4833, [2]: ValueNode<BoolImm> false}
#   6: @div_4467:CNode_4835{[0]: ValueNode<Primitive> Switch, [1]: CNode_4834, [2]: ValueNode<FuncGraph> ✓div_4836, [3]: ValueNode<FuncGraph> ✗div_4837}
#   7: @div_4467:CNode_4838{[0]: CNode_4835}
#   8: @div_4467:CNode_4839{[0]: ValueNode<Primitive> Return, [1]: CNode_4838}


subgraph attr:
subgraph instance: add_4477 : 0x561a20b85d30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:308/def add(input, other):/
subgraph @add_4477(%para239_input, %para240_other) {
  %1(CNode_4840) = S_Prim_Add[output_names: ["output"], input_names: ["x", "y"]](%para239_input, %para240_other)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:364/    return tensor_add(input, other)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:364/    return tensor_add(input, other)/
}
# Order:
#   1: @add_4477:CNode_4840{[0]: ValueNode<PrimitivePy> Cast, [1]: param_other, [2]: ValueNode<Float> Float32}
#   2: @add_4477:CNode_4840{[0]: ValueNode<PrimitivePy> Cast, [1]: param_other, [2]: ValueNode<Float> Float32}
#   3: @add_4477:CNode_4840{[0]: ValueNode<PrimitivePy> Cast, [1]: param_other, [2]: ValueNode<Float> Float32}
#   4: @add_4477:CNode_4840{[0]: ValueNode<PrimitivePy> Cast, [1]: param_other, [2]: ValueNode<Float> Float32}
#   5: @add_4477:CNode_4840{[0]: ValueNode<PrimitivePy> Cast, [1]: param_other, [2]: ValueNode<Float> Float32}
#   6: @add_4477:CNode_4840{[0]: ValueNode<PrimitivePy> Cast, [1]: param_other, [2]: ValueNode<Float> Float32}
#   7: @add_4477:CNode_4840{[0]: ValueNode<PrimitivePy> Cast, [1]: param_other, [2]: ValueNode<Float> Float32}
#   8: @add_4477:CNode_4840{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Add, [1]: param_input, [2]: param_other}
#   9: @add_4477:CNode_4841{[0]: ValueNode<Primitive> Return, [1]: CNode_4840}


subgraph attr:
training : 0
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_4488 : 0x56199189dba0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_4488 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4354]() {
  %1(CNode_4486) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para197_@CNode_4486, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_4842) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_4357) = $(mindspore_nn_layer_container_SequentialCell_construct_4285):MakeTuple(@mindcv_models_bit_Bottleneck_construct_4482, @mindcv_models_bit_Bottleneck_construct_4483, @mindcv_models_bit_Bottleneck_construct_4484)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_4843) = call @ms_iter_4166(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para197_@CNode_4486)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para198_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_4844) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4354(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_4845) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_4488:CNode_4843{[0]: ValueNode<FuncGraph> ms_iter_4166, [1]: CNode_4357}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_4488:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_4843, [2]: param_@CNode_4486}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_4488:CNode_4486{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.11, [1]: param_@CNode_4486, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_4488:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_4488:CNode_4844{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4354, [1]: CNode_4486, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_4488:CNode_4846{[0]: ValueNode<Primitive> Return, [1]: CNode_4845}


subgraph attr:
training : 0
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_4489 : 0x561a1fe27f20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_4489 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4354]() {
  Return(%para198_фinput_data)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_4489:CNode_4847{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4499 : 0x561a1ecd80f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4499 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4482](%para241_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindspore_nn_layer_normalization_GroupNorm_construct_4501(%para199_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindspore_nn_layer_activation_ReLU_construct_4502(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindcv_models_bit_StdConv2d_construct_4503(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindspore_nn_layer_normalization_GroupNorm_construct_4504(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindspore_nn_layer_activation_ReLU_construct_4502(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindcv_models_bit_StdConv2d_construct_4505(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindspore_nn_layer_normalization_GroupNorm_construct_4506(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindspore_nn_layer_activation_ReLU_construct_4502(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindcv_models_bit_StdConv2d_construct_4507(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para241_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4499:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4499:CNode_4848{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4496 : 0x561a1ed05720
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4496 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4482]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindspore_nn_layer_normalization_GroupNorm_construct_4501(%para199_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4482):call @mindspore_nn_layer_activation_ReLU_construct_4502(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = call @mindspore_nn_layer_container_SequentialCell_construct_4493(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4496:identity{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4493, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4496:CNode_4849{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4497 : 0x561a1ed02aa0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4497 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4482]() {
  Return(%para199_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4497:CNode_4850{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4507 : 0x561a215d6380
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4507 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para242_x) {
  %1(CNode_4852) = call @L_mindcv_models_bit_StdConv2d_construct_4851(%para242_x, %para8_backbone.layer4.0.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (2048, 512, 1, 1), ref_key=:backbone.layer4.0.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4507:CNode_4852{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_4851, [1]: param_x, [2]: param_backbone.layer4.0.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4507:CNode_4853{[0]: ValueNode<Primitive> Return, [1]: CNode_4852}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_4493 : 0x561a18076850
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_4493 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para243_input_data) {
  %1(CNode_4855) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4854(I64(0), %para243_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_4493:CNode_4856{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_4857}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_4493:CNode_4855{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4854, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_4493:CNode_4858{[0]: ValueNode<Primitive> Return, [1]: CNode_4855}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4502 : 0x561a1f69bfa0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4502(%para244_x) {
  %1(CNode_4859) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para244_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4502:CNode_4859{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4502:CNode_4860{[0]: ValueNode<Primitive> Return, [1]: CNode_4859}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4506 : 0x561a16df9400
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4506 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para245_x) {
  %1(CNode_4861) = call @shape_4343(%para245_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4862) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4863) = getattr(%para245_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4864) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4865) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4866) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4867) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4868(%para245_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4869) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4506:CNode_4861{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4506:CNode_4862{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4861, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4506:CNode_4863{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4506:CNode_4864{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4506:CNode_4865{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4863, [2]: CNode_4864, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4506:output{[0]: ValueNode<FuncGraph> _cal_output_4868, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4506:CNode_4870{[0]: ValueNode<Primitive> Return, [1]: CNode_4869}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4505 : 0x561a21fe6cb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4505 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para246_x) {
  %1(CNode_4871) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para21_backbone.layer4.0.conv2.weight, %1)
      : (<Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:backbone.layer4.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_4872) = S_Prim_sub(%para21_backbone.layer4.0.conv2.weight, %2)
      : (<Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:backbone.layer4.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_4873) = getattr(%para21_backbone.layer4.0.conv2.weight, "var")
      : (<Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:backbone.layer4.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_4874) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_4875) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_4876) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_4877) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_4878) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_4879) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_4880) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(512), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para246_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4871{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_4505:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer4.0.conv2.weight, [2]: CNode_4871}
#   3: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4873{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer4.0.conv2.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4874{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4875{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4874}
#   6: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4876{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4877{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4878{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_4876, [2]: CNode_4877}
#   9: @mindcv_models_bit_StdConv2d_construct_4505:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.4881, [1]: CNode_4873, [2]: CNode_4875, [3]: CNode_4878}
#  10: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4872{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer4.0.conv2.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4879{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4880{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_4879}
#  13: @mindcv_models_bit_StdConv2d_construct_4505:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_4872, [2]: CNode_4880}
#  14: @mindcv_models_bit_StdConv2d_construct_4505:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_4505:CNode_4882{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4501 : 0x561a217e6e70
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4501 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para247_x) {
  %1(CNode_4883) = call @shape_4343(%para247_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4884) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4885) = getattr(%para247_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4886) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4887) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4888) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4889) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4890(%para247_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4891) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4501:CNode_4883{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4501:CNode_4884{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4883, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4501:CNode_4885{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4501:CNode_4886{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4501:CNode_4887{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4885, [2]: CNode_4886, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4501:output{[0]: ValueNode<FuncGraph> _cal_output_4890, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4501:CNode_4892{[0]: ValueNode<Primitive> Return, [1]: CNode_4891}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4504 : 0x56198ec40f70
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4504 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para248_x) {
  %1(CNode_4893) = call @shape_4343(%para248_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4894) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4895) = getattr(%para248_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4896) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4897) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4898) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4899) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4900(%para248_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4901) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4504:CNode_4893{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4504:CNode_4894{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4893, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4504:CNode_4895{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4504:CNode_4896{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4504:CNode_4897{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4895, [2]: CNode_4896, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4504:output{[0]: ValueNode<FuncGraph> _cal_output_4900, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4504:CNode_4902{[0]: ValueNode<Primitive> Return, [1]: CNode_4901}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4503 : 0x561a14a78660
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4503 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para249_x) {
  %1(CNode_4903) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para38_backbone.layer4.0.conv1.weight, %1)
      : (<Ref[Tensor[Float32]], (512, 1024, 1, 1), ref_key=:backbone.layer4.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_4904) = S_Prim_sub(%para38_backbone.layer4.0.conv1.weight, %2)
      : (<Ref[Tensor[Float32]], (512, 1024, 1, 1), ref_key=:backbone.layer4.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_4905) = getattr(%para38_backbone.layer4.0.conv1.weight, "var")
      : (<Ref[Tensor[Float32]], (512, 1024, 1, 1), ref_key=:backbone.layer4.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_4906) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_4907) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_4908) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_4909) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_4910) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_4911) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_4912) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(512), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para249_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4903{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_4503:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer4.0.conv1.weight, [2]: CNode_4903}
#   3: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4905{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer4.0.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4906{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4907{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_4906}
#   6: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4908{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4909{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4910{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_4908, [2]: CNode_4909}
#   9: @mindcv_models_bit_StdConv2d_construct_4503:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.4913, [1]: CNode_4905, [2]: CNode_4907, [3]: CNode_4910}
#  10: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4904{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer4.0.conv1.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4911{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4912{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_4911}
#  13: @mindcv_models_bit_StdConv2d_construct_4503:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_4904, [2]: CNode_4912}
#  14: @mindcv_models_bit_StdConv2d_construct_4503:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_4503:CNode_4914{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4515 : 0x561a18742b50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4515 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4483](%para250_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindspore_nn_layer_normalization_GroupNorm_construct_4517(%para200_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindspore_nn_layer_activation_ReLU_construct_4518(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindcv_models_bit_StdConv2d_construct_4519(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindspore_nn_layer_normalization_GroupNorm_construct_4520(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindspore_nn_layer_activation_ReLU_construct_4518(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindcv_models_bit_StdConv2d_construct_4521(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindspore_nn_layer_normalization_GroupNorm_construct_4522(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindspore_nn_layer_activation_ReLU_construct_4518(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindcv_models_bit_StdConv2d_construct_4523(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para250_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4515:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4515:CNode_4915{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4512 : 0x5619892843f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4512 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4483]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindspore_nn_layer_normalization_GroupNorm_construct_4517(%para200_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4483):call @mindspore_nn_layer_activation_ReLU_construct_4518(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4512:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4512:CNode_4916{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4513 : 0x561987501230
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4513 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4483]() {
  Return(%para200_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4513:CNode_4917{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4523 : 0x56198b7ac070
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4523 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para251_x) {
  %1(CNode_4918) = call @L_mindcv_models_bit_StdConv2d_construct_4851(%para251_x, %para9_backbone.layer4.1.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (2048, 512, 1, 1), ref_key=:backbone.layer4.1.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4523:CNode_4918{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_4851, [1]: param_x, [2]: param_backbone.layer4.1.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4523:CNode_4919{[0]: ValueNode<Primitive> Return, [1]: CNode_4918}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4518 : 0x561a172a70d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4518(%para252_x) {
  %1(CNode_4920) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para252_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4518:CNode_4920{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4518:CNode_4921{[0]: ValueNode<Primitive> Return, [1]: CNode_4920}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4522 : 0x561a1d194d60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4522 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para253_x) {
  %1(CNode_4922) = call @shape_4343(%para253_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4923) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4924) = getattr(%para253_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4925) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4926) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4927) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4928) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4929(%para253_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4930) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4522:CNode_4922{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4522:CNode_4923{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4922, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4522:CNode_4924{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4522:CNode_4925{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4522:CNode_4926{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4924, [2]: CNode_4925, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4522:output{[0]: ValueNode<FuncGraph> _cal_output_4929, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4522:CNode_4931{[0]: ValueNode<Primitive> Return, [1]: CNode_4930}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4521 : 0x561a1c5b95d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4521 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para254_x) {
  %1(CNode_4933) = call @L_mindcv_models_bit_StdConv2d_construct_4932(%para254_x, %para22_backbone.layer4.1.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:backbone.layer4.1.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4521:CNode_4933{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_4932, [1]: param_x, [2]: param_backbone.layer4.1.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4521:CNode_4934{[0]: ValueNode<Primitive> Return, [1]: CNode_4933}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4517 : 0x561a25a28080
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4517 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para255_x) {
  %1(CNode_4935) = call @shape_4343(%para255_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4936) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4937) = getattr(%para255_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4938) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4939) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4940) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4941) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4942(%para255_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4943) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4517:CNode_4935{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4517:CNode_4936{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4935, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4517:CNode_4937{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4517:CNode_4938{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4517:CNode_4939{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4937, [2]: CNode_4938, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4517:output{[0]: ValueNode<FuncGraph> _cal_output_4942, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4517:CNode_4944{[0]: ValueNode<Primitive> Return, [1]: CNode_4943}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4520 : 0x56198aba9bb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4520 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para256_x) {
  %1(CNode_4945) = call @shape_4343(%para256_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4946) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4947) = getattr(%para256_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4948) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4949) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4950) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4951) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4952(%para256_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4953) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4520:CNode_4945{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4520:CNode_4946{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4945, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4520:CNode_4947{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4520:CNode_4948{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4520:CNode_4949{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4947, [2]: CNode_4948, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4520:output{[0]: ValueNode<FuncGraph> _cal_output_4952, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4520:CNode_4954{[0]: ValueNode<Primitive> Return, [1]: CNode_4953}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4519 : 0x561a143e6a60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4519 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para257_x) {
  %1(CNode_4956) = call @L_mindcv_models_bit_StdConv2d_construct_4955(%para257_x, %para40_backbone.layer4.1.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 2048, 1, 1), ref_key=:backbone.layer4.1.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4519:CNode_4956{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_4955, [1]: param_x, [2]: param_backbone.layer4.1.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4519:CNode_4957{[0]: ValueNode<Primitive> Return, [1]: CNode_4956}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4531 : 0x561a1f210bc0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4531 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4484](%para258_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindspore_nn_layer_normalization_GroupNorm_construct_4533(%para201_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindspore_nn_layer_activation_ReLU_construct_4534(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindcv_models_bit_StdConv2d_construct_4535(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindspore_nn_layer_normalization_GroupNorm_construct_4536(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindspore_nn_layer_activation_ReLU_construct_4534(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindcv_models_bit_StdConv2d_construct_4537(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindspore_nn_layer_normalization_GroupNorm_construct_4538(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindspore_nn_layer_activation_ReLU_construct_4534(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindcv_models_bit_StdConv2d_construct_4539(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para258_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4531:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4531:CNode_4958{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4528 : 0x56198bad3f40
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4528 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4484]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindspore_nn_layer_normalization_GroupNorm_construct_4533(%para201_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4484):call @mindspore_nn_layer_activation_ReLU_construct_4534(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4528:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4528:CNode_4959{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4529 : 0x561a1dd62790
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4529 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4484]() {
  Return(%para201_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4529:CNode_4960{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4539 : 0x561a17edbec0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4539 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para259_x) {
  %1(CNode_4961) = call @L_mindcv_models_bit_StdConv2d_construct_4851(%para259_x, %para10_backbone.layer4.2.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (2048, 512, 1, 1), ref_key=:backbone.layer4.2.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4539:CNode_4961{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_4851, [1]: param_x, [2]: param_backbone.layer4.2.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4539:CNode_4962{[0]: ValueNode<Primitive> Return, [1]: CNode_4961}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4534 : 0x5619883faf60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4534(%para260_x) {
  %1(CNode_4963) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para260_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4534:CNode_4963{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4534:CNode_4964{[0]: ValueNode<Primitive> Return, [1]: CNode_4963}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4538 : 0x5619938399c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4538 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para261_x) {
  %1(CNode_4965) = call @shape_4343(%para261_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4966) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4967) = getattr(%para261_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4968) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4969) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4970) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4971) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4972(%para261_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4973) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4538:CNode_4965{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4538:CNode_4966{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4965, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4538:CNode_4967{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4538:CNode_4968{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4538:CNode_4969{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4967, [2]: CNode_4968, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4538:output{[0]: ValueNode<FuncGraph> _cal_output_4972, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4538:CNode_4974{[0]: ValueNode<Primitive> Return, [1]: CNode_4973}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4537 : 0x561a26276140
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4537 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para262_x) {
  %1(CNode_4975) = call @L_mindcv_models_bit_StdConv2d_construct_4932(%para262_x, %para23_backbone.layer4.2.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:backbone.layer4.2.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4537:CNode_4975{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_4932, [1]: param_x, [2]: param_backbone.layer4.2.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4537:CNode_4976{[0]: ValueNode<Primitive> Return, [1]: CNode_4975}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4533 : 0x561a268cb9b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4533 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para263_x) {
  %1(CNode_4977) = call @shape_4343(%para263_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4978) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4979) = getattr(%para263_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4980) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4981) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4982) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4983) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4984(%para263_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4985) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4533:CNode_4977{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4533:CNode_4978{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4977, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4533:CNode_4979{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4533:CNode_4980{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4533:CNode_4981{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4979, [2]: CNode_4980, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4533:output{[0]: ValueNode<FuncGraph> _cal_output_4984, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4533:CNode_4986{[0]: ValueNode<Primitive> Return, [1]: CNode_4985}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4536 : 0x561a1c2503a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4536 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para264_x) {
  %1(CNode_4987) = call @shape_4343(%para264_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_4988) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_4989) = getattr(%para264_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_4990) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_4991) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_4992) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_4993) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_4994(%para264_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_4995) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4536:CNode_4987{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4536:CNode_4988{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_4987, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4536:CNode_4989{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4536:CNode_4990{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4536:CNode_4991{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_4989, [2]: CNode_4990, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4536:output{[0]: ValueNode<FuncGraph> _cal_output_4994, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4536:CNode_4996{[0]: ValueNode<Primitive> Return, [1]: CNode_4995}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4535 : 0x561a14e0c360
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4535 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para265_x) {
  %1(CNode_4997) = call @L_mindcv_models_bit_StdConv2d_construct_4955(%para265_x, %para42_backbone.layer4.2.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 2048, 1, 1), ref_key=:backbone.layer4.2.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4535:CNode_4997{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_4955, [1]: param_x, [2]: param_backbone.layer4.2.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4535:CNode_4998{[0]: ValueNode<Primitive> Return, [1]: CNode_4997}


subgraph attr:
training : 0
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_4550 : 0x561990030e90
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_4550 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4359]() {
  %1(CNode_4548) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para202_@CNode_4548, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_4999) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_4362) = $(mindspore_nn_layer_container_SequentialCell_construct_4284):MakeTuple(@mindcv_models_bit_Bottleneck_construct_4541, @mindcv_models_bit_Bottleneck_construct_4542, @mindcv_models_bit_Bottleneck_construct_4543, @mindcv_models_bit_Bottleneck_construct_4544, @mindcv_models_bit_Bottleneck_construct_4545, @mindcv_models_bit_Bottleneck_construct_4546)
      : (<null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_5000) = call @ms_iter_4166(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para202_@CNode_4548)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para203_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_5001) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4359(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_5002) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_4550:CNode_5000{[0]: ValueNode<FuncGraph> ms_iter_4166, [1]: CNode_4362}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_4550:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5000, [2]: param_@CNode_4548}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_4550:CNode_4548{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.11, [1]: param_@CNode_4548, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_4550:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_4550:CNode_5001{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4359, [1]: CNode_4548, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_4550:CNode_5003{[0]: ValueNode<Primitive> Return, [1]: CNode_5002}


subgraph attr:
training : 0
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_4551 : 0x56198823b5e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_4551 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4359]() {
  Return(%para203_фinput_data)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_4551:CNode_5004{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4561 : 0x5619a1afd440
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4561 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4541](%para266_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindspore_nn_layer_normalization_GroupNorm_construct_4563(%para204_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindspore_nn_layer_activation_ReLU_construct_4564(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindcv_models_bit_StdConv2d_construct_4565(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindspore_nn_layer_normalization_GroupNorm_construct_4566(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindspore_nn_layer_activation_ReLU_construct_4564(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindcv_models_bit_StdConv2d_construct_4567(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindspore_nn_layer_normalization_GroupNorm_construct_4568(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindspore_nn_layer_activation_ReLU_construct_4564(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindcv_models_bit_StdConv2d_construct_4569(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para266_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4561:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4561:CNode_5005{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4558 : 0x561988279a80
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4558 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4541]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindspore_nn_layer_normalization_GroupNorm_construct_4563(%para204_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4541):call @mindspore_nn_layer_activation_ReLU_construct_4564(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = call @mindspore_nn_layer_container_SequentialCell_construct_4555(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4558:identity{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4555, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4558:CNode_5006{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4559 : 0x561a1c96a870
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4559 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4541]() {
  Return(%para204_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4559:CNode_5007{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4569 : 0x561985cfe240
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4569 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para267_x) {
  %1(CNode_5009) = call @L_mindcv_models_bit_StdConv2d_construct_5008(%para267_x, %para11_backbone.layer3.0.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.0.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4569:CNode_5009{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5008, [1]: param_x, [2]: param_backbone.layer3.0.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4569:CNode_5010{[0]: ValueNode<Primitive> Return, [1]: CNode_5009}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_4555 : 0x56198868b0c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_4555 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para268_input_data) {
  %1(CNode_5012) = call @↵mindspore_nn_layer_container_SequentialCell_construct_5011(I64(0), %para268_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_4555:CNode_5013{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_5014}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_4555:CNode_5012{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_5011, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_4555:CNode_5015{[0]: ValueNode<Primitive> Return, [1]: CNode_5012}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4564 : 0x56198c04adf0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4564(%para269_x) {
  %1(CNode_5016) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para269_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4564:CNode_5016{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4564:CNode_5017{[0]: ValueNode<Primitive> Return, [1]: CNode_5016}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4568 : 0x561a26055290
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4568 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para270_x) {
  %1(CNode_5018) = call @shape_4343(%para270_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5019) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5020) = getattr(%para270_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5021) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5022) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5023) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5024) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5025(%para270_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5026) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4568:CNode_5018{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4568:CNode_5019{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5018, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4568:CNode_5020{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4568:CNode_5021{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4568:CNode_5022{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5020, [2]: CNode_5021, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4568:output{[0]: ValueNode<FuncGraph> _cal_output_5025, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4568:CNode_5027{[0]: ValueNode<Primitive> Return, [1]: CNode_5026}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4567 : 0x561a19315a40
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4567 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para271_x) {
  %1(CNode_5028) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para27_backbone.layer3.0.conv2.weight, %1)
      : (<Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5029) = S_Prim_sub(%para27_backbone.layer3.0.conv2.weight, %2)
      : (<Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5030) = getattr(%para27_backbone.layer3.0.conv2.weight, "var")
      : (<Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5031) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5032) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5033) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5034) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5035) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5036) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5037) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(256), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para271_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5028{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_4567:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer3.0.conv2.weight, [2]: CNode_5028}
#   3: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5030{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer3.0.conv2.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5031{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5032{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5031}
#   6: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5033{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5034{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5035{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5033, [2]: CNode_5034}
#   9: @mindcv_models_bit_StdConv2d_construct_4567:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5038, [1]: CNode_5030, [2]: CNode_5032, [3]: CNode_5035}
#  10: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5029{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer3.0.conv2.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5036{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5037{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_5036}
#  13: @mindcv_models_bit_StdConv2d_construct_4567:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5029, [2]: CNode_5037}
#  14: @mindcv_models_bit_StdConv2d_construct_4567:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_4567:CNode_5039{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4563 : 0x561a1caeb740
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4563 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para272_x) {
  %1(CNode_5040) = call @shape_4343(%para272_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5041) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5042) = getattr(%para272_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5043) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5044) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5045) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5046) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5047(%para272_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5048) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4563:CNode_5040{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4563:CNode_5041{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5040, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4563:CNode_5042{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4563:CNode_5043{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4563:CNode_5044{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5042, [2]: CNode_5043, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4563:output{[0]: ValueNode<FuncGraph> _cal_output_5047, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4563:CNode_5049{[0]: ValueNode<Primitive> Return, [1]: CNode_5048}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4566 : 0x561a14c43780
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4566 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para273_x) {
  %1(CNode_5050) = call @shape_4343(%para273_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5051) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5052) = getattr(%para273_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5053) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5054) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5055) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5056) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5057(%para273_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5058) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4566:CNode_5050{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4566:CNode_5051{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5050, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4566:CNode_5052{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4566:CNode_5053{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4566:CNode_5054{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5052, [2]: CNode_5053, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4566:output{[0]: ValueNode<FuncGraph> _cal_output_5057, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4566:CNode_5059{[0]: ValueNode<Primitive> Return, [1]: CNode_5058}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4565 : 0x561984192690
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4565 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para274_x) {
  %1(CNode_5060) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para53_backbone.layer3.0.conv1.weight, %1)
      : (<Ref[Tensor[Float32]], (256, 512, 1, 1), ref_key=:backbone.layer3.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5061) = S_Prim_sub(%para53_backbone.layer3.0.conv1.weight, %2)
      : (<Ref[Tensor[Float32]], (256, 512, 1, 1), ref_key=:backbone.layer3.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5062) = getattr(%para53_backbone.layer3.0.conv1.weight, "var")
      : (<Ref[Tensor[Float32]], (256, 512, 1, 1), ref_key=:backbone.layer3.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5063) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5064) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5065) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5066) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5067) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5068) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5069) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(256), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para274_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5060{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_4565:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer3.0.conv1.weight, [2]: CNode_5060}
#   3: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5062{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer3.0.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5063{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5064{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5063}
#   6: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5065{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5066{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5067{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5065, [2]: CNode_5066}
#   9: @mindcv_models_bit_StdConv2d_construct_4565:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5070, [1]: CNode_5062, [2]: CNode_5064, [3]: CNode_5067}
#  10: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5061{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer3.0.conv1.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5068{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5069{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_5068}
#  13: @mindcv_models_bit_StdConv2d_construct_4565:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5061, [2]: CNode_5069}
#  14: @mindcv_models_bit_StdConv2d_construct_4565:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_4565:CNode_5071{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4577 : 0x561989478230
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4577 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4542](%para275_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindspore_nn_layer_normalization_GroupNorm_construct_4579(%para205_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindspore_nn_layer_activation_ReLU_construct_4580(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindcv_models_bit_StdConv2d_construct_4581(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindspore_nn_layer_normalization_GroupNorm_construct_4582(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindspore_nn_layer_activation_ReLU_construct_4580(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindcv_models_bit_StdConv2d_construct_4583(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindspore_nn_layer_normalization_GroupNorm_construct_4584(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindspore_nn_layer_activation_ReLU_construct_4580(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindcv_models_bit_StdConv2d_construct_4585(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para275_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4577:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4577:CNode_5072{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4574 : 0x561991417c20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4574 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4542]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindspore_nn_layer_normalization_GroupNorm_construct_4579(%para205_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4542):call @mindspore_nn_layer_activation_ReLU_construct_4580(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4574:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4574:CNode_5073{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4575 : 0x561a1fabb580
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4575 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4542]() {
  Return(%para205_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4575:CNode_5074{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4585 : 0x561a1d252410
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4585 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para276_x) {
  %1(CNode_5075) = call @L_mindcv_models_bit_StdConv2d_construct_5008(%para276_x, %para12_backbone.layer3.1.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.1.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4585:CNode_5075{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5008, [1]: param_x, [2]: param_backbone.layer3.1.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4585:CNode_5076{[0]: ValueNode<Primitive> Return, [1]: CNode_5075}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4580 : 0x561a1d25a3c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4580(%para277_x) {
  %1(CNode_5077) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para277_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4580:CNode_5077{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4580:CNode_5078{[0]: ValueNode<Primitive> Return, [1]: CNode_5077}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4584 : 0x561a25e96950
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4584 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para278_x) {
  %1(CNode_5079) = call @shape_4343(%para278_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5080) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5081) = getattr(%para278_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5082) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5083) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5084) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5085) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5086(%para278_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5087) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4584:CNode_5079{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4584:CNode_5080{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5079, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4584:CNode_5081{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4584:CNode_5082{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4584:CNode_5083{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5081, [2]: CNode_5082, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4584:output{[0]: ValueNode<FuncGraph> _cal_output_5086, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4584:CNode_5088{[0]: ValueNode<Primitive> Return, [1]: CNode_5087}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4583 : 0x561a1c0bcce0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4583 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para279_x) {
  %1(CNode_5090) = call @L_mindcv_models_bit_StdConv2d_construct_5089(%para279_x, %para28_backbone.layer3.1.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.1.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4583:CNode_5090{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5089, [1]: param_x, [2]: param_backbone.layer3.1.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4583:CNode_5091{[0]: ValueNode<Primitive> Return, [1]: CNode_5090}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4579 : 0x561984a4b8f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4579 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para280_x) {
  %1(CNode_5092) = call @shape_4343(%para280_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5093) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5094) = getattr(%para280_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5095) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5096) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5097) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5098) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5099(%para280_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5100) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4579:CNode_5092{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4579:CNode_5093{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5092, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4579:CNode_5094{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4579:CNode_5095{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4579:CNode_5096{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5094, [2]: CNode_5095, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4579:output{[0]: ValueNode<FuncGraph> _cal_output_5099, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4579:CNode_5101{[0]: ValueNode<Primitive> Return, [1]: CNode_5100}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4582 : 0x561a1347c6f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4582 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para281_x) {
  %1(CNode_5102) = call @shape_4343(%para281_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5103) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5104) = getattr(%para281_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5105) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5106) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5107) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5108) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5109(%para281_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5110) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4582:CNode_5102{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4582:CNode_5103{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5102, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4582:CNode_5104{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4582:CNode_5105{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4582:CNode_5106{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5104, [2]: CNode_5105, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4582:output{[0]: ValueNode<FuncGraph> _cal_output_5109, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4582:CNode_5111{[0]: ValueNode<Primitive> Return, [1]: CNode_5110}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4581 : 0x561a1d559df0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4581 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para282_x) {
  %1(CNode_5113) = call @L_mindcv_models_bit_StdConv2d_construct_5112(%para282_x, %para55_backbone.layer3.1.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.1.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4581:CNode_5113{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5112, [1]: param_x, [2]: param_backbone.layer3.1.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4581:CNode_5114{[0]: ValueNode<Primitive> Return, [1]: CNode_5113}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4593 : 0x561a19711b30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4593 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4543](%para283_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindspore_nn_layer_normalization_GroupNorm_construct_4595(%para206_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindspore_nn_layer_activation_ReLU_construct_4596(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindcv_models_bit_StdConv2d_construct_4597(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindspore_nn_layer_normalization_GroupNorm_construct_4598(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindspore_nn_layer_activation_ReLU_construct_4596(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindcv_models_bit_StdConv2d_construct_4599(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindspore_nn_layer_normalization_GroupNorm_construct_4600(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindspore_nn_layer_activation_ReLU_construct_4596(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindcv_models_bit_StdConv2d_construct_4601(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para283_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4593:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4593:CNode_5115{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4590 : 0x561991993c90
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4590 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4543]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindspore_nn_layer_normalization_GroupNorm_construct_4595(%para206_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4543):call @mindspore_nn_layer_activation_ReLU_construct_4596(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4590:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4590:CNode_5116{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4591 : 0x561a14ec1780
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4591 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4543]() {
  Return(%para206_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4591:CNode_5117{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4601 : 0x561993b8e480
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4601 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para284_x) {
  %1(CNode_5118) = call @L_mindcv_models_bit_StdConv2d_construct_5008(%para284_x, %para13_backbone.layer3.2.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.2.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4601:CNode_5118{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5008, [1]: param_x, [2]: param_backbone.layer3.2.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4601:CNode_5119{[0]: ValueNode<Primitive> Return, [1]: CNode_5118}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4596 : 0x5619881f1160
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4596(%para285_x) {
  %1(CNode_5120) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para285_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4596:CNode_5120{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4596:CNode_5121{[0]: ValueNode<Primitive> Return, [1]: CNode_5120}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4600 : 0x561a261468d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4600 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para286_x) {
  %1(CNode_5122) = call @shape_4343(%para286_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5123) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5124) = getattr(%para286_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5125) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5126) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5127) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5128) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5129(%para286_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5130) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4600:CNode_5122{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4600:CNode_5123{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5122, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4600:CNode_5124{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4600:CNode_5125{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4600:CNode_5126{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5124, [2]: CNode_5125, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4600:output{[0]: ValueNode<FuncGraph> _cal_output_5129, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4600:CNode_5131{[0]: ValueNode<Primitive> Return, [1]: CNode_5130}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4599 : 0x561a219a4dd0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4599 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para287_x) {
  %1(CNode_5132) = call @L_mindcv_models_bit_StdConv2d_construct_5089(%para287_x, %para29_backbone.layer3.2.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.2.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4599:CNode_5132{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5089, [1]: param_x, [2]: param_backbone.layer3.2.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4599:CNode_5133{[0]: ValueNode<Primitive> Return, [1]: CNode_5132}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4595 : 0x5619a14483d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4595 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para288_x) {
  %1(CNode_5134) = call @shape_4343(%para288_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5135) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5136) = getattr(%para288_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5137) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5138) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5139) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5140) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5141(%para288_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5142) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4595:CNode_5134{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4595:CNode_5135{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5134, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4595:CNode_5136{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4595:CNode_5137{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4595:CNode_5138{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5136, [2]: CNode_5137, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4595:output{[0]: ValueNode<FuncGraph> _cal_output_5141, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4595:CNode_5143{[0]: ValueNode<Primitive> Return, [1]: CNode_5142}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4598 : 0x56198e459b30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4598 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para289_x) {
  %1(CNode_5144) = call @shape_4343(%para289_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5145) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5146) = getattr(%para289_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5147) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5148) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5149) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5150) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5151(%para289_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5152) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4598:CNode_5144{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4598:CNode_5145{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5144, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4598:CNode_5146{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4598:CNode_5147{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4598:CNode_5148{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5146, [2]: CNode_5147, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4598:output{[0]: ValueNode<FuncGraph> _cal_output_5151, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4598:CNode_5153{[0]: ValueNode<Primitive> Return, [1]: CNode_5152}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4597 : 0x56198a94aad0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4597 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para290_x) {
  %1(CNode_5154) = call @L_mindcv_models_bit_StdConv2d_construct_5112(%para290_x, %para57_backbone.layer3.2.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.2.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4597:CNode_5154{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5112, [1]: param_x, [2]: param_backbone.layer3.2.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4597:CNode_5155{[0]: ValueNode<Primitive> Return, [1]: CNode_5154}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4609 : 0x561a1de2c1c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4609 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4544](%para291_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindspore_nn_layer_normalization_GroupNorm_construct_4611(%para207_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindspore_nn_layer_activation_ReLU_construct_4612(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindcv_models_bit_StdConv2d_construct_4613(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindspore_nn_layer_normalization_GroupNorm_construct_4614(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindspore_nn_layer_activation_ReLU_construct_4612(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindcv_models_bit_StdConv2d_construct_4615(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindspore_nn_layer_normalization_GroupNorm_construct_4616(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindspore_nn_layer_activation_ReLU_construct_4612(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindcv_models_bit_StdConv2d_construct_4617(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para291_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4609:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4609:CNode_5156{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4606 : 0x561a20995720
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4606 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4544]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindspore_nn_layer_normalization_GroupNorm_construct_4611(%para207_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4544):call @mindspore_nn_layer_activation_ReLU_construct_4612(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4606:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4606:CNode_5157{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4607 : 0x56199141f070
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4607 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4544]() {
  Return(%para207_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4607:CNode_5158{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4617 : 0x561987d47070
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4617 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para292_x) {
  %1(CNode_5159) = call @L_mindcv_models_bit_StdConv2d_construct_5008(%para292_x, %para14_backbone.layer3.3.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.3.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4617:CNode_5159{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5008, [1]: param_x, [2]: param_backbone.layer3.3.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4617:CNode_5160{[0]: ValueNode<Primitive> Return, [1]: CNode_5159}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4612 : 0x56198815c380
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4612(%para293_x) {
  %1(CNode_5161) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para293_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4612:CNode_5161{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4612:CNode_5162{[0]: ValueNode<Primitive> Return, [1]: CNode_5161}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4616 : 0x561a267d2540
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4616 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para294_x) {
  %1(CNode_5163) = call @shape_4343(%para294_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5164) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5165) = getattr(%para294_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5166) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5167) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5168) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5169) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5170(%para294_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5171) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4616:CNode_5163{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4616:CNode_5164{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5163, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4616:CNode_5165{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4616:CNode_5166{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4616:CNode_5167{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5165, [2]: CNode_5166, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4616:output{[0]: ValueNode<FuncGraph> _cal_output_5170, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4616:CNode_5172{[0]: ValueNode<Primitive> Return, [1]: CNode_5171}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4615 : 0x561988f3d080
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4615 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para295_x) {
  %1(CNode_5173) = call @L_mindcv_models_bit_StdConv2d_construct_5089(%para295_x, %para30_backbone.layer3.3.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.3.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4615:CNode_5173{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5089, [1]: param_x, [2]: param_backbone.layer3.3.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4615:CNode_5174{[0]: ValueNode<Primitive> Return, [1]: CNode_5173}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4611 : 0x561a1bddc760
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4611 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para296_x) {
  %1(CNode_5175) = call @shape_4343(%para296_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5176) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5177) = getattr(%para296_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5178) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5179) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5180) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5181) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5182(%para296_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5183) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4611:CNode_5175{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4611:CNode_5176{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5175, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4611:CNode_5177{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4611:CNode_5178{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4611:CNode_5179{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5177, [2]: CNode_5178, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4611:output{[0]: ValueNode<FuncGraph> _cal_output_5182, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4611:CNode_5184{[0]: ValueNode<Primitive> Return, [1]: CNode_5183}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4614 : 0x561a185afc40
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4614 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para297_x) {
  %1(CNode_5185) = call @shape_4343(%para297_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5186) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5187) = getattr(%para297_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5188) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5189) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5190) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5191) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5192(%para297_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5193) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4614:CNode_5185{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4614:CNode_5186{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5185, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4614:CNode_5187{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4614:CNode_5188{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4614:CNode_5189{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5187, [2]: CNode_5188, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4614:output{[0]: ValueNode<FuncGraph> _cal_output_5192, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4614:CNode_5194{[0]: ValueNode<Primitive> Return, [1]: CNode_5193}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4613 : 0x5619896aa150
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4613 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para298_x) {
  %1(CNode_5195) = call @L_mindcv_models_bit_StdConv2d_construct_5112(%para298_x, %para59_backbone.layer3.3.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.3.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4613:CNode_5195{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5112, [1]: param_x, [2]: param_backbone.layer3.3.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4613:CNode_5196{[0]: ValueNode<Primitive> Return, [1]: CNode_5195}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4625 : 0x56198783f650
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4625 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4545](%para299_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindspore_nn_layer_normalization_GroupNorm_construct_4627(%para208_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindspore_nn_layer_activation_ReLU_construct_4628(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindcv_models_bit_StdConv2d_construct_4629(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindspore_nn_layer_normalization_GroupNorm_construct_4630(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindspore_nn_layer_activation_ReLU_construct_4628(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindcv_models_bit_StdConv2d_construct_4631(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindspore_nn_layer_normalization_GroupNorm_construct_4632(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindspore_nn_layer_activation_ReLU_construct_4628(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindcv_models_bit_StdConv2d_construct_4633(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para299_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4625:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4625:CNode_5197{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4622 : 0x5619a1b5ae20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4622 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4545]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindspore_nn_layer_normalization_GroupNorm_construct_4627(%para208_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4545):call @mindspore_nn_layer_activation_ReLU_construct_4628(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4622:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4622:CNode_5198{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4623 : 0x561a212c0bd0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4623 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4545]() {
  Return(%para208_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4623:CNode_5199{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4633 : 0x561a1cd01ea0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4633 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para300_x) {
  %1(CNode_5200) = call @L_mindcv_models_bit_StdConv2d_construct_5008(%para300_x, %para15_backbone.layer3.4.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.4.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4633:CNode_5200{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5008, [1]: param_x, [2]: param_backbone.layer3.4.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4633:CNode_5201{[0]: ValueNode<Primitive> Return, [1]: CNode_5200}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4628 : 0x561a1d01c210
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4628(%para301_x) {
  %1(CNode_5202) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para301_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4628:CNode_5202{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4628:CNode_5203{[0]: ValueNode<Primitive> Return, [1]: CNode_5202}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4632 : 0x561a24d92080
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4632 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para302_x) {
  %1(CNode_5204) = call @shape_4343(%para302_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5205) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5206) = getattr(%para302_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5207) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5208) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5209) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5210) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5211(%para302_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5212) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4632:CNode_5204{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4632:CNode_5205{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5204, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4632:CNode_5206{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4632:CNode_5207{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4632:CNode_5208{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5206, [2]: CNode_5207, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4632:output{[0]: ValueNode<FuncGraph> _cal_output_5211, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4632:CNode_5213{[0]: ValueNode<Primitive> Return, [1]: CNode_5212}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4631 : 0x561a138002d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4631 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para303_x) {
  %1(CNode_5214) = call @L_mindcv_models_bit_StdConv2d_construct_5089(%para303_x, %para31_backbone.layer3.4.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.4.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4631:CNode_5214{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5089, [1]: param_x, [2]: param_backbone.layer3.4.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4631:CNode_5215{[0]: ValueNode<Primitive> Return, [1]: CNode_5214}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4627 : 0x561a20858390
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4627 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para304_x) {
  %1(CNode_5216) = call @shape_4343(%para304_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5217) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5218) = getattr(%para304_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5219) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5220) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5221) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5222) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5223(%para304_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5224) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4627:CNode_5216{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4627:CNode_5217{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5216, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4627:CNode_5218{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4627:CNode_5219{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4627:CNode_5220{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5218, [2]: CNode_5219, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4627:output{[0]: ValueNode<FuncGraph> _cal_output_5223, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4627:CNode_5225{[0]: ValueNode<Primitive> Return, [1]: CNode_5224}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4630 : 0x561993b5a080
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4630 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para305_x) {
  %1(CNode_5226) = call @shape_4343(%para305_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5227) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5228) = getattr(%para305_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5229) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5230) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5231) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5232) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5233(%para305_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5234) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4630:CNode_5226{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4630:CNode_5227{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5226, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4630:CNode_5228{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4630:CNode_5229{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4630:CNode_5230{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5228, [2]: CNode_5229, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4630:output{[0]: ValueNode<FuncGraph> _cal_output_5233, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4630:CNode_5235{[0]: ValueNode<Primitive> Return, [1]: CNode_5234}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4629 : 0x56198947c3e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4629 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para306_x) {
  %1(CNode_5236) = call @L_mindcv_models_bit_StdConv2d_construct_5112(%para306_x, %para61_backbone.layer3.4.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.4.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4629:CNode_5236{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5112, [1]: param_x, [2]: param_backbone.layer3.4.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4629:CNode_5237{[0]: ValueNode<Primitive> Return, [1]: CNode_5236}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4641 : 0x561a2620d8a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4641 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4546](%para307_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindspore_nn_layer_normalization_GroupNorm_construct_4643(%para209_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindspore_nn_layer_activation_ReLU_construct_4644(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindcv_models_bit_StdConv2d_construct_4645(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindspore_nn_layer_normalization_GroupNorm_construct_4646(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindspore_nn_layer_activation_ReLU_construct_4644(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindcv_models_bit_StdConv2d_construct_4647(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindspore_nn_layer_normalization_GroupNorm_construct_4648(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindspore_nn_layer_activation_ReLU_construct_4644(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindcv_models_bit_StdConv2d_construct_4649(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para307_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4641:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4641:CNode_5238{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4638 : 0x561a1832b120
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4638 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4546]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindspore_nn_layer_normalization_GroupNorm_construct_4643(%para209_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4546):call @mindspore_nn_layer_activation_ReLU_construct_4644(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4638:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4638:CNode_5239{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4639 : 0x561a195de800
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4639 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4546]() {
  Return(%para209_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4639:CNode_5240{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4649 : 0x561987f14300
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4649 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para308_x) {
  %1(CNode_5241) = call @L_mindcv_models_bit_StdConv2d_construct_5008(%para308_x, %para16_backbone.layer3.5.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (1024, 256, 1, 1), ref_key=:backbone.layer3.5.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4649:CNode_5241{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5008, [1]: param_x, [2]: param_backbone.layer3.5.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4649:CNode_5242{[0]: ValueNode<Primitive> Return, [1]: CNode_5241}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4644 : 0x561a146fc5f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4644(%para309_x) {
  %1(CNode_5243) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para309_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4644:CNode_5243{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4644:CNode_5244{[0]: ValueNode<Primitive> Return, [1]: CNode_5243}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4648 : 0x561a261096c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4648 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para310_x) {
  %1(CNode_5245) = call @shape_4343(%para310_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5246) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5247) = getattr(%para310_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5248) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5249) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5250) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5251) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5252(%para310_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5253) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4648:CNode_5245{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4648:CNode_5246{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5245, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4648:CNode_5247{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4648:CNode_5248{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4648:CNode_5249{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5247, [2]: CNode_5248, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4648:output{[0]: ValueNode<FuncGraph> _cal_output_5252, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4648:CNode_5254{[0]: ValueNode<Primitive> Return, [1]: CNode_5253}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4647 : 0x561a19c62e50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4647 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para311_x) {
  %1(CNode_5255) = call @L_mindcv_models_bit_StdConv2d_construct_5089(%para311_x, %para32_backbone.layer3.5.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:backbone.layer3.5.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4647:CNode_5255{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5089, [1]: param_x, [2]: param_backbone.layer3.5.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4647:CNode_5256{[0]: ValueNode<Primitive> Return, [1]: CNode_5255}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4643 : 0x561a198da160
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4643 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para312_x) {
  %1(CNode_5257) = call @shape_4343(%para312_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5258) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5259) = getattr(%para312_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5260) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5261) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5262) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5263) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5264(%para312_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5265) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4643:CNode_5257{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4643:CNode_5258{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5257, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4643:CNode_5259{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4643:CNode_5260{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4643:CNode_5261{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5259, [2]: CNode_5260, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4643:output{[0]: ValueNode<FuncGraph> _cal_output_5264, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4643:CNode_5266{[0]: ValueNode<Primitive> Return, [1]: CNode_5265}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4646 : 0x561a19693b50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4646 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para313_x) {
  %1(CNode_5267) = call @shape_4343(%para313_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5268) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5269) = getattr(%para313_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5270) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5271) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5272) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5273) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5274(%para313_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5275) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4646:CNode_5267{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4646:CNode_5268{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5267, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4646:CNode_5269{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4646:CNode_5270{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4646:CNode_5271{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5269, [2]: CNode_5270, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4646:output{[0]: ValueNode<FuncGraph> _cal_output_5274, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4646:CNode_5276{[0]: ValueNode<Primitive> Return, [1]: CNode_5275}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4645 : 0x56198928b310
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4645 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para314_x) {
  %1(CNode_5277) = call @L_mindcv_models_bit_StdConv2d_construct_5112(%para314_x, %para63_backbone.layer3.5.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 1024, 1, 1), ref_key=:backbone.layer3.5.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4645:CNode_5277{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5112, [1]: param_x, [2]: param_backbone.layer3.5.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4645:CNode_5278{[0]: ValueNode<Primitive> Return, [1]: CNode_5277}


subgraph attr:
training : 0
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_4658 : 0x561993e57bb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_4658 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4364]() {
  %1(CNode_4656) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para210_@CNode_4656, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_5279) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_4367) = $(mindspore_nn_layer_container_SequentialCell_construct_4283):MakeTuple(@mindcv_models_bit_Bottleneck_construct_4651, @mindcv_models_bit_Bottleneck_construct_4652, @mindcv_models_bit_Bottleneck_construct_4653, @mindcv_models_bit_Bottleneck_construct_4654)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_5280) = call @ms_iter_4166(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para210_@CNode_4656)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para211_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_5281) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4364(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_5282) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_4658:CNode_5280{[0]: ValueNode<FuncGraph> ms_iter_4166, [1]: CNode_4367}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_4658:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5280, [2]: param_@CNode_4656}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_4658:CNode_4656{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.11, [1]: param_@CNode_4656, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_4658:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_4658:CNode_5281{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4364, [1]: CNode_4656, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_4658:CNode_5283{[0]: ValueNode<Primitive> Return, [1]: CNode_5282}


subgraph attr:
training : 0
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_4659 : 0x561a1fe52860
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_4659 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4364]() {
  Return(%para211_фinput_data)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_4659:CNode_5284{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4669 : 0x561995649de0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4669 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4651](%para315_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindspore_nn_layer_normalization_GroupNorm_construct_4671(%para212_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindspore_nn_layer_activation_ReLU_construct_4672(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindcv_models_bit_StdConv2d_construct_4673(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindspore_nn_layer_normalization_GroupNorm_construct_4674(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindspore_nn_layer_activation_ReLU_construct_4672(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindcv_models_bit_StdConv2d_construct_4675(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindspore_nn_layer_normalization_GroupNorm_construct_4676(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindspore_nn_layer_activation_ReLU_construct_4672(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindcv_models_bit_StdConv2d_construct_4677(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para315_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4669:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4669:CNode_5285{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4666 : 0x5619949704d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4666 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4651]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindspore_nn_layer_normalization_GroupNorm_construct_4671(%para212_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4651):call @mindspore_nn_layer_activation_ReLU_construct_4672(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = call @mindspore_nn_layer_container_SequentialCell_construct_4663(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4666:identity{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4663, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4666:CNode_5286{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4667 : 0x56198a993830
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4667 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4651]() {
  Return(%para212_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4667:CNode_5287{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4677 : 0x561a21eae880
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4677 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para316_x) {
  %1(CNode_5289) = call @L_mindcv_models_bit_StdConv2d_construct_5288(%para316_x, %para17_backbone.layer2.0.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 128, 1, 1), ref_key=:backbone.layer2.0.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4677:CNode_5289{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5288, [1]: param_x, [2]: param_backbone.layer2.0.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4677:CNode_5290{[0]: ValueNode<Primitive> Return, [1]: CNode_5289}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_4663 : 0x561987eedde0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_4663 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para317_input_data) {
  %1(CNode_5292) = call @↵mindspore_nn_layer_container_SequentialCell_construct_5291(I64(0), %para317_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_4663:CNode_5293{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_5294}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_4663:CNode_5292{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_5291, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_4663:CNode_5295{[0]: ValueNode<Primitive> Return, [1]: CNode_5292}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4672 : 0x561a2639e520
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4672(%para318_x) {
  %1(CNode_5296) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para318_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4672:CNode_5296{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4672:CNode_5297{[0]: ValueNode<Primitive> Return, [1]: CNode_5296}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4676 : 0x561986701710
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4676 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para319_x) {
  %1(CNode_5298) = call @shape_4343(%para319_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5299) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5300) = getattr(%para319_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5301) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5302) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5303) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5304) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5305(%para319_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5306) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4676:CNode_5298{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4676:CNode_5299{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5298, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4676:CNode_5300{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4676:CNode_5301{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4676:CNode_5302{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5300, [2]: CNode_5301, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4676:output{[0]: ValueNode<FuncGraph> _cal_output_5305, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4676:CNode_5307{[0]: ValueNode<Primitive> Return, [1]: CNode_5306}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4675 : 0x561a1fc05410
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4675 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para320_x) {
  %1(CNode_5308) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para33_backbone.layer2.0.conv2.weight, %1)
      : (<Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5309) = S_Prim_sub(%para33_backbone.layer2.0.conv2.weight, %2)
      : (<Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5310) = getattr(%para33_backbone.layer2.0.conv2.weight, "var")
      : (<Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.0.conv2.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5311) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5312) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5313) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5314) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5315) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5316) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5317) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(128), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para320_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5308{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_4675:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer2.0.conv2.weight, [2]: CNode_5308}
#   3: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5310{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer2.0.conv2.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5311{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5312{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5311}
#   6: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5313{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5314{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5315{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5313, [2]: CNode_5314}
#   9: @mindcv_models_bit_StdConv2d_construct_4675:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5318, [1]: CNode_5310, [2]: CNode_5312, [3]: CNode_5315}
#  10: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5309{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer2.0.conv2.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5316{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5317{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_5316}
#  13: @mindcv_models_bit_StdConv2d_construct_4675:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5309, [2]: CNode_5317}
#  14: @mindcv_models_bit_StdConv2d_construct_4675:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_4675:CNode_5319{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4671 : 0x561a14810a60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4671 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para321_x) {
  %1(CNode_5320) = call @shape_4343(%para321_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5321) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5322) = getattr(%para321_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5323) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5324) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5325) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5326) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5327(%para321_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5328) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4671:CNode_5320{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4671:CNode_5321{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5320, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4671:CNode_5322{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4671:CNode_5323{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4671:CNode_5324{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5322, [2]: CNode_5323, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4671:output{[0]: ValueNode<FuncGraph> _cal_output_5327, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4671:CNode_5329{[0]: ValueNode<Primitive> Return, [1]: CNode_5328}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4674 : 0x561989266290
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4674 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para322_x) {
  %1(CNode_5330) = call @shape_4343(%para322_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5331) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5332) = getattr(%para322_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5333) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5334) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5335) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5336) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5337(%para322_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5338) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4674:CNode_5330{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4674:CNode_5331{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5330, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4674:CNode_5332{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4674:CNode_5333{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4674:CNode_5334{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5332, [2]: CNode_5333, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4674:output{[0]: ValueNode<FuncGraph> _cal_output_5337, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4674:CNode_5339{[0]: ValueNode<Primitive> Return, [1]: CNode_5338}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4673 : 0x561993d176c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4673 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para323_x) {
  %1(CNode_5340) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para80_backbone.layer2.0.conv1.weight, %1)
      : (<Ref[Tensor[Float32]], (128, 256, 1, 1), ref_key=:backbone.layer2.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5341) = S_Prim_sub(%para80_backbone.layer2.0.conv1.weight, %2)
      : (<Ref[Tensor[Float32]], (128, 256, 1, 1), ref_key=:backbone.layer2.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5342) = getattr(%para80_backbone.layer2.0.conv1.weight, "var")
      : (<Ref[Tensor[Float32]], (128, 256, 1, 1), ref_key=:backbone.layer2.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5343) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5344) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5345) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5346) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5347) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5348) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5349) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(128), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para323_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5340{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_4673:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer2.0.conv1.weight, [2]: CNode_5340}
#   3: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5342{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer2.0.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5343{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5344{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5343}
#   6: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5345{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5346{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5347{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5345, [2]: CNode_5346}
#   9: @mindcv_models_bit_StdConv2d_construct_4673:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5350, [1]: CNode_5342, [2]: CNode_5344, [3]: CNode_5347}
#  10: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5341{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer2.0.conv1.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5348{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5349{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_5348}
#  13: @mindcv_models_bit_StdConv2d_construct_4673:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5341, [2]: CNode_5349}
#  14: @mindcv_models_bit_StdConv2d_construct_4673:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_4673:CNode_5351{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4685 : 0x56198ec18d30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4685 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4652](%para324_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindspore_nn_layer_normalization_GroupNorm_construct_4687(%para213_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindspore_nn_layer_activation_ReLU_construct_4688(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindcv_models_bit_StdConv2d_construct_4689(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindspore_nn_layer_normalization_GroupNorm_construct_4690(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindspore_nn_layer_activation_ReLU_construct_4688(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindcv_models_bit_StdConv2d_construct_4691(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindspore_nn_layer_normalization_GroupNorm_construct_4692(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindspore_nn_layer_activation_ReLU_construct_4688(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindcv_models_bit_StdConv2d_construct_4693(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para324_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4685:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4685:CNode_5352{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4682 : 0x56198e550370
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4682 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4652]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindspore_nn_layer_normalization_GroupNorm_construct_4687(%para213_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4652):call @mindspore_nn_layer_activation_ReLU_construct_4688(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4682:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4682:CNode_5353{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4683 : 0x561995b2ecb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4683 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4652]() {
  Return(%para213_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4683:CNode_5354{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4693 : 0x561a1ccadf00
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4693 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para325_x) {
  %1(CNode_5355) = call @L_mindcv_models_bit_StdConv2d_construct_5288(%para325_x, %para18_backbone.layer2.1.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 128, 1, 1), ref_key=:backbone.layer2.1.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4693:CNode_5355{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5288, [1]: param_x, [2]: param_backbone.layer2.1.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4693:CNode_5356{[0]: ValueNode<Primitive> Return, [1]: CNode_5355}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4688 : 0x561a26d9aa80
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4688(%para326_x) {
  %1(CNode_5357) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para326_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4688:CNode_5357{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4688:CNode_5358{[0]: ValueNode<Primitive> Return, [1]: CNode_5357}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4692 : 0x561994521220
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4692 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para327_x) {
  %1(CNode_5359) = call @shape_4343(%para327_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5360) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5361) = getattr(%para327_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5362) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5363) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5364) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5365) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5366(%para327_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5367) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4692:CNode_5359{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4692:CNode_5360{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5359, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4692:CNode_5361{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4692:CNode_5362{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4692:CNode_5363{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5361, [2]: CNode_5362, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4692:output{[0]: ValueNode<FuncGraph> _cal_output_5366, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4692:CNode_5368{[0]: ValueNode<Primitive> Return, [1]: CNode_5367}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4691 : 0x5619a13c4b00
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4691 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para328_x) {
  %1(CNode_5370) = call @L_mindcv_models_bit_StdConv2d_construct_5369(%para328_x, %para34_backbone.layer2.1.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.1.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4691:CNode_5370{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5369, [1]: param_x, [2]: param_backbone.layer2.1.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4691:CNode_5371{[0]: ValueNode<Primitive> Return, [1]: CNode_5370}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4687 : 0x561a18fa1930
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4687 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para329_x) {
  %1(CNode_5372) = call @shape_4343(%para329_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5373) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5374) = getattr(%para329_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5375) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5376) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5377) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5378) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5379(%para329_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5380) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4687:CNode_5372{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4687:CNode_5373{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5372, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4687:CNode_5374{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4687:CNode_5375{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4687:CNode_5376{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5374, [2]: CNode_5375, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4687:output{[0]: ValueNode<FuncGraph> _cal_output_5379, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4687:CNode_5381{[0]: ValueNode<Primitive> Return, [1]: CNode_5380}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4690 : 0x5619892402a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4690 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para330_x) {
  %1(CNode_5382) = call @shape_4343(%para330_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5383) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5384) = getattr(%para330_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5385) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5386) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5387) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5388) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5389(%para330_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5390) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4690:CNode_5382{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4690:CNode_5383{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5382, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4690:CNode_5384{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4690:CNode_5385{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4690:CNode_5386{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5384, [2]: CNode_5385, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4690:output{[0]: ValueNode<FuncGraph> _cal_output_5389, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4690:CNode_5391{[0]: ValueNode<Primitive> Return, [1]: CNode_5390}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4689 : 0x561993cefec0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4689 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para331_x) {
  %1(CNode_5393) = call @L_mindcv_models_bit_StdConv2d_construct_5392(%para331_x, %para82_backbone.layer2.1.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 512, 1, 1), ref_key=:backbone.layer2.1.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4689:CNode_5393{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5392, [1]: param_x, [2]: param_backbone.layer2.1.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4689:CNode_5394{[0]: ValueNode<Primitive> Return, [1]: CNode_5393}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4701 : 0x561986709820
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4701 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4653](%para332_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindspore_nn_layer_normalization_GroupNorm_construct_4703(%para214_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindspore_nn_layer_activation_ReLU_construct_4704(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindcv_models_bit_StdConv2d_construct_4705(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindspore_nn_layer_normalization_GroupNorm_construct_4706(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindspore_nn_layer_activation_ReLU_construct_4704(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindcv_models_bit_StdConv2d_construct_4707(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindspore_nn_layer_normalization_GroupNorm_construct_4708(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindspore_nn_layer_activation_ReLU_construct_4704(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindcv_models_bit_StdConv2d_construct_4709(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para332_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4701:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4701:CNode_5395{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4698 : 0x561991153830
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4698 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4653]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindspore_nn_layer_normalization_GroupNorm_construct_4703(%para214_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4653):call @mindspore_nn_layer_activation_ReLU_construct_4704(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4698:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4698:CNode_5396{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4699 : 0x56198761f320
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4699 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4653]() {
  Return(%para214_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4699:CNode_5397{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4709 : 0x561a1d5ad470
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4709 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para333_x) {
  %1(CNode_5398) = call @L_mindcv_models_bit_StdConv2d_construct_5288(%para333_x, %para19_backbone.layer2.2.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 128, 1, 1), ref_key=:backbone.layer2.2.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4709:CNode_5398{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5288, [1]: param_x, [2]: param_backbone.layer2.2.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4709:CNode_5399{[0]: ValueNode<Primitive> Return, [1]: CNode_5398}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4704 : 0x561a13798a20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4704(%para334_x) {
  %1(CNode_5400) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para334_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4704:CNode_5400{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4704:CNode_5401{[0]: ValueNode<Primitive> Return, [1]: CNode_5400}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4708 : 0x56198baa54d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4708 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para335_x) {
  %1(CNode_5402) = call @shape_4343(%para335_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5403) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5404) = getattr(%para335_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5405) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5406) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5407) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5408) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5409(%para335_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5410) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4708:CNode_5402{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4708:CNode_5403{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5402, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4708:CNode_5404{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4708:CNode_5405{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4708:CNode_5406{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5404, [2]: CNode_5405, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4708:output{[0]: ValueNode<FuncGraph> _cal_output_5409, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4708:CNode_5411{[0]: ValueNode<Primitive> Return, [1]: CNode_5410}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4707 : 0x561a16b154f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4707 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para336_x) {
  %1(CNode_5412) = call @L_mindcv_models_bit_StdConv2d_construct_5369(%para336_x, %para35_backbone.layer2.2.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.2.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4707:CNode_5412{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5369, [1]: param_x, [2]: param_backbone.layer2.2.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4707:CNode_5413{[0]: ValueNode<Primitive> Return, [1]: CNode_5412}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4703 : 0x561a14eee1a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4703 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para337_x) {
  %1(CNode_5414) = call @shape_4343(%para337_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5415) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5416) = getattr(%para337_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5417) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5418) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5419) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5420) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5421(%para337_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5422) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4703:CNode_5414{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4703:CNode_5415{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5414, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4703:CNode_5416{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4703:CNode_5417{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4703:CNode_5418{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5416, [2]: CNode_5417, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4703:output{[0]: ValueNode<FuncGraph> _cal_output_5421, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4703:CNode_5423{[0]: ValueNode<Primitive> Return, [1]: CNode_5422}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4706 : 0x561989175be0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4706 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para338_x) {
  %1(CNode_5424) = call @shape_4343(%para338_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5425) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5426) = getattr(%para338_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5427) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5428) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5429) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5430) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5431(%para338_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5432) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4706:CNode_5424{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4706:CNode_5425{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5424, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4706:CNode_5426{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4706:CNode_5427{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4706:CNode_5428{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5426, [2]: CNode_5427, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4706:output{[0]: ValueNode<FuncGraph> _cal_output_5431, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4706:CNode_5433{[0]: ValueNode<Primitive> Return, [1]: CNode_5432}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4705 : 0x561993be71a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4705 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para339_x) {
  %1(CNode_5434) = call @L_mindcv_models_bit_StdConv2d_construct_5392(%para339_x, %para84_backbone.layer2.2.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 512, 1, 1), ref_key=:backbone.layer2.2.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4705:CNode_5434{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5392, [1]: param_x, [2]: param_backbone.layer2.2.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4705:CNode_5435{[0]: ValueNode<Primitive> Return, [1]: CNode_5434}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4717 : 0x561a2126e740
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4717 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4654](%para340_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindspore_nn_layer_normalization_GroupNorm_construct_4719(%para215_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindspore_nn_layer_activation_ReLU_construct_4720(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindcv_models_bit_StdConv2d_construct_4721(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindspore_nn_layer_normalization_GroupNorm_construct_4722(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindspore_nn_layer_activation_ReLU_construct_4720(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindcv_models_bit_StdConv2d_construct_4723(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindspore_nn_layer_normalization_GroupNorm_construct_4724(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindspore_nn_layer_activation_ReLU_construct_4720(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindcv_models_bit_StdConv2d_construct_4725(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para340_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4717:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4717:CNode_5436{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4714 : 0x561a1fbe14d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4714 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4654]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindspore_nn_layer_normalization_GroupNorm_construct_4719(%para215_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4654):call @mindspore_nn_layer_activation_ReLU_construct_4720(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4714:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4714:CNode_5437{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4715 : 0x561a212b2b80
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4715 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4654]() {
  Return(%para215_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4715:CNode_5438{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4725 : 0x561a1bd172b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4725 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para341_x) {
  %1(CNode_5439) = call @L_mindcv_models_bit_StdConv2d_construct_5288(%para341_x, %para20_backbone.layer2.3.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 128, 1, 1), ref_key=:backbone.layer2.3.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4725:CNode_5439{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5288, [1]: param_x, [2]: param_backbone.layer2.3.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4725:CNode_5440{[0]: ValueNode<Primitive> Return, [1]: CNode_5439}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4720 : 0x561a264ac1b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4720(%para342_x) {
  %1(CNode_5441) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para342_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4720:CNode_5441{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4720:CNode_5442{[0]: ValueNode<Primitive> Return, [1]: CNode_5441}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4724 : 0x561990d3cb70
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4724 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para343_x) {
  %1(CNode_5443) = call @shape_4343(%para343_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5444) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5445) = getattr(%para343_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5446) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5447) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5448) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5449) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5450(%para343_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5451) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4724:CNode_5443{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4724:CNode_5444{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5443, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4724:CNode_5445{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4724:CNode_5446{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4724:CNode_5447{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5445, [2]: CNode_5446, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4724:output{[0]: ValueNode<FuncGraph> _cal_output_5450, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4724:CNode_5452{[0]: ValueNode<Primitive> Return, [1]: CNode_5451}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4723 : 0x56198f926d30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4723 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para344_x) {
  %1(CNode_5453) = call @L_mindcv_models_bit_StdConv2d_construct_5369(%para344_x, %para36_backbone.layer2.3.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:backbone.layer2.3.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4723:CNode_5453{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5369, [1]: param_x, [2]: param_backbone.layer2.3.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4723:CNode_5454{[0]: ValueNode<Primitive> Return, [1]: CNode_5453}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4719 : 0x561a14bc2b50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4719 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para345_x) {
  %1(CNode_5455) = call @shape_4343(%para345_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5456) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5457) = getattr(%para345_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5458) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5459) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5460) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5461) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5462(%para345_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5463) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4719:CNode_5455{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4719:CNode_5456{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5455, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4719:CNode_5457{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4719:CNode_5458{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4719:CNode_5459{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5457, [2]: CNode_5458, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4719:output{[0]: ValueNode<FuncGraph> _cal_output_5462, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4719:CNode_5464{[0]: ValueNode<Primitive> Return, [1]: CNode_5463}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4722 : 0x561989173c40
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4722 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para346_x) {
  %1(CNode_5465) = call @shape_4343(%para346_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5466) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5467) = getattr(%para346_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5468) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5469) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5470) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5471) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5472(%para346_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5473) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4722:CNode_5465{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4722:CNode_5466{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5465, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4722:CNode_5467{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4722:CNode_5468{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4722:CNode_5469{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5467, [2]: CNode_5468, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4722:output{[0]: ValueNode<FuncGraph> _cal_output_5472, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4722:CNode_5474{[0]: ValueNode<Primitive> Return, [1]: CNode_5473}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4721 : 0x561993a934c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4721 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para347_x) {
  %1(CNode_5475) = call @L_mindcv_models_bit_StdConv2d_construct_5392(%para347_x, %para86_backbone.layer2.3.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 512, 1, 1), ref_key=:backbone.layer2.3.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4721:CNode_5475{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5392, [1]: param_x, [2]: param_backbone.layer2.3.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4721:CNode_5476{[0]: ValueNode<Primitive> Return, [1]: CNode_5475}


subgraph attr:
training : 0
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_4733 : 0x561a179f9300
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_4733 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4369]() {
  %1(CNode_4731) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para216_@CNode_4731, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_5477) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_4372) = $(mindspore_nn_layer_container_SequentialCell_construct_4282):MakeTuple(@mindcv_models_bit_Bottleneck_construct_4727, @mindcv_models_bit_Bottleneck_construct_4728, @mindcv_models_bit_Bottleneck_construct_4729)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_5478) = call @ms_iter_4166(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para216_@CNode_4731)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para217_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_5479) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4369(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_5480) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_4733:CNode_5478{[0]: ValueNode<FuncGraph> ms_iter_4166, [1]: CNode_4372}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_4733:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5478, [2]: param_@CNode_4731}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_4733:CNode_4731{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.11, [1]: param_@CNode_4731, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_4733:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_4733:CNode_5479{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4369, [1]: CNode_4731, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_4733:CNode_5481{[0]: ValueNode<Primitive> Return, [1]: CNode_5480}


subgraph attr:
training : 0
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_4734 : 0x561a260d71a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_4734 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4369]() {
  Return(%para217_фinput_data)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_4734:CNode_5482{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4744 : 0x561988c019f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4744 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4727](%para348_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindspore_nn_layer_normalization_GroupNorm_construct_4746(%para218_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindspore_nn_layer_activation_ReLU_construct_4747(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindcv_models_bit_StdConv2d_construct_4748(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindspore_nn_layer_normalization_GroupNorm_construct_4749(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindspore_nn_layer_activation_ReLU_construct_4747(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindcv_models_bit_StdConv2d_construct_4750(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindspore_nn_layer_normalization_GroupNorm_construct_4751(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindspore_nn_layer_activation_ReLU_construct_4747(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindcv_models_bit_StdConv2d_construct_4752(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para348_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4744:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4744:CNode_5483{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4741 : 0x561a20c96ee0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4741 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4727]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindspore_nn_layer_normalization_GroupNorm_construct_4746(%para218_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4727):call @mindspore_nn_layer_activation_ReLU_construct_4747(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = call @mindspore_nn_layer_container_SequentialCell_construct_4738(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4741:identity{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_4738, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4741:CNode_5484{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4742 : 0x561a1ddd4e00
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4742 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4727]() {
  Return(%para218_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4742:CNode_5485{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4752 : 0x561a26193ba0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4752 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para349_x) {
  %1(CNode_5487) = call @L_mindcv_models_bit_StdConv2d_construct_5486(%para349_x, %para24_backbone.layer1.0.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 64, 1, 1), ref_key=:backbone.layer1.0.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4752:CNode_5487{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5486, [1]: param_x, [2]: param_backbone.layer1.0.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4752:CNode_5488{[0]: ValueNode<Primitive> Return, [1]: CNode_5487}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_4738 : 0x561a1d21b740
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_4738 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para350_input_data) {
  %1(CNode_5490) = call @↵mindspore_nn_layer_container_SequentialCell_construct_5489(I64(0), %para350_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_4738:CNode_5491{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_5492}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_4738:CNode_5490{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_5489, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_4738:CNode_5493{[0]: ValueNode<Primitive> Return, [1]: CNode_5490}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4747 : 0x56198ea49bc0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4747(%para351_x) {
  %1(CNode_5494) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para351_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4747:CNode_5494{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4747:CNode_5495{[0]: ValueNode<Primitive> Return, [1]: CNode_5494}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4751 : 0x561a14bb7190
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4751 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para352_x) {
  %1(CNode_5496) = call @shape_4343(%para352_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5497) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5498) = getattr(%para352_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5499) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5500) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5501) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5502) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5503(%para352_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5504) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4751:CNode_5496{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4751:CNode_5497{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5496, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4751:CNode_5498{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4751:CNode_5499{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4751:CNode_5500{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5498, [2]: CNode_5499, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4751:output{[0]: ValueNode<FuncGraph> _cal_output_5503, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4751:CNode_5505{[0]: ValueNode<Primitive> Return, [1]: CNode_5504}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4750 : 0x56198e45aff0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4750 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para353_x) {
  %1(CNode_5507) = call @L_mindcv_models_bit_StdConv2d_construct_5506(%para353_x, %para43_backbone.layer1.0.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:backbone.layer1.0.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4750:CNode_5507{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5506, [1]: param_x, [2]: param_backbone.layer1.0.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4750:CNode_5508{[0]: ValueNode<Primitive> Return, [1]: CNode_5507}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4746 : 0x561a1f6ddeb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4746 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para354_x) {
  %1(CNode_5509) = call @shape_4343(%para354_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5510) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5511) = getattr(%para354_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5512) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5513) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5514) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5515) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5516(%para354_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5517) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4746:CNode_5509{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4746:CNode_5510{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5509, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4746:CNode_5511{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4746:CNode_5512{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4746:CNode_5513{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5511, [2]: CNode_5512, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4746:output{[0]: ValueNode<FuncGraph> _cal_output_5516, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4746:CNode_5518{[0]: ValueNode<Primitive> Return, [1]: CNode_5517}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4749 : 0x561993a7b400
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4749 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para355_x) {
  %1(CNode_5519) = call @shape_4343(%para355_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5520) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5521) = getattr(%para355_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5522) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5523) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5524) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5525) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5526(%para355_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5527) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4749:CNode_5519{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4749:CNode_5520{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5519, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4749:CNode_5521{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4749:CNode_5522{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4749:CNode_5523{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5521, [2]: CNode_5522, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4749:output{[0]: ValueNode<FuncGraph> _cal_output_5526, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4749:CNode_5528{[0]: ValueNode<Primitive> Return, [1]: CNode_5527}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4748 : 0x561a19603c00
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4748 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para356_x) {
  %1(CNode_5529) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para105_backbone.layer1.0.conv1.weight, %1)
      : (<Ref[Tensor[Float32]], (64, 64, 1, 1), ref_key=:backbone.layer1.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5530) = S_Prim_sub(%para105_backbone.layer1.0.conv1.weight, %2)
      : (<Ref[Tensor[Float32]], (64, 64, 1, 1), ref_key=:backbone.layer1.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5531) = getattr(%para105_backbone.layer1.0.conv1.weight, "var")
      : (<Ref[Tensor[Float32]], (64, 64, 1, 1), ref_key=:backbone.layer1.0.conv1.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5532) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5533) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5534) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5535) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5536) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5537) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5538) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(64), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para356_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5529{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_4748:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer1.0.conv1.weight, [2]: CNode_5529}
#   3: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5531{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer1.0.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5532{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5533{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5532}
#   6: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5534{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5535{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5536{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5534, [2]: CNode_5535}
#   9: @mindcv_models_bit_StdConv2d_construct_4748:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5539, [1]: CNode_5531, [2]: CNode_5533, [3]: CNode_5536}
#  10: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5530{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer1.0.conv1.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5537{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5538{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_5537}
#  13: @mindcv_models_bit_StdConv2d_construct_4748:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5530, [2]: CNode_5538}
#  14: @mindcv_models_bit_StdConv2d_construct_4748:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_4748:CNode_5540{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4760 : 0x561a15191ac0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4760 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4728](%para357_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindspore_nn_layer_normalization_GroupNorm_construct_4762(%para219_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindspore_nn_layer_activation_ReLU_construct_4763(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindcv_models_bit_StdConv2d_construct_4764(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindspore_nn_layer_normalization_GroupNorm_construct_4765(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindspore_nn_layer_activation_ReLU_construct_4763(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindcv_models_bit_StdConv2d_construct_4766(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindspore_nn_layer_normalization_GroupNorm_construct_4767(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindspore_nn_layer_activation_ReLU_construct_4763(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindcv_models_bit_StdConv2d_construct_4768(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para357_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4760:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4760:CNode_5541{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4757 : 0x5619a1df8140
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4757 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4728]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindspore_nn_layer_normalization_GroupNorm_construct_4762(%para219_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4728):call @mindspore_nn_layer_activation_ReLU_construct_4763(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4757:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4757:CNode_5542{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4758 : 0x561a14918230
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4758 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4728]() {
  Return(%para219_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4758:CNode_5543{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4768 : 0x561985533b60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4768 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para358_x) {
  %1(CNode_5544) = call @L_mindcv_models_bit_StdConv2d_construct_5486(%para358_x, %para25_backbone.layer1.1.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 64, 1, 1), ref_key=:backbone.layer1.1.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4768:CNode_5544{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5486, [1]: param_x, [2]: param_backbone.layer1.1.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4768:CNode_5545{[0]: ValueNode<Primitive> Return, [1]: CNode_5544}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4763 : 0x5619a1bc2a60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4763(%para359_x) {
  %1(CNode_5546) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para359_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4763:CNode_5546{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4763:CNode_5547{[0]: ValueNode<Primitive> Return, [1]: CNode_5546}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4767 : 0x561a14ba1a30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4767 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para360_x) {
  %1(CNode_5548) = call @shape_4343(%para360_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5549) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5550) = getattr(%para360_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5551) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5552) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5553) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5554) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5555(%para360_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5556) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4767:CNode_5548{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4767:CNode_5549{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5548, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4767:CNode_5550{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4767:CNode_5551{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4767:CNode_5552{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5550, [2]: CNode_5551, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4767:output{[0]: ValueNode<FuncGraph> _cal_output_5555, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4767:CNode_5557{[0]: ValueNode<Primitive> Return, [1]: CNode_5556}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4766 : 0x56198c0554a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4766 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para361_x) {
  %1(CNode_5558) = call @L_mindcv_models_bit_StdConv2d_construct_5506(%para361_x, %para44_backbone.layer1.1.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:backbone.layer1.1.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4766:CNode_5558{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5506, [1]: param_x, [2]: param_backbone.layer1.1.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4766:CNode_5559{[0]: ValueNode<Primitive> Return, [1]: CNode_5558}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4762 : 0x561a24d2cc50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4762 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para362_x) {
  %1(CNode_5560) = call @shape_4343(%para362_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5561) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5562) = getattr(%para362_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5563) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5564) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5565) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5566) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5567(%para362_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5568) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4762:CNode_5560{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4762:CNode_5561{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5560, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4762:CNode_5562{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4762:CNode_5563{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4762:CNode_5564{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5562, [2]: CNode_5563, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4762:output{[0]: ValueNode<FuncGraph> _cal_output_5567, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4762:CNode_5569{[0]: ValueNode<Primitive> Return, [1]: CNode_5568}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4765 : 0x5619939dec60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4765 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para363_x) {
  %1(CNode_5570) = call @shape_4343(%para363_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5571) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5572) = getattr(%para363_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5573) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5574) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5575) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5576) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5577(%para363_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5578) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4765:CNode_5570{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4765:CNode_5571{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5570, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4765:CNode_5572{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4765:CNode_5573{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4765:CNode_5574{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5572, [2]: CNode_5573, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4765:output{[0]: ValueNode<FuncGraph> _cal_output_5577, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4765:CNode_5579{[0]: ValueNode<Primitive> Return, [1]: CNode_5578}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4764 : 0x561a1939f8c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4764 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para364_x) {
  %1(CNode_5581) = call @L_mindcv_models_bit_StdConv2d_construct_5580(%para364_x, %para107_backbone.layer1.1.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 256, 1, 1), ref_key=:backbone.layer1.1.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4764:CNode_5581{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5580, [1]: param_x, [2]: param_backbone.layer1.1.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4764:CNode_5582{[0]: ValueNode<Primitive> Return, [1]: CNode_5581}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindcv_models_bit_Bottleneck_construct_4776 : 0x56198a970600
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @↓mindcv_models_bit_Bottleneck_construct_4776 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4729](%para365_) {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindspore_nn_layer_normalization_GroupNorm_construct_4778(%para220_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindspore_nn_layer_activation_ReLU_construct_4779(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindcv_models_bit_StdConv2d_construct_4780(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:130/        out = self.conv1(out)/
  %4(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindspore_nn_layer_normalization_GroupNorm_construct_4781(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:132/        out = self.gn2(out)/
  %5(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindspore_nn_layer_activation_ReLU_construct_4779(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:133/        out = self.relu(out)/
  %6(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindcv_models_bit_StdConv2d_construct_4782(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:134/        out = self.conv2(out)/
  %7(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindspore_nn_layer_normalization_GroupNorm_construct_4783(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:136/        out = self.gn3(out)/
  %8(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindspore_nn_layer_activation_ReLU_construct_4779(%7)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:137/        out = self.relu(out)/
  %9(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindcv_models_bit_StdConv2d_construct_4784(%8)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:138/        out = self.conv3(out)/
  %10(out) = S_Prim_add(%9, %para365_фidentity)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:143/        out += identity/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:146/        return out/
}
# Order:
#   1: @↓mindcv_models_bit_Bottleneck_construct_4776:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: out, [2]: param_фidentity}
#   2: @↓mindcv_models_bit_Bottleneck_construct_4776:CNode_5583{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✓mindcv_models_bit_Bottleneck_construct_4773 : 0x561a200b1ca0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✓mindcv_models_bit_Bottleneck_construct_4773 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4729]() {
  %1(out) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindspore_nn_layer_normalization_GroupNorm_construct_4778(%para220_identity)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:125/        out = self.gn1(x)/
  %2(residual) = $(mindcv_models_bit_Bottleneck_construct_4729):call @mindspore_nn_layer_activation_ReLU_construct_4779(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:126/        out = self.relu(out)/
  %3(identity) = None(%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:141/            identity = self.down_sample(residual)/
}
# Order:
#   1: @✓mindcv_models_bit_Bottleneck_construct_4773:identity{[0]: ValueNode<None> None, [1]: residual}
#   2: @✓mindcv_models_bit_Bottleneck_construct_4773:CNode_5584{[0]: ValueNode<Primitive> Return, [1]: identity}


subgraph attr:
training : 0
subgraph instance: ✗mindcv_models_bit_Bottleneck_construct_4774 : 0x561a173b3190
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:123/    def construct(self, x: Tensor) -> Tensor:/
subgraph @✗mindcv_models_bit_Bottleneck_construct_4774 parent: [subgraph @mindcv_models_bit_Bottleneck_construct_4729]() {
  Return(%para220_identity)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:140/        if self.down_sample is not None:/
}
# Order:
#   1: @✗mindcv_models_bit_Bottleneck_construct_4774:CNode_5585{[0]: ValueNode<Primitive> Return, [1]: param_identity}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4784 : 0x561a216ad300
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4784 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para366_x) {
  %1(CNode_5586) = call @L_mindcv_models_bit_StdConv2d_construct_5486(%para366_x, %para26_backbone.layer1.2.conv3.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 64, 1, 1), ref_key=:backbone.layer1.2.conv3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4784:CNode_5586{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5486, [1]: param_x, [2]: param_backbone.layer1.2.conv3.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4784:CNode_5587{[0]: ValueNode<Primitive> Return, [1]: CNode_5586}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_4779 : 0x561994947ae0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_4779(%para367_x) {
  %1(CNode_5588) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para367_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/relu-ReLU)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_4779:CNode_5588{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_4779:CNode_5589{[0]: ValueNode<Primitive> Return, [1]: CNode_5588}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4783 : 0x561a14b1b940
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4783 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para368_x) {
  %1(CNode_5590) = call @shape_4343(%para368_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5591) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5592) = getattr(%para368_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5593) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5594) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5595) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5596) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5597(%para368_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5598) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4783:CNode_5590{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4783:CNode_5591{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5590, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4783:CNode_5592{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4783:CNode_5593{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4783:CNode_5594{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5592, [2]: CNode_5593, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4783:output{[0]: ValueNode<FuncGraph> _cal_output_5597, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4783:CNode_5599{[0]: ValueNode<Primitive> Return, [1]: CNode_5598}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4782 : 0x561a19052400
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4782 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para369_x) {
  %1(CNode_5600) = call @L_mindcv_models_bit_StdConv2d_construct_5506(%para369_x, %para45_backbone.layer1.2.conv2.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:backbone.layer1.2.conv2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4782:CNode_5600{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5506, [1]: param_x, [2]: param_backbone.layer1.2.conv2.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4782:CNode_5601{[0]: ValueNode<Primitive> Return, [1]: CNode_5600}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4778 : 0x561a25449650
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4778 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para370_x) {
  %1(CNode_5602) = call @shape_4343(%para370_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5603) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5604) = getattr(%para370_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5605) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5606) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5607) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5608) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5609(%para370_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5610) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4778:CNode_5602{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4778:CNode_5603{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5602, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4778:CNode_5604{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4778:CNode_5605{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4778:CNode_5606{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5604, [2]: CNode_5605, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4778:output{[0]: ValueNode<FuncGraph> _cal_output_5609, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4778:CNode_5611{[0]: ValueNode<Primitive> Return, [1]: CNode_5610}


subgraph attr:
training : 0
subgraph instance: mindspore_nn_layer_normalization_GroupNorm_construct_4781 : 0x561994580b00
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_GroupNorm_construct_4781 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para371_x) {
  %1(CNode_5612) = call @shape_4343(%para371_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %2(CNode_5613) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "GroupNorm")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1188/        self._check_input_dim(F.shape(x), self.cls_name)/
  %3(CNode_5614) = getattr(%para371_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %4(CNode_5615) = S_Prim_make_list(F16, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %5(CNode_5616) = S_Prim__check_dtype[constexpr_prim: Bool(1)](%3, %4, "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1189/        self._check_dtype(x.dtype, [mstype.float16, mstype.float32], self.cls_name)/
  %6(CNode_5617) = MakeTuple(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %7(CNode_5618) = StopGradient(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1187/    def construct(self, x):/
  %8(output) = call @_cal_output_5619(%para371_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  %9(CNode_5620) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1190/        output = self._cal_output(x)/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1191/        return output/
}
# Order:
#   1: @mindspore_nn_layer_normalization_GroupNorm_construct_4781:CNode_5612{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @mindspore_nn_layer_normalization_GroupNorm_construct_4781:CNode_5613{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_5612, [2]: ValueNode<StringImm> GroupNorm}
#   3: @mindspore_nn_layer_normalization_GroupNorm_construct_4781:CNode_5614{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   4: @mindspore_nn_layer_normalization_GroupNorm_construct_4781:CNode_5615{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Float> Float16, [2]: ValueNode<Float> Float32}
#   5: @mindspore_nn_layer_normalization_GroupNorm_construct_4781:CNode_5616{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_dtype, [1]: CNode_5614, [2]: CNode_5615, [3]: ValueNode<StringImm> GroupNorm}
#   6: @mindspore_nn_layer_normalization_GroupNorm_construct_4781:output{[0]: ValueNode<FuncGraph> _cal_output_5619, [1]: param_x}
#   7: @mindspore_nn_layer_normalization_GroupNorm_construct_4781:CNode_5621{[0]: ValueNode<Primitive> Return, [1]: CNode_5620}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_4780 : 0x5619851e1480
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_4780 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para372_x) {
  %1(CNode_5622) = call @L_mindcv_models_bit_StdConv2d_construct_5580(%para372_x, %para109_backbone.layer1.2.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 256, 1, 1), ref_key=:backbone.layer1.2.conv1.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_4780:CNode_5622{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5580, [1]: param_x, [2]: param_backbone.layer1.2.conv1.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_4780:CNode_5623{[0]: ValueNode<Primitive> Return, [1]: CNode_5622}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787 : 0x561a1cc20f20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787(%para373_, %para374_) {
  %1(CNode_5625) = call @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:573/        if self.use_pad:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:573/        if self.use_pad:/
}
# Order:
#   1: @↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787:CNode_5625{[0]: ValueNode<FuncGraph> ✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624}
#   2: @↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787:CNode_5626{[0]: ValueNode<Primitive> Return, [1]: CNode_5625}


subgraph attr:
subgraph instance: sum_4798 : 0x561a19864b20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @sum_4798(%para375_input, %para376_dim, %para377_keepdim, %para378_dtype) {
  %1(CNode_5627) = S_Prim_isinstance(%para375_input, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12010/    if not isinstance(input, Tensor):/
  %2(CNode_5628) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12010/    if not isinstance(input, Tensor):/
  %3(CNode_5629) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12010/    if not isinstance(input, Tensor):/
  %4(CNode_5630) = Switch(%3, @✓sum_5631, @✗sum_5632)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12010/    if not isinstance(input, Tensor):/
  %5(CNode_5633) = %4()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12010/    if not isinstance(input, Tensor):/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12010/    if not isinstance(input, Tensor):/
}
# Order:
#   1: @sum_4798:CNode_5627{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_input, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   2: @sum_4798:CNode_5628{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_5627}
#   3: @sum_4798:CNode_5629{[0]: ValueNode<Primitive> Cond, [1]: CNode_5628, [2]: ValueNode<BoolImm> false}
#   4: @sum_4798:CNode_5630{[0]: ValueNode<Primitive> Switch, [1]: CNode_5629, [2]: ValueNode<FuncGraph> ✓sum_5631, [3]: ValueNode<FuncGraph> ✗sum_5632}
#   5: @sum_4798:CNode_5633{[0]: CNode_5630}
#   6: @sum_4798:CNode_5634{[0]: ValueNode<Primitive> Return, [1]: CNode_5633}


subgraph attr:
subgraph instance: ✓_get_cache_prim_4802 : 0x561a1daad4e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:35/def _get_cache_prim(cls: Primitive) -> Primitive:/
subgraph @✓_get_cache_prim_4802 parent: [subgraph @_get_cache_prim_4422]() {
  Return(@_new_prim_for_graph_5635)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:89/        return _new_prim_for_graph/
}
# Order:
#   1: @✓_get_cache_prim_4802:CNode_5636{[0]: ValueNode<Primitive> Return, [1]: ValueNode<FuncGraph> _new_prim_for_graph_5635}


subgraph attr:
training : 0
subgraph instance: ✗2↓mindspore_nn_layer_basic_Dense_construct_4805 : 0x561a1de890a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @✗2↓mindspore_nn_layer_basic_Dense_construct_4805 parent: [subgraph @✓↓mindspore_nn_layer_basic_Dense_construct_4310]() {
  %1(CNode_5638) = call @3↓mindspore_nn_layer_basic_Dense_construct_5637()
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:630/        if self.activation_flag:/
  Return(%1)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:630/        if self.activation_flag:/
}
# Order:
#   1: @✗2↓mindspore_nn_layer_basic_Dense_construct_4805:CNode_5638{[0]: ValueNode<FuncGraph> 3↓mindspore_nn_layer_basic_Dense_construct_5637}
#   2: @✗2↓mindspore_nn_layer_basic_Dense_construct_4805:CNode_5639{[0]: ValueNode<Primitive> Return, [1]: CNode_5638}


subgraph attr:
subgraph instance: ✓pad_4812 : 0x561988644de0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓pad_4812 parent: [subgraph @pad_4440]() {
  %1(CNode_5640) = S_Prim_MakeTuple("input_x")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3393/        raise TypeError(f"For 'pad', the type of 'input_x' must be Tensor, but got {type(input_x)}.")/
  %2(CNode_5641) = S_Prim_MakeTuple(%para226_input_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3393/        raise TypeError(f"For 'pad', the type of 'input_x' must be Tensor, but got {type(input_x)}.")/
  %3(CNode_5642) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3393/        raise TypeError(f"For 'pad', the type of 'input_x' must be Tensor, but got {type(input_x)}.")/
  %4(ValueNode_5643) = PyInterpret[side_effect_io: Bool(1)](Script['f"For 'pad', the type of 'input_x' must be Tensor, but got {type(input_x)}."'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3393/        raise TypeError(f"For 'pad', the type of 'input_x' must be Tensor, but got {type(input_x)}.")/
  %5(CNode_5644) = raise[side_effect_io: Bool(1)]("TypeError", %4, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3393/        raise TypeError(f"For 'pad', the type of 'input_x' must be Tensor, but got {type(input_x)}.")/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3393/        raise TypeError(f"For 'pad', the type of 'input_x' must be Tensor, but got {type(input_x)}.")/
}
# Order:
#   1: @✓pad_4812:CNode_5640{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> input_x}
#   2: @✓pad_4812:CNode_5641{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_input_x}
#   3: @✓pad_4812:CNode_5642{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5640, [2]: CNode_5641}
#   4: @✓pad_4812:ValueNode_5643{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'f"For 'pad', the type of 'input_x' must be Tensor, but got {type(input_x)}."', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'isinstance': <built-in function isinstance>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>, 'type': <class 'type'>}), [3]: CNode_5642}
#   5: @✓pad_4812:CNode_5644{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: ValueNode_5643, [3]: ValueNode<StringImm> None}
#   6: @✓pad_4812:CNode_5645{[0]: ValueNode<Primitive> Return, [1]: CNode_5644}


subgraph attr:
subgraph instance: ✗pad_4813 : 0x56198ecbe680
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗pad_4813 parent: [subgraph @pad_4440]() {
  %1(CNode_5647) = call @↓pad_5646()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3392/    if not isinstance(input_x, Tensor):/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3392/    if not isinstance(input_x, Tensor):/
}
# Order:
#   1: @✗pad_4813:CNode_5647{[0]: ValueNode<FuncGraph> ↓pad_5646}
#   2: @✗pad_4813:CNode_5648{[0]: ValueNode<Primitive> Return, [1]: CNode_5647}


subgraph attr:
subgraph instance: ✓div_4836 : 0x561a208e9b60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @✓div_4836() {
  %1(CNode_5649) = raise[side_effect_io: Bool(1)]("ValueError", "For ops.div, rounding_mode value should be None, 'floor' or 'trunc'.", "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1083/        raise ValueError("For ops.div, rounding_mode value should be None, 'floor' or 'trunc'.")/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1083/        raise ValueError("For ops.div, rounding_mode value should be None, 'floor' or 'trunc'.")/
}
# Order:
#   1: @✓div_4836:CNode_5649{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: ValueNode<StringImm> For ops.div, rounding_mode value should be None, 'floor' or 'trunc'., [3]: ValueNode<StringImm> None}
#   2: @✓div_4836:CNode_5650{[0]: ValueNode<Primitive> Return, [1]: CNode_5649}


subgraph attr:
subgraph instance: ✗div_4837 : 0x561a19a59900
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @✗div_4837 parent: [subgraph @div_4467]() {
  %1(CNode_5652) = call @↓div_5651()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
}
# Order:
#   1: @✗div_4837:CNode_5652{[0]: ValueNode<FuncGraph> ↓div_5651}
#   2: @✗div_4837:CNode_5653{[0]: ValueNode<Primitive> Return, [1]: CNode_5652}


subgraph attr:
subgraph instance: ↰div_4831 : 0x561a20b24320
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @↰div_4831 parent: [subgraph @div_4467]() {
  %1(CNode_5654) = S_Prim_make_list("floor", "trunc")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  %2(CNode_5655) = S_Prim_not_in(%para238_rounding_mode, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  Return(%2)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
}
# Order:
#   1: @↰div_4831:CNode_5654{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<StringImm> floor, [2]: ValueNode<StringImm> trunc}
#   2: @↰div_4831:CNode_5655{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_in, [1]: param_rounding_mode, [2]: CNode_5654}
#   3: @↰div_4831:CNode_5656{[0]: ValueNode<Primitive> Return, [1]: CNode_5655}


subgraph attr:
subgraph instance: ↱div_4832 : 0x56198ba20420
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @↱div_4832 parent: [subgraph @div_4467]() {
  %1(CNode_4828) = $(div_4467):S_Prim_is_not(%para238_rounding_mode, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1082/    if rounding_mode is not None and rounding_mode not in ['floor', 'trunc']:/
}
# Order:
#   1: @↱div_4832:CNode_5657{[0]: ValueNode<Primitive> Return, [1]: CNode_4828}


subgraph attr:
subgraph instance: ms_iter_4166 : 0x561985d6e640
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2345/def ms_iter(xs):/
subgraph @ms_iter_4166(%para379_xs) {
  %1(CNode_5658) = getattr(%para379_xs, "__ms_iter__")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2347/    return xs.__ms_iter__/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2347/    return xs.__ms_iter__/
}
# Order:
#   1: @ms_iter_4166:CNode_5658{[0]: ValueNode<Primitive> getattr, [1]: param_xs, [2]: ValueNode<StringImm> __ms_iter__}
#   2: @ms_iter_4166:CNode_5659{[0]: ValueNode<Primitive> Return, [1]: CNode_5658}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_4851 : 0x561a1ec208a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_4851(%para380_x, %para381_) {
  %1(CNode_5660) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para381_L_backbone.layer4.0.conv3.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5661) = S_Prim_sub(%para381_L_backbone.layer4.0.conv3.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5662) = getattr(%para381_L_backbone.layer4.0.conv3.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5663) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5664) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5665) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5666) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5667) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5668) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5670) = call @L_sqrt_5669(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(2048), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para380_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5660{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_4851:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer4.0.conv3.weight, [2]: CNode_5660}
#   3: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5662{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer4.0.conv3.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5663{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5664{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5663}
#   6: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5665{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5666{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5667{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5665, [2]: CNode_5666}
#   9: @L_mindcv_models_bit_StdConv2d_construct_4851:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5671, [1]: CNode_5662, [2]: CNode_5664, [3]: CNode_5667}
#  10: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5661{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer4.0.conv3.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5668{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_5670{[0]: ValueNode<FuncGraph> L_sqrt_5669, [1]: CNode_5668}
#  13: @L_mindcv_models_bit_StdConv2d_construct_4851:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5661, [2]: CNode_5670}
#  14: @L_mindcv_models_bit_StdConv2d_construct_4851:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_4851:CNode_4853{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_4854 : 0x56198f43bee0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4854 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_4493](%para382_, %para383_) {
  %1(CNode_4857) = $(mindspore_nn_layer_container_SequentialCell_construct_4493):MakeTuple(@mindcv_models_bit_StdConv2d_construct_5672)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_4856) = $(mindspore_nn_layer_container_SequentialCell_construct_4493):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_5673) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para382_@CNode_5674, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_5675) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_5676, @↓mindspore_nn_layer_container_SequentialCell_construct_5677)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_5678) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_4854:CNode_5673{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.10, [1]: param_@CNode_5674, [2]: CNode_4856}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_4854:CNode_5675{[0]: ValueNode<Primitive> Switch, [1]: CNode_5673, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_5676, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_5677}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_4854:CNode_5678{[0]: CNode_5675}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_4854:CNode_5679{[0]: ValueNode<Primitive> Return, [1]: CNode_5678}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_5672 : 0x5619937dd860
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_5672 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para384_x) {
  %1(CNode_5680) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para111_backbone.layer4.0.down_sample.0.weight, %1)
      : (<Ref[Tensor[Float32]], (2048, 1024, 1, 1), ref_key=:backbone.layer4.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5681) = S_Prim_sub(%para111_backbone.layer4.0.down_sample.0.weight, %2)
      : (<Ref[Tensor[Float32]], (2048, 1024, 1, 1), ref_key=:backbone.layer4.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5682) = getattr(%para111_backbone.layer4.0.down_sample.0.weight, "var")
      : (<Ref[Tensor[Float32]], (2048, 1024, 1, 1), ref_key=:backbone.layer4.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5683) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5684) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5685) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5686) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5687) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5688) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5689) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(2048), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para384_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5680{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_5672:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer4.0.down_sample.0.weight, [2]: CNode_5680}
#   3: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5682{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer4.0.down_sample.0.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5683{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5684{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5683}
#   6: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5685{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5686{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5687{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5685, [2]: CNode_5686}
#   9: @mindcv_models_bit_StdConv2d_construct_5672:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5690, [1]: CNode_5682, [2]: CNode_5684, [3]: CNode_5687}
#  10: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5681{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer4.0.down_sample.0.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5688{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5689{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_5688}
#  13: @mindcv_models_bit_StdConv2d_construct_5672:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5681, [2]: CNode_5689}
#  14: @mindcv_models_bit_StdConv2d_construct_5672:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_5672:CNode_5691{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_4868 : 0x561a14b09750
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4868 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para385_x) {
  %1(CNode_5692) = call @shape_4343(%para385_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5693) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5694) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5695) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5696) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para385_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5697) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5698) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5699) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5700) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5701) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5702) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5703) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5704) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5705) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5706) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5707) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5708) = call @reshape_4457(%para46_backbone.layer4.0.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.0.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5709) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5710) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5711) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5712) = call @reshape_4457(%para37_backbone.layer4.0.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.0.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5713) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4868:CNode_5692{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4868:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5692, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4868:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5692, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4868:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5692, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4868:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5692, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4868:CNode_5693{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4868:CNode_5695{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4868:CNode_5696{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5695}
#   9: @_cal_output_4868:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5696}
#  10: @_cal_output_4868:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4868:CNode_5698{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4868:CNode_5699{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5698}
#  13: @_cal_output_4868:CNode_5700{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5699, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4868:CNode_5701{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4868:CNode_5702{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5701, [2]: width}
#  16: @_cal_output_4868:CNode_5703{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5702, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4868:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5700, [2]: CNode_5703}
#  18: @_cal_output_4868:CNode_5704{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4868:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5704}
#  20: @_cal_output_4868:CNode_5697{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4868:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5697, [2]: std}
#  22: @_cal_output_4868:CNode_5705{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4868:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5705}
#  24: @_cal_output_4868:CNode_5706{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4868:CNode_5707{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5706, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4868:CNode_5708{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.0.gn3.gamma, [2]: CNode_5707}
#  27: @_cal_output_4868:CNode_5709{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5708}
#  28: @_cal_output_4868:CNode_5710{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4868:CNode_5711{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5710, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4868:CNode_5712{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.0.gn3.beta, [2]: CNode_5711}
#  31: @_cal_output_4868:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5709, [2]: CNode_5712}
#  32: @_cal_output_4868:CNode_5714{[0]: ValueNode<Primitive> Return, [1]: CNode_5713}


subgraph attr:
training : 0
subgraph instance: _cal_output_4890 : 0x56198a7ed220
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4890 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para386_x) {
  %1(CNode_5715) = call @shape_4343(%para386_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5716) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(1024), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5717) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5718) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5719) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para386_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5720) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5721) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5722) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5723) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5724) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5725) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5726) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5727) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5728) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5729) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5730) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5731) = call @reshape_4457(%para64_backbone.layer4.0.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer4.0.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5732) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5733) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5734) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5735) = call @reshape_4457(%para47_backbone.layer4.0.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer4.0.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5736) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4890:CNode_5715{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4890:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5715, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4890:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5715, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4890:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5715, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4890:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5715, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4890:CNode_5716{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 1024, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4890:CNode_5718{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4890:CNode_5719{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5718}
#   9: @_cal_output_4890:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5719}
#  10: @_cal_output_4890:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4890:CNode_5721{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4890:CNode_5722{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5721}
#  13: @_cal_output_4890:CNode_5723{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5722, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4890:CNode_5724{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4890:CNode_5725{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5724, [2]: width}
#  16: @_cal_output_4890:CNode_5726{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5725, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4890:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5723, [2]: CNode_5726}
#  18: @_cal_output_4890:CNode_5727{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4890:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5727}
#  20: @_cal_output_4890:CNode_5720{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4890:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5720, [2]: std}
#  22: @_cal_output_4890:CNode_5728{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4890:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5728}
#  24: @_cal_output_4890:CNode_5729{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4890:CNode_5730{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5729, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4890:CNode_5731{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.0.gn1.gamma, [2]: CNode_5730}
#  27: @_cal_output_4890:CNode_5732{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5731}
#  28: @_cal_output_4890:CNode_5733{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4890:CNode_5734{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5733, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4890:CNode_5735{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.0.gn1.beta, [2]: CNode_5734}
#  31: @_cal_output_4890:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5732, [2]: CNode_5735}
#  32: @_cal_output_4890:CNode_5737{[0]: ValueNode<Primitive> Return, [1]: CNode_5736}


subgraph attr:
training : 0
subgraph instance: _cal_output_4900 : 0x561993e87d00
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4900 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para387_x) {
  %1(CNode_5738) = call @shape_4343(%para387_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5739) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5740) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5741) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5742) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para387_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5743) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5744) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5745) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5746) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5747) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5748) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5749) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5750) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5751) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5752) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5753) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5754) = call @reshape_4457(%para110_backbone.layer4.0.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.0.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5755) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5756) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5757) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5758) = call @reshape_4457(%para87_backbone.layer4.0.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.0.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5759) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4900:CNode_5738{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4900:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5738, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4900:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5738, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4900:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5738, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4900:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5738, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4900:CNode_5739{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4900:CNode_5741{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4900:CNode_5742{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5741}
#   9: @_cal_output_4900:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5742}
#  10: @_cal_output_4900:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4900:CNode_5744{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4900:CNode_5745{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5744}
#  13: @_cal_output_4900:CNode_5746{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5745, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4900:CNode_5747{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4900:CNode_5748{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5747, [2]: width}
#  16: @_cal_output_4900:CNode_5749{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5748, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4900:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5746, [2]: CNode_5749}
#  18: @_cal_output_4900:CNode_5750{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4900:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5750}
#  20: @_cal_output_4900:CNode_5743{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4900:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5743, [2]: std}
#  22: @_cal_output_4900:CNode_5751{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4900:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5751}
#  24: @_cal_output_4900:CNode_5752{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4900:CNode_5753{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5752, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4900:CNode_5754{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.0.gn2.gamma, [2]: CNode_5753}
#  27: @_cal_output_4900:CNode_5755{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5754}
#  28: @_cal_output_4900:CNode_5756{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4900:CNode_5757{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5756, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4900:CNode_5758{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.0.gn2.beta, [2]: CNode_5757}
#  31: @_cal_output_4900:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5755, [2]: CNode_5758}
#  32: @_cal_output_4900:CNode_5760{[0]: ValueNode<Primitive> Return, [1]: CNode_5759}


subgraph attr:
training : 0
subgraph instance: _cal_output_4929 : 0x561a14659070
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4929 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para388_x) {
  %1(CNode_5761) = call @shape_4343(%para388_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5762) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5763) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5764) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5765) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para388_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5766) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5767) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5768) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5769) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5770) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5771) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5772) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5773) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5774) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5775) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5776) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5777) = call @reshape_4457(%para48_backbone.layer4.1.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.1.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5778) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5779) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5780) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5781) = call @reshape_4457(%para39_backbone.layer4.1.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.1.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5782) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4929:CNode_5761{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4929:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5761, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4929:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5761, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4929:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5761, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4929:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5761, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4929:CNode_5762{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4929:CNode_5764{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4929:CNode_5765{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5764}
#   9: @_cal_output_4929:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5765}
#  10: @_cal_output_4929:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4929:CNode_5767{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4929:CNode_5768{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5767}
#  13: @_cal_output_4929:CNode_5769{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5768, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4929:CNode_5770{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4929:CNode_5771{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5770, [2]: width}
#  16: @_cal_output_4929:CNode_5772{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5771, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4929:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5769, [2]: CNode_5772}
#  18: @_cal_output_4929:CNode_5773{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4929:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5773}
#  20: @_cal_output_4929:CNode_5766{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4929:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5766, [2]: std}
#  22: @_cal_output_4929:CNode_5774{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4929:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5774}
#  24: @_cal_output_4929:CNode_5775{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4929:CNode_5776{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5775, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4929:CNode_5777{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.1.gn3.gamma, [2]: CNode_5776}
#  27: @_cal_output_4929:CNode_5778{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5777}
#  28: @_cal_output_4929:CNode_5779{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4929:CNode_5780{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5779, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4929:CNode_5781{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.1.gn3.beta, [2]: CNode_5780}
#  31: @_cal_output_4929:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5778, [2]: CNode_5781}
#  32: @_cal_output_4929:CNode_5783{[0]: ValueNode<Primitive> Return, [1]: CNode_5782}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_4932 : 0x561a1c3d5010
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_4932(%para389_x, %para390_) {
  %1(CNode_5784) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para390_L_backbone.layer4.1.conv2.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5785) = S_Prim_sub(%para390_L_backbone.layer4.1.conv2.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5786) = getattr(%para390_L_backbone.layer4.1.conv2.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5787) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5788) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5789) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5790) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5791) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5792) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5794) = call @L_sqrt_5793(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(512), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para389_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5784{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_4932:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer4.1.conv2.weight, [2]: CNode_5784}
#   3: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5786{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer4.1.conv2.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5787{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5788{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5787}
#   6: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5789{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5790{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5791{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5789, [2]: CNode_5790}
#   9: @L_mindcv_models_bit_StdConv2d_construct_4932:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5795, [1]: CNode_5786, [2]: CNode_5788, [3]: CNode_5791}
#  10: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5785{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer4.1.conv2.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5792{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_5794{[0]: ValueNode<FuncGraph> L_sqrt_5793, [1]: CNode_5792}
#  13: @L_mindcv_models_bit_StdConv2d_construct_4932:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5785, [2]: CNode_5794}
#  14: @L_mindcv_models_bit_StdConv2d_construct_4932:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_4932:CNode_4934{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_4942 : 0x561988f465a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4942 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para391_x) {
  %1(CNode_5796) = call @shape_4343(%para391_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5797) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(2048), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5798) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5799) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5800) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para391_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5801) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5802) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5803) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5804) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5805) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5806) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5807) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5808) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5809) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5810) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5811) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5812) = call @reshape_4457(%para65_backbone.layer4.1.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (2048), ref_key=:backbone.layer4.1.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5813) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5814) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5815) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5816) = call @reshape_4457(%para49_backbone.layer4.1.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (2048), ref_key=:backbone.layer4.1.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5817) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4942:CNode_5796{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4942:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5796, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4942:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5796, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4942:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5796, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4942:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5796, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4942:CNode_5797{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 2048, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4942:CNode_5799{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4942:CNode_5800{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5799}
#   9: @_cal_output_4942:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5800}
#  10: @_cal_output_4942:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4942:CNode_5802{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4942:CNode_5803{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5802}
#  13: @_cal_output_4942:CNode_5804{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5803, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4942:CNode_5805{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4942:CNode_5806{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5805, [2]: width}
#  16: @_cal_output_4942:CNode_5807{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5806, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4942:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5804, [2]: CNode_5807}
#  18: @_cal_output_4942:CNode_5808{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4942:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5808}
#  20: @_cal_output_4942:CNode_5801{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4942:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5801, [2]: std}
#  22: @_cal_output_4942:CNode_5809{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4942:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5809}
#  24: @_cal_output_4942:CNode_5810{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4942:CNode_5811{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5810, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4942:CNode_5812{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.1.gn1.gamma, [2]: CNode_5811}
#  27: @_cal_output_4942:CNode_5813{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5812}
#  28: @_cal_output_4942:CNode_5814{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4942:CNode_5815{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5814, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4942:CNode_5816{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.1.gn1.beta, [2]: CNode_5815}
#  31: @_cal_output_4942:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5813, [2]: CNode_5816}
#  32: @_cal_output_4942:CNode_5818{[0]: ValueNode<Primitive> Return, [1]: CNode_5817}


subgraph attr:
training : 0
subgraph instance: _cal_output_4952 : 0x5619913fc130
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4952 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para392_x) {
  %1(CNode_5819) = call @shape_4343(%para392_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5820) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5821) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5822) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5823) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para392_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5824) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5825) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5826) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5827) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5828) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5829) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5830) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5831) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5832) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5833) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5834) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5835) = call @reshape_4457(%para112_backbone.layer4.1.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.1.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5836) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5837) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5838) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5839) = call @reshape_4457(%para88_backbone.layer4.1.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.1.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5840) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4952:CNode_5819{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4952:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5819, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4952:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5819, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4952:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5819, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4952:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5819, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4952:CNode_5820{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4952:CNode_5822{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4952:CNode_5823{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5822}
#   9: @_cal_output_4952:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5823}
#  10: @_cal_output_4952:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4952:CNode_5825{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4952:CNode_5826{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5825}
#  13: @_cal_output_4952:CNode_5827{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5826, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4952:CNode_5828{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4952:CNode_5829{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5828, [2]: width}
#  16: @_cal_output_4952:CNode_5830{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5829, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4952:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5827, [2]: CNode_5830}
#  18: @_cal_output_4952:CNode_5831{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4952:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5831}
#  20: @_cal_output_4952:CNode_5824{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4952:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5824, [2]: std}
#  22: @_cal_output_4952:CNode_5832{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4952:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5832}
#  24: @_cal_output_4952:CNode_5833{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4952:CNode_5834{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5833, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4952:CNode_5835{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.1.gn2.gamma, [2]: CNode_5834}
#  27: @_cal_output_4952:CNode_5836{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5835}
#  28: @_cal_output_4952:CNode_5837{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4952:CNode_5838{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5837, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4952:CNode_5839{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.1.gn2.beta, [2]: CNode_5838}
#  31: @_cal_output_4952:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5836, [2]: CNode_5839}
#  32: @_cal_output_4952:CNode_5841{[0]: ValueNode<Primitive> Return, [1]: CNode_5840}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_4955 : 0x56198671ad40
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_4955(%para393_x, %para394_) {
  %1(CNode_5842) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para394_L_backbone.layer4.1.conv1.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5843) = S_Prim_sub(%para394_L_backbone.layer4.1.conv1.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5844) = getattr(%para394_L_backbone.layer4.1.conv1.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5845) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5846) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5847) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5848) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5849) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5850) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5852) = call @L_sqrt_5851(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(512), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para393_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5842{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_4955:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer4.1.conv1.weight, [2]: CNode_5842}
#   3: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5844{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer4.1.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5845{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5846{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5845}
#   6: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5847{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5848{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5849{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5847, [2]: CNode_5848}
#   9: @L_mindcv_models_bit_StdConv2d_construct_4955:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5853, [1]: CNode_5844, [2]: CNode_5846, [3]: CNode_5849}
#  10: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5843{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer4.1.conv1.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5850{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_5852{[0]: ValueNode<FuncGraph> L_sqrt_5851, [1]: CNode_5850}
#  13: @L_mindcv_models_bit_StdConv2d_construct_4955:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5843, [2]: CNode_5852}
#  14: @L_mindcv_models_bit_StdConv2d_construct_4955:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_4955:CNode_4957{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_4972 : 0x561a137939f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4972 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para395_x) {
  %1(CNode_5854) = call @shape_4343(%para395_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5855) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5856) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5857) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5858) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para395_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5859) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5860) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5861) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5862) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5863) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5864) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5865) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5866) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5867) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5868) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5869) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5870) = call @reshape_4457(%para50_backbone.layer4.2.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.2.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5871) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5872) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5873) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5874) = call @reshape_4457(%para41_backbone.layer4.2.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.2.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5875) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4972:CNode_5854{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4972:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5854, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4972:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5854, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4972:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5854, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4972:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5854, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4972:CNode_5855{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4972:CNode_5857{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4972:CNode_5858{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5857}
#   9: @_cal_output_4972:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5858}
#  10: @_cal_output_4972:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4972:CNode_5860{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4972:CNode_5861{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5860}
#  13: @_cal_output_4972:CNode_5862{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5861, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4972:CNode_5863{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4972:CNode_5864{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5863, [2]: width}
#  16: @_cal_output_4972:CNode_5865{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5864, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4972:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5862, [2]: CNode_5865}
#  18: @_cal_output_4972:CNode_5866{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4972:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5866}
#  20: @_cal_output_4972:CNode_5859{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4972:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5859, [2]: std}
#  22: @_cal_output_4972:CNode_5867{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4972:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5867}
#  24: @_cal_output_4972:CNode_5868{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4972:CNode_5869{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5868, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4972:CNode_5870{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.2.gn3.gamma, [2]: CNode_5869}
#  27: @_cal_output_4972:CNode_5871{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5870}
#  28: @_cal_output_4972:CNode_5872{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4972:CNode_5873{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5872, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4972:CNode_5874{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.2.gn3.beta, [2]: CNode_5873}
#  31: @_cal_output_4972:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5871, [2]: CNode_5874}
#  32: @_cal_output_4972:CNode_5876{[0]: ValueNode<Primitive> Return, [1]: CNode_5875}


subgraph attr:
training : 0
subgraph instance: _cal_output_4984 : 0x5619876b42c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4984 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para396_x) {
  %1(CNode_5877) = call @shape_4343(%para396_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5878) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(2048), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5879) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5880) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5881) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para396_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5882) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5883) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5884) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5885) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5886) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5887) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5888) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5889) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5890) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5891) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5892) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5893) = call @reshape_4457(%para66_backbone.layer4.2.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (2048), ref_key=:backbone.layer4.2.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5894) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5895) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5896) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5897) = call @reshape_4457(%para51_backbone.layer4.2.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (2048), ref_key=:backbone.layer4.2.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5898) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4984:CNode_5877{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4984:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5877, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4984:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5877, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4984:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5877, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4984:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5877, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4984:CNode_5878{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 2048, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4984:CNode_5880{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4984:CNode_5881{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5880}
#   9: @_cal_output_4984:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5881}
#  10: @_cal_output_4984:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4984:CNode_5883{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4984:CNode_5884{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5883}
#  13: @_cal_output_4984:CNode_5885{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5884, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4984:CNode_5886{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4984:CNode_5887{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5886, [2]: width}
#  16: @_cal_output_4984:CNode_5888{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5887, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4984:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5885, [2]: CNode_5888}
#  18: @_cal_output_4984:CNode_5889{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4984:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5889}
#  20: @_cal_output_4984:CNode_5882{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4984:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5882, [2]: std}
#  22: @_cal_output_4984:CNode_5890{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4984:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5890}
#  24: @_cal_output_4984:CNode_5891{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4984:CNode_5892{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5891, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4984:CNode_5893{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.2.gn1.gamma, [2]: CNode_5892}
#  27: @_cal_output_4984:CNode_5894{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5893}
#  28: @_cal_output_4984:CNode_5895{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4984:CNode_5896{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5895, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4984:CNode_5897{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.2.gn1.beta, [2]: CNode_5896}
#  31: @_cal_output_4984:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5894, [2]: CNode_5897}
#  32: @_cal_output_4984:CNode_5899{[0]: ValueNode<Primitive> Return, [1]: CNode_5898}


subgraph attr:
training : 0
subgraph instance: _cal_output_4994 : 0x561a1fbbd030
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_4994 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para397_x) {
  %1(CNode_5900) = call @shape_4343(%para397_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5901) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5902) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5903) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5904) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para397_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5905) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5906) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5907) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5908) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5909) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5910) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5911) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5912) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5913) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5914) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5915) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5916) = call @reshape_4457(%para113_backbone.layer4.2.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.2.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5917) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5918) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5919) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5920) = call @reshape_4457(%para89_backbone.layer4.2.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer4.2.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5921) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_4994:CNode_5900{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_4994:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5900, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_4994:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5900, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_4994:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5900, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_4994:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5900, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_4994:CNode_5901{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_4994:CNode_5903{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_4994:CNode_5904{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5903}
#   9: @_cal_output_4994:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5904}
#  10: @_cal_output_4994:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_4994:CNode_5906{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_4994:CNode_5907{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5906}
#  13: @_cal_output_4994:CNode_5908{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5907, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_4994:CNode_5909{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_4994:CNode_5910{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5909, [2]: width}
#  16: @_cal_output_4994:CNode_5911{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5910, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_4994:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5908, [2]: CNode_5911}
#  18: @_cal_output_4994:CNode_5912{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_4994:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5912}
#  20: @_cal_output_4994:CNode_5905{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_4994:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5905, [2]: std}
#  22: @_cal_output_4994:CNode_5913{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_4994:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5913}
#  24: @_cal_output_4994:CNode_5914{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_4994:CNode_5915{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5914, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_4994:CNode_5916{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.2.gn2.gamma, [2]: CNode_5915}
#  27: @_cal_output_4994:CNode_5917{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5916}
#  28: @_cal_output_4994:CNode_5918{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_4994:CNode_5919{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5918, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_4994:CNode_5920{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer4.2.gn2.beta, [2]: CNode_5919}
#  31: @_cal_output_4994:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5917, [2]: CNode_5920}
#  32: @_cal_output_4994:CNode_5922{[0]: ValueNode<Primitive> Return, [1]: CNode_5921}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5008 : 0x561a1cd6bbc0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5008(%para398_x, %para399_) {
  %1(CNode_5923) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para399_L_backbone.layer3.0.conv3.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5924) = S_Prim_sub(%para399_L_backbone.layer3.0.conv3.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5925) = getattr(%para399_L_backbone.layer3.0.conv3.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5926) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5927) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5928) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5929) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5930) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5931) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5933) = call @L_sqrt_5932(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(1024), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para398_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5923{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5008:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer3.0.conv3.weight, [2]: CNode_5923}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5925{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer3.0.conv3.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5926{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5927{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5926}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5928{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5929{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5930{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5928, [2]: CNode_5929}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5008:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5934, [1]: CNode_5925, [2]: CNode_5927, [3]: CNode_5930}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5924{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer3.0.conv3.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5931{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5933{[0]: ValueNode<FuncGraph> L_sqrt_5932, [1]: CNode_5931}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5008:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5924, [2]: CNode_5933}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5008:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5008:CNode_5010{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_5011 : 0x56198684e6b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5011 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_4555](%para400_, %para401_) {
  %1(CNode_5014) = $(mindspore_nn_layer_container_SequentialCell_construct_4555):MakeTuple(@mindcv_models_bit_StdConv2d_construct_5935)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_5013) = $(mindspore_nn_layer_container_SequentialCell_construct_4555):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_5936) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para400_@CNode_5937, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_5938) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_5939, @↓mindspore_nn_layer_container_SequentialCell_construct_5940)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_5941) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_5011:CNode_5936{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.10, [1]: param_@CNode_5937, [2]: CNode_5013}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_5011:CNode_5938{[0]: ValueNode<Primitive> Switch, [1]: CNode_5936, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_5939, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_5940}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_5011:CNode_5941{[0]: CNode_5938}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_5011:CNode_5942{[0]: ValueNode<Primitive> Return, [1]: CNode_5941}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_5935 : 0x561a188b6e80
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_5935 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para402_x) {
  %1(CNode_5943) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para131_backbone.layer3.0.down_sample.0.weight, %1)
      : (<Ref[Tensor[Float32]], (1024, 512, 1, 1), ref_key=:backbone.layer3.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_5944) = S_Prim_sub(%para131_backbone.layer3.0.down_sample.0.weight, %2)
      : (<Ref[Tensor[Float32]], (1024, 512, 1, 1), ref_key=:backbone.layer3.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_5945) = getattr(%para131_backbone.layer3.0.down_sample.0.weight, "var")
      : (<Ref[Tensor[Float32]], (1024, 512, 1, 1), ref_key=:backbone.layer3.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_5946) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_5947) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_5948) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_5949) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_5950) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_5951) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_5952) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(1024), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para402_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5943{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_5935:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer3.0.down_sample.0.weight, [2]: CNode_5943}
#   3: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5945{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer3.0.down_sample.0.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5946{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5947{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5946}
#   6: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5948{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5949{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5950{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_5948, [2]: CNode_5949}
#   9: @mindcv_models_bit_StdConv2d_construct_5935:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.5953, [1]: CNode_5945, [2]: CNode_5947, [3]: CNode_5950}
#  10: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5944{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer3.0.down_sample.0.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5951{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5952{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_5951}
#  13: @mindcv_models_bit_StdConv2d_construct_5935:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5944, [2]: CNode_5952}
#  14: @mindcv_models_bit_StdConv2d_construct_5935:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_5935:CNode_5954{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_5025 : 0x56198682b210
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5025 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para403_x) {
  %1(CNode_5955) = call @shape_4343(%para403_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5956) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5957) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5958) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5959) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para403_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5960) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5961) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5962) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5963) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5964) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5965) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5966) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5967) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5968) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5969) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5970) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5971) = call @reshape_4457(%para67_backbone.layer3.0.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.0.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5972) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5973) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5974) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5975) = call @reshape_4457(%para52_backbone.layer3.0.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.0.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5976) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5025:CNode_5955{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5025:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5955, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5025:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5955, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5025:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5955, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5025:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5955, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5025:CNode_5956{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5025:CNode_5958{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5025:CNode_5959{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5958}
#   9: @_cal_output_5025:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5959}
#  10: @_cal_output_5025:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5025:CNode_5961{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5025:CNode_5962{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5961}
#  13: @_cal_output_5025:CNode_5963{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5962, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5025:CNode_5964{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5025:CNode_5965{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5964, [2]: width}
#  16: @_cal_output_5025:CNode_5966{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5965, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5025:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5963, [2]: CNode_5966}
#  18: @_cal_output_5025:CNode_5967{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5025:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5967}
#  20: @_cal_output_5025:CNode_5960{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5025:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5960, [2]: std}
#  22: @_cal_output_5025:CNode_5968{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5025:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5968}
#  24: @_cal_output_5025:CNode_5969{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5025:CNode_5970{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5969, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5025:CNode_5971{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.0.gn3.gamma, [2]: CNode_5970}
#  27: @_cal_output_5025:CNode_5972{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5971}
#  28: @_cal_output_5025:CNode_5973{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5025:CNode_5974{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5973, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5025:CNode_5975{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.0.gn3.beta, [2]: CNode_5974}
#  31: @_cal_output_5025:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5972, [2]: CNode_5975}
#  32: @_cal_output_5025:CNode_5977{[0]: ValueNode<Primitive> Return, [1]: CNode_5976}


subgraph attr:
training : 0
subgraph instance: _cal_output_5047 : 0x561988475490
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5047 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para404_x) {
  %1(CNode_5978) = call @shape_4343(%para404_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_5979) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_5980) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_5981) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_5982) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para404_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_5983) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_5984) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_5985) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_5986) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_5987) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_5988) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_5989) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_5990) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_5991) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_5992) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_5993) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_5994) = call @reshape_4457(%para90_backbone.layer3.0.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer3.0.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_5995) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_5996) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_5997) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_5998) = call @reshape_4457(%para68_backbone.layer3.0.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer3.0.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_5999) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5047:CNode_5978{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5047:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5978, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5047:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5978, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5047:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5978, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5047:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_5978, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5047:CNode_5979{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5047:CNode_5981{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5047:CNode_5982{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_5981}
#   9: @_cal_output_5047:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_5982}
#  10: @_cal_output_5047:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5047:CNode_5984{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5047:CNode_5985{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_5984}
#  13: @_cal_output_5047:CNode_5986{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_5985, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5047:CNode_5987{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5047:CNode_5988{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_5987, [2]: width}
#  16: @_cal_output_5047:CNode_5989{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_5988, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5047:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5986, [2]: CNode_5989}
#  18: @_cal_output_5047:CNode_5990{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5047:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_5990}
#  20: @_cal_output_5047:CNode_5983{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5047:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_5983, [2]: std}
#  22: @_cal_output_5047:CNode_5991{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5047:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_5991}
#  24: @_cal_output_5047:CNode_5992{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5047:CNode_5993{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5992, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5047:CNode_5994{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.0.gn1.gamma, [2]: CNode_5993}
#  27: @_cal_output_5047:CNode_5995{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_5994}
#  28: @_cal_output_5047:CNode_5996{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5047:CNode_5997{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_5996, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5047:CNode_5998{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.0.gn1.beta, [2]: CNode_5997}
#  31: @_cal_output_5047:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_5995, [2]: CNode_5998}
#  32: @_cal_output_5047:CNode_6000{[0]: ValueNode<Primitive> Return, [1]: CNode_5999}


subgraph attr:
training : 0
subgraph instance: _cal_output_5057 : 0x561a18d3c0c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5057 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para405_x) {
  %1(CNode_6001) = call @shape_4343(%para405_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6002) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6003) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6004) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6005) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para405_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6006) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6007) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6008) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6009) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6010) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6011) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6012) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6013) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6014) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6015) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6016) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6017) = call @reshape_4457(%para130_backbone.layer3.0.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.0.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6018) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6019) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6020) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6021) = call @reshape_4457(%para114_backbone.layer3.0.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.0.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6022) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5057:CNode_6001{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5057:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6001, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5057:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6001, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5057:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6001, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5057:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6001, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5057:CNode_6002{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5057:CNode_6004{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5057:CNode_6005{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6004}
#   9: @_cal_output_5057:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6005}
#  10: @_cal_output_5057:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5057:CNode_6007{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5057:CNode_6008{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6007}
#  13: @_cal_output_5057:CNode_6009{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6008, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5057:CNode_6010{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5057:CNode_6011{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6010, [2]: width}
#  16: @_cal_output_5057:CNode_6012{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6011, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5057:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6009, [2]: CNode_6012}
#  18: @_cal_output_5057:CNode_6013{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5057:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6013}
#  20: @_cal_output_5057:CNode_6006{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5057:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6006, [2]: std}
#  22: @_cal_output_5057:CNode_6014{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5057:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6014}
#  24: @_cal_output_5057:CNode_6015{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5057:CNode_6016{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6015, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5057:CNode_6017{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.0.gn2.gamma, [2]: CNode_6016}
#  27: @_cal_output_5057:CNode_6018{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6017}
#  28: @_cal_output_5057:CNode_6019{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5057:CNode_6020{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6019, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5057:CNode_6021{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.0.gn2.beta, [2]: CNode_6020}
#  31: @_cal_output_5057:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6018, [2]: CNode_6021}
#  32: @_cal_output_5057:CNode_6023{[0]: ValueNode<Primitive> Return, [1]: CNode_6022}


subgraph attr:
training : 0
subgraph instance: _cal_output_5086 : 0x561a1f81e3f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5086 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para406_x) {
  %1(CNode_6024) = call @shape_4343(%para406_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6025) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6026) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6027) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6028) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para406_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6029) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6030) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6031) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6032) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6033) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6034) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6035) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6036) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6037) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6038) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6039) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6040) = call @reshape_4457(%para69_backbone.layer3.1.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.1.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6041) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6042) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6043) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6044) = call @reshape_4457(%para54_backbone.layer3.1.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.1.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6045) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5086:CNode_6024{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5086:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6024, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5086:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6024, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5086:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6024, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5086:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6024, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5086:CNode_6025{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5086:CNode_6027{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5086:CNode_6028{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6027}
#   9: @_cal_output_5086:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6028}
#  10: @_cal_output_5086:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5086:CNode_6030{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5086:CNode_6031{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6030}
#  13: @_cal_output_5086:CNode_6032{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6031, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5086:CNode_6033{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5086:CNode_6034{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6033, [2]: width}
#  16: @_cal_output_5086:CNode_6035{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6034, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5086:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6032, [2]: CNode_6035}
#  18: @_cal_output_5086:CNode_6036{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5086:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6036}
#  20: @_cal_output_5086:CNode_6029{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5086:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6029, [2]: std}
#  22: @_cal_output_5086:CNode_6037{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5086:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6037}
#  24: @_cal_output_5086:CNode_6038{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5086:CNode_6039{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6038, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5086:CNode_6040{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.1.gn3.gamma, [2]: CNode_6039}
#  27: @_cal_output_5086:CNode_6041{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6040}
#  28: @_cal_output_5086:CNode_6042{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5086:CNode_6043{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6042, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5086:CNode_6044{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.1.gn3.beta, [2]: CNode_6043}
#  31: @_cal_output_5086:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6041, [2]: CNode_6044}
#  32: @_cal_output_5086:CNode_6046{[0]: ValueNode<Primitive> Return, [1]: CNode_6045}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5089 : 0x561995abe890
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5089(%para407_x, %para408_) {
  %1(CNode_6047) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para408_L_backbone.layer3.1.conv2.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6048) = S_Prim_sub(%para408_L_backbone.layer3.1.conv2.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6049) = getattr(%para408_L_backbone.layer3.1.conv2.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6050) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6051) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6052) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6053) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6054) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6055) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6057) = call @L_sqrt_6056(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(256), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para407_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6047{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5089:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer3.1.conv2.weight, [2]: CNode_6047}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6049{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer3.1.conv2.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6050{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6051{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6050}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6052{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6053{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6054{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6052, [2]: CNode_6053}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5089:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6058, [1]: CNode_6049, [2]: CNode_6051, [3]: CNode_6054}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6048{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer3.1.conv2.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6055{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_6057{[0]: ValueNode<FuncGraph> L_sqrt_6056, [1]: CNode_6055}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5089:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6048, [2]: CNode_6057}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5089:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5089:CNode_5091{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_5099 : 0x56198a741c50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5099 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para409_x) {
  %1(CNode_6059) = call @shape_4343(%para409_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6060) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(1024), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6061) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6062) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6063) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para409_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6064) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6065) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6066) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6067) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6068) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6069) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6070) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6071) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6072) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6073) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6074) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6075) = call @reshape_4457(%para91_backbone.layer3.1.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.1.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6076) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6077) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6078) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6079) = call @reshape_4457(%para70_backbone.layer3.1.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.1.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6080) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5099:CNode_6059{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5099:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6059, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5099:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6059, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5099:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6059, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5099:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6059, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5099:CNode_6060{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 1024, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5099:CNode_6062{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5099:CNode_6063{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6062}
#   9: @_cal_output_5099:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6063}
#  10: @_cal_output_5099:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5099:CNode_6065{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5099:CNode_6066{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6065}
#  13: @_cal_output_5099:CNode_6067{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6066, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5099:CNode_6068{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5099:CNode_6069{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6068, [2]: width}
#  16: @_cal_output_5099:CNode_6070{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6069, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5099:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6067, [2]: CNode_6070}
#  18: @_cal_output_5099:CNode_6071{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5099:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6071}
#  20: @_cal_output_5099:CNode_6064{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5099:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6064, [2]: std}
#  22: @_cal_output_5099:CNode_6072{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5099:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6072}
#  24: @_cal_output_5099:CNode_6073{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5099:CNode_6074{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6073, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5099:CNode_6075{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.1.gn1.gamma, [2]: CNode_6074}
#  27: @_cal_output_5099:CNode_6076{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6075}
#  28: @_cal_output_5099:CNode_6077{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5099:CNode_6078{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6077, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5099:CNode_6079{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.1.gn1.beta, [2]: CNode_6078}
#  31: @_cal_output_5099:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6076, [2]: CNode_6079}
#  32: @_cal_output_5099:CNode_6081{[0]: ValueNode<Primitive> Return, [1]: CNode_6080}


subgraph attr:
training : 0
subgraph instance: _cal_output_5109 : 0x561a19849a70
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5109 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para410_x) {
  %1(CNode_6082) = call @shape_4343(%para410_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6083) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6084) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6085) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6086) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para410_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6087) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6088) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6089) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6090) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6091) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6092) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6093) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6094) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6095) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6096) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6097) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6098) = call @reshape_4457(%para132_backbone.layer3.1.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.1.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6099) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6100) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6101) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6102) = call @reshape_4457(%para115_backbone.layer3.1.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.1.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6103) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5109:CNode_6082{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5109:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6082, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5109:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6082, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5109:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6082, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5109:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6082, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5109:CNode_6083{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5109:CNode_6085{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5109:CNode_6086{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6085}
#   9: @_cal_output_5109:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6086}
#  10: @_cal_output_5109:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5109:CNode_6088{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5109:CNode_6089{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6088}
#  13: @_cal_output_5109:CNode_6090{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6089, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5109:CNode_6091{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5109:CNode_6092{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6091, [2]: width}
#  16: @_cal_output_5109:CNode_6093{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6092, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5109:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6090, [2]: CNode_6093}
#  18: @_cal_output_5109:CNode_6094{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5109:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6094}
#  20: @_cal_output_5109:CNode_6087{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5109:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6087, [2]: std}
#  22: @_cal_output_5109:CNode_6095{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5109:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6095}
#  24: @_cal_output_5109:CNode_6096{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5109:CNode_6097{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6096, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5109:CNode_6098{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.1.gn2.gamma, [2]: CNode_6097}
#  27: @_cal_output_5109:CNode_6099{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6098}
#  28: @_cal_output_5109:CNode_6100{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5109:CNode_6101{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6100, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5109:CNode_6102{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.1.gn2.beta, [2]: CNode_6101}
#  31: @_cal_output_5109:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6099, [2]: CNode_6102}
#  32: @_cal_output_5109:CNode_6104{[0]: ValueNode<Primitive> Return, [1]: CNode_6103}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5112 : 0x561988f10fe0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5112(%para411_x, %para412_) {
  %1(CNode_6105) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para412_L_backbone.layer3.1.conv1.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6106) = S_Prim_sub(%para412_L_backbone.layer3.1.conv1.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6107) = getattr(%para412_L_backbone.layer3.1.conv1.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6108) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6109) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6110) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6111) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6112) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6113) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6115) = call @L_sqrt_6114(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(256), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para411_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6105{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5112:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer3.1.conv1.weight, [2]: CNode_6105}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6107{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer3.1.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6108{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6109{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6108}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6110{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6111{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6112{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6110, [2]: CNode_6111}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5112:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6116, [1]: CNode_6107, [2]: CNode_6109, [3]: CNode_6112}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6106{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer3.1.conv1.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6113{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_6115{[0]: ValueNode<FuncGraph> L_sqrt_6114, [1]: CNode_6113}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5112:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6106, [2]: CNode_6115}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5112:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5112:CNode_5114{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_5129 : 0x5619877be0a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5129 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para413_x) {
  %1(CNode_6117) = call @shape_4343(%para413_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6118) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6119) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6120) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6121) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para413_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6122) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6123) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6124) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6125) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6126) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6127) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6128) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6129) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6130) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6131) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6132) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6133) = call @reshape_4457(%para71_backbone.layer3.2.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.2.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6134) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6135) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6136) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6137) = call @reshape_4457(%para56_backbone.layer3.2.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.2.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6138) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5129:CNode_6117{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5129:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6117, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5129:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6117, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5129:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6117, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5129:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6117, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5129:CNode_6118{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5129:CNode_6120{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5129:CNode_6121{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6120}
#   9: @_cal_output_5129:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6121}
#  10: @_cal_output_5129:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5129:CNode_6123{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5129:CNode_6124{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6123}
#  13: @_cal_output_5129:CNode_6125{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6124, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5129:CNode_6126{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5129:CNode_6127{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6126, [2]: width}
#  16: @_cal_output_5129:CNode_6128{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6127, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5129:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6125, [2]: CNode_6128}
#  18: @_cal_output_5129:CNode_6129{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5129:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6129}
#  20: @_cal_output_5129:CNode_6122{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5129:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6122, [2]: std}
#  22: @_cal_output_5129:CNode_6130{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5129:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6130}
#  24: @_cal_output_5129:CNode_6131{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5129:CNode_6132{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6131, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5129:CNode_6133{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.2.gn3.gamma, [2]: CNode_6132}
#  27: @_cal_output_5129:CNode_6134{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6133}
#  28: @_cal_output_5129:CNode_6135{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5129:CNode_6136{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6135, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5129:CNode_6137{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.2.gn3.beta, [2]: CNode_6136}
#  31: @_cal_output_5129:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6134, [2]: CNode_6137}
#  32: @_cal_output_5129:CNode_6139{[0]: ValueNode<Primitive> Return, [1]: CNode_6138}


subgraph attr:
training : 0
subgraph instance: _cal_output_5141 : 0x56198a6c1570
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5141 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para414_x) {
  %1(CNode_6140) = call @shape_4343(%para414_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6141) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(1024), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6142) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6143) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6144) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para414_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6145) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6146) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6147) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6148) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6149) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6150) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6151) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6152) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6153) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6154) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6155) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6156) = call @reshape_4457(%para92_backbone.layer3.2.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.2.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6157) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6158) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6159) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6160) = call @reshape_4457(%para72_backbone.layer3.2.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.2.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6161) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5141:CNode_6140{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5141:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6140, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5141:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6140, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5141:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6140, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5141:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6140, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5141:CNode_6141{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 1024, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5141:CNode_6143{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5141:CNode_6144{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6143}
#   9: @_cal_output_5141:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6144}
#  10: @_cal_output_5141:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5141:CNode_6146{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5141:CNode_6147{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6146}
#  13: @_cal_output_5141:CNode_6148{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6147, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5141:CNode_6149{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5141:CNode_6150{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6149, [2]: width}
#  16: @_cal_output_5141:CNode_6151{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6150, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5141:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6148, [2]: CNode_6151}
#  18: @_cal_output_5141:CNode_6152{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5141:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6152}
#  20: @_cal_output_5141:CNode_6145{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5141:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6145, [2]: std}
#  22: @_cal_output_5141:CNode_6153{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5141:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6153}
#  24: @_cal_output_5141:CNode_6154{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5141:CNode_6155{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6154, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5141:CNode_6156{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.2.gn1.gamma, [2]: CNode_6155}
#  27: @_cal_output_5141:CNode_6157{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6156}
#  28: @_cal_output_5141:CNode_6158{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5141:CNode_6159{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6158, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5141:CNode_6160{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.2.gn1.beta, [2]: CNode_6159}
#  31: @_cal_output_5141:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6157, [2]: CNode_6160}
#  32: @_cal_output_5141:CNode_6162{[0]: ValueNode<Primitive> Return, [1]: CNode_6161}


subgraph attr:
training : 0
subgraph instance: _cal_output_5151 : 0x56198e977400
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5151 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para415_x) {
  %1(CNode_6163) = call @shape_4343(%para415_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6164) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6165) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6166) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6167) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para415_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6168) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6169) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6170) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6171) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6172) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6173) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6174) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6175) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6176) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6177) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6178) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6179) = call @reshape_4457(%para133_backbone.layer3.2.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.2.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6180) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6181) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6182) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6183) = call @reshape_4457(%para116_backbone.layer3.2.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.2.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6184) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5151:CNode_6163{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5151:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6163, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5151:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6163, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5151:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6163, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5151:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6163, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5151:CNode_6164{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5151:CNode_6166{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5151:CNode_6167{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6166}
#   9: @_cal_output_5151:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6167}
#  10: @_cal_output_5151:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5151:CNode_6169{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5151:CNode_6170{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6169}
#  13: @_cal_output_5151:CNode_6171{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6170, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5151:CNode_6172{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5151:CNode_6173{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6172, [2]: width}
#  16: @_cal_output_5151:CNode_6174{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6173, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5151:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6171, [2]: CNode_6174}
#  18: @_cal_output_5151:CNode_6175{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5151:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6175}
#  20: @_cal_output_5151:CNode_6168{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5151:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6168, [2]: std}
#  22: @_cal_output_5151:CNode_6176{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5151:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6176}
#  24: @_cal_output_5151:CNode_6177{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5151:CNode_6178{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6177, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5151:CNode_6179{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.2.gn2.gamma, [2]: CNode_6178}
#  27: @_cal_output_5151:CNode_6180{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6179}
#  28: @_cal_output_5151:CNode_6181{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5151:CNode_6182{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6181, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5151:CNode_6183{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.2.gn2.beta, [2]: CNode_6182}
#  31: @_cal_output_5151:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6180, [2]: CNode_6183}
#  32: @_cal_output_5151:CNode_6185{[0]: ValueNode<Primitive> Return, [1]: CNode_6184}


subgraph attr:
training : 0
subgraph instance: _cal_output_5170 : 0x56198a81b440
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5170 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para416_x) {
  %1(CNode_6186) = call @shape_4343(%para416_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6187) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6188) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6189) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6190) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para416_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6191) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6192) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6193) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6194) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6195) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6196) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6197) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6198) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6199) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6200) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6201) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6202) = call @reshape_4457(%para73_backbone.layer3.3.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.3.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6203) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6204) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6205) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6206) = call @reshape_4457(%para58_backbone.layer3.3.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.3.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6207) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5170:CNode_6186{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5170:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6186, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5170:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6186, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5170:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6186, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5170:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6186, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5170:CNode_6187{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5170:CNode_6189{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5170:CNode_6190{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6189}
#   9: @_cal_output_5170:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6190}
#  10: @_cal_output_5170:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5170:CNode_6192{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5170:CNode_6193{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6192}
#  13: @_cal_output_5170:CNode_6194{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6193, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5170:CNode_6195{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5170:CNode_6196{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6195, [2]: width}
#  16: @_cal_output_5170:CNode_6197{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6196, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5170:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6194, [2]: CNode_6197}
#  18: @_cal_output_5170:CNode_6198{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5170:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6198}
#  20: @_cal_output_5170:CNode_6191{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5170:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6191, [2]: std}
#  22: @_cal_output_5170:CNode_6199{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5170:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6199}
#  24: @_cal_output_5170:CNode_6200{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5170:CNode_6201{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6200, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5170:CNode_6202{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.3.gn3.gamma, [2]: CNode_6201}
#  27: @_cal_output_5170:CNode_6203{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6202}
#  28: @_cal_output_5170:CNode_6204{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5170:CNode_6205{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6204, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5170:CNode_6206{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.3.gn3.beta, [2]: CNode_6205}
#  31: @_cal_output_5170:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6203, [2]: CNode_6206}
#  32: @_cal_output_5170:CNode_6208{[0]: ValueNode<Primitive> Return, [1]: CNode_6207}


subgraph attr:
training : 0
subgraph instance: _cal_output_5182 : 0x5619882d1b60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5182 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para417_x) {
  %1(CNode_6209) = call @shape_4343(%para417_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6210) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(1024), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6211) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6212) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6213) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para417_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6214) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6215) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6216) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6217) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6218) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6219) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6220) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6221) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6222) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6223) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6224) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6225) = call @reshape_4457(%para93_backbone.layer3.3.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.3.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6226) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6227) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6228) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6229) = call @reshape_4457(%para74_backbone.layer3.3.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.3.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6230) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5182:CNode_6209{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5182:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6209, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5182:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6209, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5182:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6209, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5182:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6209, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5182:CNode_6210{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 1024, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5182:CNode_6212{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5182:CNode_6213{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6212}
#   9: @_cal_output_5182:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6213}
#  10: @_cal_output_5182:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5182:CNode_6215{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5182:CNode_6216{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6215}
#  13: @_cal_output_5182:CNode_6217{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6216, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5182:CNode_6218{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5182:CNode_6219{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6218, [2]: width}
#  16: @_cal_output_5182:CNode_6220{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6219, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5182:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6217, [2]: CNode_6220}
#  18: @_cal_output_5182:CNode_6221{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5182:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6221}
#  20: @_cal_output_5182:CNode_6214{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5182:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6214, [2]: std}
#  22: @_cal_output_5182:CNode_6222{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5182:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6222}
#  24: @_cal_output_5182:CNode_6223{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5182:CNode_6224{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6223, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5182:CNode_6225{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.3.gn1.gamma, [2]: CNode_6224}
#  27: @_cal_output_5182:CNode_6226{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6225}
#  28: @_cal_output_5182:CNode_6227{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5182:CNode_6228{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6227, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5182:CNode_6229{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.3.gn1.beta, [2]: CNode_6228}
#  31: @_cal_output_5182:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6226, [2]: CNode_6229}
#  32: @_cal_output_5182:CNode_6231{[0]: ValueNode<Primitive> Return, [1]: CNode_6230}


subgraph attr:
training : 0
subgraph instance: _cal_output_5192 : 0x561a1873c660
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5192 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para418_x) {
  %1(CNode_6232) = call @shape_4343(%para418_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6233) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6234) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6235) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6236) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para418_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6237) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6238) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6239) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6240) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6241) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6242) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6243) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6244) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6245) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6246) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6247) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6248) = call @reshape_4457(%para134_backbone.layer3.3.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.3.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6249) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6250) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6251) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6252) = call @reshape_4457(%para117_backbone.layer3.3.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.3.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6253) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5192:CNode_6232{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5192:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6232, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5192:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6232, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5192:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6232, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5192:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6232, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5192:CNode_6233{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5192:CNode_6235{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5192:CNode_6236{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6235}
#   9: @_cal_output_5192:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6236}
#  10: @_cal_output_5192:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5192:CNode_6238{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5192:CNode_6239{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6238}
#  13: @_cal_output_5192:CNode_6240{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6239, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5192:CNode_6241{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5192:CNode_6242{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6241, [2]: width}
#  16: @_cal_output_5192:CNode_6243{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6242, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5192:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6240, [2]: CNode_6243}
#  18: @_cal_output_5192:CNode_6244{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5192:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6244}
#  20: @_cal_output_5192:CNode_6237{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5192:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6237, [2]: std}
#  22: @_cal_output_5192:CNode_6245{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5192:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6245}
#  24: @_cal_output_5192:CNode_6246{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5192:CNode_6247{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6246, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5192:CNode_6248{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.3.gn2.gamma, [2]: CNode_6247}
#  27: @_cal_output_5192:CNode_6249{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6248}
#  28: @_cal_output_5192:CNode_6250{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5192:CNode_6251{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6250, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5192:CNode_6252{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.3.gn2.beta, [2]: CNode_6251}
#  31: @_cal_output_5192:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6249, [2]: CNode_6252}
#  32: @_cal_output_5192:CNode_6254{[0]: ValueNode<Primitive> Return, [1]: CNode_6253}


subgraph attr:
training : 0
subgraph instance: _cal_output_5211 : 0x56198958a820
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5211 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para419_x) {
  %1(CNode_6255) = call @shape_4343(%para419_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6256) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6257) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6258) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6259) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para419_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6260) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6261) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6262) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6263) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6264) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6265) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6266) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6267) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6268) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6269) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6270) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6271) = call @reshape_4457(%para75_backbone.layer3.4.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.4.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6272) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6273) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6274) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6275) = call @reshape_4457(%para60_backbone.layer3.4.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.4.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6276) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5211:CNode_6255{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5211:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6255, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5211:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6255, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5211:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6255, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5211:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6255, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5211:CNode_6256{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5211:CNode_6258{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5211:CNode_6259{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6258}
#   9: @_cal_output_5211:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6259}
#  10: @_cal_output_5211:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5211:CNode_6261{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5211:CNode_6262{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6261}
#  13: @_cal_output_5211:CNode_6263{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6262, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5211:CNode_6264{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5211:CNode_6265{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6264, [2]: width}
#  16: @_cal_output_5211:CNode_6266{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6265, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5211:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6263, [2]: CNode_6266}
#  18: @_cal_output_5211:CNode_6267{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5211:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6267}
#  20: @_cal_output_5211:CNode_6260{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5211:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6260, [2]: std}
#  22: @_cal_output_5211:CNode_6268{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5211:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6268}
#  24: @_cal_output_5211:CNode_6269{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5211:CNode_6270{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6269, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5211:CNode_6271{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.4.gn3.gamma, [2]: CNode_6270}
#  27: @_cal_output_5211:CNode_6272{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6271}
#  28: @_cal_output_5211:CNode_6273{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5211:CNode_6274{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6273, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5211:CNode_6275{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.4.gn3.beta, [2]: CNode_6274}
#  31: @_cal_output_5211:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6272, [2]: CNode_6275}
#  32: @_cal_output_5211:CNode_6277{[0]: ValueNode<Primitive> Return, [1]: CNode_6276}


subgraph attr:
training : 0
subgraph instance: _cal_output_5223 : 0x561994a09e80
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5223 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para420_x) {
  %1(CNode_6278) = call @shape_4343(%para420_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6279) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(1024), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6280) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6281) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6282) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para420_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6283) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6284) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6285) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6286) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6287) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6288) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6289) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6290) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6291) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6292) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6293) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6294) = call @reshape_4457(%para94_backbone.layer3.4.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.4.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6295) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6296) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6297) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6298) = call @reshape_4457(%para76_backbone.layer3.4.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.4.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6299) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5223:CNode_6278{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5223:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6278, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5223:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6278, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5223:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6278, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5223:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6278, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5223:CNode_6279{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 1024, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5223:CNode_6281{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5223:CNode_6282{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6281}
#   9: @_cal_output_5223:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6282}
#  10: @_cal_output_5223:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5223:CNode_6284{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5223:CNode_6285{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6284}
#  13: @_cal_output_5223:CNode_6286{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6285, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5223:CNode_6287{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5223:CNode_6288{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6287, [2]: width}
#  16: @_cal_output_5223:CNode_6289{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6288, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5223:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6286, [2]: CNode_6289}
#  18: @_cal_output_5223:CNode_6290{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5223:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6290}
#  20: @_cal_output_5223:CNode_6283{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5223:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6283, [2]: std}
#  22: @_cal_output_5223:CNode_6291{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5223:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6291}
#  24: @_cal_output_5223:CNode_6292{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5223:CNode_6293{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6292, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5223:CNode_6294{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.4.gn1.gamma, [2]: CNode_6293}
#  27: @_cal_output_5223:CNode_6295{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6294}
#  28: @_cal_output_5223:CNode_6296{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5223:CNode_6297{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6296, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5223:CNode_6298{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.4.gn1.beta, [2]: CNode_6297}
#  31: @_cal_output_5223:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6295, [2]: CNode_6298}
#  32: @_cal_output_5223:CNode_6300{[0]: ValueNode<Primitive> Return, [1]: CNode_6299}


subgraph attr:
training : 0
subgraph instance: _cal_output_5233 : 0x561993afcff0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5233 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para421_x) {
  %1(CNode_6301) = call @shape_4343(%para421_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6302) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6303) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6304) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6305) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para421_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6306) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6307) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6308) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6309) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6310) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6311) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6312) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6313) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6314) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6315) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6316) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6317) = call @reshape_4457(%para135_backbone.layer3.4.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.4.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6318) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6319) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6320) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6321) = call @reshape_4457(%para118_backbone.layer3.4.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.4.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6322) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/4-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5233:CNode_6301{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5233:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6301, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5233:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6301, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5233:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6301, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5233:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6301, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5233:CNode_6302{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5233:CNode_6304{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5233:CNode_6305{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6304}
#   9: @_cal_output_5233:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6305}
#  10: @_cal_output_5233:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5233:CNode_6307{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5233:CNode_6308{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6307}
#  13: @_cal_output_5233:CNode_6309{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6308, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5233:CNode_6310{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5233:CNode_6311{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6310, [2]: width}
#  16: @_cal_output_5233:CNode_6312{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6311, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5233:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6309, [2]: CNode_6312}
#  18: @_cal_output_5233:CNode_6313{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5233:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6313}
#  20: @_cal_output_5233:CNode_6306{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5233:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6306, [2]: std}
#  22: @_cal_output_5233:CNode_6314{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5233:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6314}
#  24: @_cal_output_5233:CNode_6315{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5233:CNode_6316{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6315, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5233:CNode_6317{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.4.gn2.gamma, [2]: CNode_6316}
#  27: @_cal_output_5233:CNode_6318{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6317}
#  28: @_cal_output_5233:CNode_6319{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5233:CNode_6320{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6319, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5233:CNode_6321{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.4.gn2.beta, [2]: CNode_6320}
#  31: @_cal_output_5233:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6318, [2]: CNode_6321}
#  32: @_cal_output_5233:CNode_6323{[0]: ValueNode<Primitive> Return, [1]: CNode_6322}


subgraph attr:
training : 0
subgraph instance: _cal_output_5252 : 0x56198941e4d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5252 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para422_x) {
  %1(CNode_6324) = call @shape_4343(%para422_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6325) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6326) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6327) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6328) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para422_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6329) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6330) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6331) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6332) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6333) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6334) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6335) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6336) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6337) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6338) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6339) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6340) = call @reshape_4457(%para77_backbone.layer3.5.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.5.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6341) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6342) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6343) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6344) = call @reshape_4457(%para62_backbone.layer3.5.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.5.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6345) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5252:CNode_6324{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5252:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6324, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5252:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6324, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5252:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6324, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5252:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6324, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5252:CNode_6325{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5252:CNode_6327{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5252:CNode_6328{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6327}
#   9: @_cal_output_5252:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6328}
#  10: @_cal_output_5252:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5252:CNode_6330{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5252:CNode_6331{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6330}
#  13: @_cal_output_5252:CNode_6332{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6331, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5252:CNode_6333{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5252:CNode_6334{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6333, [2]: width}
#  16: @_cal_output_5252:CNode_6335{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6334, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5252:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6332, [2]: CNode_6335}
#  18: @_cal_output_5252:CNode_6336{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5252:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6336}
#  20: @_cal_output_5252:CNode_6329{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5252:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6329, [2]: std}
#  22: @_cal_output_5252:CNode_6337{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5252:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6337}
#  24: @_cal_output_5252:CNode_6338{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5252:CNode_6339{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6338, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5252:CNode_6340{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.5.gn3.gamma, [2]: CNode_6339}
#  27: @_cal_output_5252:CNode_6341{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6340}
#  28: @_cal_output_5252:CNode_6342{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5252:CNode_6343{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6342, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5252:CNode_6344{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.5.gn3.beta, [2]: CNode_6343}
#  31: @_cal_output_5252:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6341, [2]: CNode_6344}
#  32: @_cal_output_5252:CNode_6346{[0]: ValueNode<Primitive> Return, [1]: CNode_6345}


subgraph attr:
training : 0
subgraph instance: _cal_output_5264 : 0x5619948a7c60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5264 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para423_x) {
  %1(CNode_6347) = call @shape_4343(%para423_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6348) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(1024), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6349) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6350) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6351) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para423_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6352) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6353) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6354) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6355) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6356) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6357) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6358) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6359) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6360) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6361) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6362) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6363) = call @reshape_4457(%para95_backbone.layer3.5.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.5.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6364) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6365) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6366) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6367) = call @reshape_4457(%para78_backbone.layer3.5.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (1024), ref_key=:backbone.layer3.5.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6368) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5264:CNode_6347{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5264:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6347, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5264:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6347, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5264:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6347, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5264:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6347, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5264:CNode_6348{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 1024, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5264:CNode_6350{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5264:CNode_6351{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6350}
#   9: @_cal_output_5264:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6351}
#  10: @_cal_output_5264:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5264:CNode_6353{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5264:CNode_6354{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6353}
#  13: @_cal_output_5264:CNode_6355{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6354, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5264:CNode_6356{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5264:CNode_6357{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6356, [2]: width}
#  16: @_cal_output_5264:CNode_6358{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6357, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5264:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6355, [2]: CNode_6358}
#  18: @_cal_output_5264:CNode_6359{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5264:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6359}
#  20: @_cal_output_5264:CNode_6352{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5264:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6352, [2]: std}
#  22: @_cal_output_5264:CNode_6360{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5264:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6360}
#  24: @_cal_output_5264:CNode_6361{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5264:CNode_6362{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6361, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5264:CNode_6363{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.5.gn1.gamma, [2]: CNode_6362}
#  27: @_cal_output_5264:CNode_6364{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6363}
#  28: @_cal_output_5264:CNode_6365{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5264:CNode_6366{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6365, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5264:CNode_6367{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.5.gn1.beta, [2]: CNode_6366}
#  31: @_cal_output_5264:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6364, [2]: CNode_6367}
#  32: @_cal_output_5264:CNode_6369{[0]: ValueNode<Primitive> Return, [1]: CNode_6368}


subgraph attr:
training : 0
subgraph instance: _cal_output_5274 : 0x561a147f8d50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5274 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para424_x) {
  %1(CNode_6370) = call @shape_4343(%para424_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6371) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6372) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6373) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6374) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para424_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6375) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6376) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6377) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6378) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6379) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6380) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6381) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6382) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6383) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6384) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6385) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6386) = call @reshape_4457(%para136_backbone.layer3.5.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.5.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6387) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6388) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6389) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6390) = call @reshape_4457(%para119_backbone.layer3.5.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer3.5.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6391) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/5-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5274:CNode_6370{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5274:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6370, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5274:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6370, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5274:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6370, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5274:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6370, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5274:CNode_6371{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5274:CNode_6373{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5274:CNode_6374{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6373}
#   9: @_cal_output_5274:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6374}
#  10: @_cal_output_5274:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5274:CNode_6376{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5274:CNode_6377{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6376}
#  13: @_cal_output_5274:CNode_6378{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6377, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5274:CNode_6379{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5274:CNode_6380{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6379, [2]: width}
#  16: @_cal_output_5274:CNode_6381{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6380, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5274:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6378, [2]: CNode_6381}
#  18: @_cal_output_5274:CNode_6382{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5274:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6382}
#  20: @_cal_output_5274:CNode_6375{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5274:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6375, [2]: std}
#  22: @_cal_output_5274:CNode_6383{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5274:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6383}
#  24: @_cal_output_5274:CNode_6384{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5274:CNode_6385{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6384, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5274:CNode_6386{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.5.gn2.gamma, [2]: CNode_6385}
#  27: @_cal_output_5274:CNode_6387{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6386}
#  28: @_cal_output_5274:CNode_6388{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5274:CNode_6389{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6388, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5274:CNode_6390{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer3.5.gn2.beta, [2]: CNode_6389}
#  31: @_cal_output_5274:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6387, [2]: CNode_6390}
#  32: @_cal_output_5274:CNode_6392{[0]: ValueNode<Primitive> Return, [1]: CNode_6391}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5288 : 0x561987fff4a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5288(%para425_x, %para426_) {
  %1(CNode_6393) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para426_L_backbone.layer2.0.conv3.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6394) = S_Prim_sub(%para426_L_backbone.layer2.0.conv3.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6395) = getattr(%para426_L_backbone.layer2.0.conv3.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6396) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6397) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6398) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6399) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6400) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6401) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6403) = call @L_sqrt_6402(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(512), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para425_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6393{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5288:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer2.0.conv3.weight, [2]: CNode_6393}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6395{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer2.0.conv3.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6396{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6397{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6396}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6398{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6399{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6400{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6398, [2]: CNode_6399}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5288:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6404, [1]: CNode_6395, [2]: CNode_6397, [3]: CNode_6400}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6394{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer2.0.conv3.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6401{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_6403{[0]: ValueNode<FuncGraph> L_sqrt_6402, [1]: CNode_6401}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5288:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6394, [2]: CNode_6403}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5288:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5288:CNode_5290{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_5291 : 0x561a1ec19de0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5291 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_4663](%para427_, %para428_) {
  %1(CNode_5294) = $(mindspore_nn_layer_container_SequentialCell_construct_4663):MakeTuple(@mindcv_models_bit_StdConv2d_construct_6405)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_5293) = $(mindspore_nn_layer_container_SequentialCell_construct_4663):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_6406) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para427_@CNode_6407, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_6408) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_6409, @↓mindspore_nn_layer_container_SequentialCell_construct_6410)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_6411) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_5291:CNode_6406{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.10, [1]: param_@CNode_6407, [2]: CNode_5293}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_5291:CNode_6408{[0]: ValueNode<Primitive> Switch, [1]: CNode_6406, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_6409, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_6410}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_5291:CNode_6411{[0]: CNode_6408}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_5291:CNode_6412{[0]: ValueNode<Primitive> Return, [1]: CNode_6411}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_6405 : 0x561a1d1b9490
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_6405 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para429_x) {
  %1(CNode_6413) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para145_backbone.layer2.0.down_sample.0.weight, %1)
      : (<Ref[Tensor[Float32]], (512, 256, 1, 1), ref_key=:backbone.layer2.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6414) = S_Prim_sub(%para145_backbone.layer2.0.down_sample.0.weight, %2)
      : (<Ref[Tensor[Float32]], (512, 256, 1, 1), ref_key=:backbone.layer2.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6415) = getattr(%para145_backbone.layer2.0.down_sample.0.weight, "var")
      : (<Ref[Tensor[Float32]], (512, 256, 1, 1), ref_key=:backbone.layer2.0.down_sample.0.weight>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6416) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6417) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6418) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6419) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6420) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6421) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6422) = call @sqrt_4409(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(512), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para429_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6413{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @mindcv_models_bit_StdConv2d_construct_6405:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_backbone.layer2.0.down_sample.0.weight, [2]: CNode_6413}
#   3: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6415{[0]: ValueNode<Primitive> getattr, [1]: param_backbone.layer2.0.down_sample.0.weight, [2]: ValueNode<StringImm> var}
#   4: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6416{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6417{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6416}
#   6: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6418{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6419{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6420{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6418, [2]: CNode_6419}
#   9: @mindcv_models_bit_StdConv2d_construct_6405:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6423, [1]: CNode_6415, [2]: CNode_6417, [3]: CNode_6420}
#  10: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6414{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_backbone.layer2.0.down_sample.0.weight, [2]: m}
#  11: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6421{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6422{[0]: ValueNode<FuncGraph> sqrt_4409, [1]: CNode_6421}
#  13: @mindcv_models_bit_StdConv2d_construct_6405:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6414, [2]: CNode_6422}
#  14: @mindcv_models_bit_StdConv2d_construct_6405:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @mindcv_models_bit_StdConv2d_construct_6405:CNode_6424{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_5305 : 0x561993e12310
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5305 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para430_x) {
  %1(CNode_6425) = call @shape_4343(%para430_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6426) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(128), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6427) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6428) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6429) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para430_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6430) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6431) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6432) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6433) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6434) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6435) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6436) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6437) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6438) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6439) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6440) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6441) = call @reshape_4457(%para96_backbone.layer2.0.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.0.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6442) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6443) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6444) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6445) = call @reshape_4457(%para79_backbone.layer2.0.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.0.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6446) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5305:CNode_6425{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5305:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6425, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5305:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6425, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5305:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6425, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5305:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6425, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5305:CNode_6426{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 128, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5305:CNode_6428{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5305:CNode_6429{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6428}
#   9: @_cal_output_5305:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6429}
#  10: @_cal_output_5305:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5305:CNode_6431{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5305:CNode_6432{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6431}
#  13: @_cal_output_5305:CNode_6433{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6432, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5305:CNode_6434{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5305:CNode_6435{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6434, [2]: width}
#  16: @_cal_output_5305:CNode_6436{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6435, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5305:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6433, [2]: CNode_6436}
#  18: @_cal_output_5305:CNode_6437{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5305:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6437}
#  20: @_cal_output_5305:CNode_6430{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5305:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6430, [2]: std}
#  22: @_cal_output_5305:CNode_6438{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5305:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6438}
#  24: @_cal_output_5305:CNode_6439{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5305:CNode_6440{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6439, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5305:CNode_6441{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.0.gn3.gamma, [2]: CNode_6440}
#  27: @_cal_output_5305:CNode_6442{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6441}
#  28: @_cal_output_5305:CNode_6443{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5305:CNode_6444{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6443, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5305:CNode_6445{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.0.gn3.beta, [2]: CNode_6444}
#  31: @_cal_output_5305:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6442, [2]: CNode_6445}
#  32: @_cal_output_5305:CNode_6447{[0]: ValueNode<Primitive> Return, [1]: CNode_6446}


subgraph attr:
training : 0
subgraph instance: _cal_output_5327 : 0x561a199c4770
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5327 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para431_x) {
  %1(CNode_6448) = call @shape_4343(%para431_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6449) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6450) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6451) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6452) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para431_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6453) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6454) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6455) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6456) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6457) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6458) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6459) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6460) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6461) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6462) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6463) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6464) = call @reshape_4457(%para120_backbone.layer2.0.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer2.0.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6465) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6466) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6467) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6468) = call @reshape_4457(%para97_backbone.layer2.0.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer2.0.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6469) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5327:CNode_6448{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5327:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6448, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5327:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6448, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5327:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6448, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5327:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6448, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5327:CNode_6449{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5327:CNode_6451{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5327:CNode_6452{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6451}
#   9: @_cal_output_5327:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6452}
#  10: @_cal_output_5327:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5327:CNode_6454{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5327:CNode_6455{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6454}
#  13: @_cal_output_5327:CNode_6456{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6455, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5327:CNode_6457{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5327:CNode_6458{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6457, [2]: width}
#  16: @_cal_output_5327:CNode_6459{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6458, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5327:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6456, [2]: CNode_6459}
#  18: @_cal_output_5327:CNode_6460{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5327:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6460}
#  20: @_cal_output_5327:CNode_6453{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5327:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6453, [2]: std}
#  22: @_cal_output_5327:CNode_6461{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5327:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6461}
#  24: @_cal_output_5327:CNode_6462{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5327:CNode_6463{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6462, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5327:CNode_6464{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.0.gn1.gamma, [2]: CNode_6463}
#  27: @_cal_output_5327:CNode_6465{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6464}
#  28: @_cal_output_5327:CNode_6466{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5327:CNode_6467{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6466, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5327:CNode_6468{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.0.gn1.beta, [2]: CNode_6467}
#  31: @_cal_output_5327:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6465, [2]: CNode_6468}
#  32: @_cal_output_5327:CNode_6470{[0]: ValueNode<Primitive> Return, [1]: CNode_6469}


subgraph attr:
training : 0
subgraph instance: _cal_output_5337 : 0x561a1d0f0fa0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5337 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para432_x) {
  %1(CNode_6471) = call @shape_4343(%para432_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6472) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(128), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6473) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6474) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6475) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para432_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6476) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6477) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6478) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6479) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6480) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6481) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6482) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6483) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6484) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6485) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6486) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6487) = call @reshape_4457(%para144_backbone.layer2.0.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.0.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6488) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6489) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6490) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6491) = call @reshape_4457(%para137_backbone.layer2.0.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.0.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6492) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5337:CNode_6471{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5337:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6471, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5337:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6471, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5337:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6471, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5337:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6471, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5337:CNode_6472{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 128, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5337:CNode_6474{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5337:CNode_6475{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6474}
#   9: @_cal_output_5337:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6475}
#  10: @_cal_output_5337:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5337:CNode_6477{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5337:CNode_6478{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6477}
#  13: @_cal_output_5337:CNode_6479{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6478, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5337:CNode_6480{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5337:CNode_6481{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6480, [2]: width}
#  16: @_cal_output_5337:CNode_6482{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6481, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5337:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6479, [2]: CNode_6482}
#  18: @_cal_output_5337:CNode_6483{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5337:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6483}
#  20: @_cal_output_5337:CNode_6476{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5337:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6476, [2]: std}
#  22: @_cal_output_5337:CNode_6484{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5337:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6484}
#  24: @_cal_output_5337:CNode_6485{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5337:CNode_6486{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6485, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5337:CNode_6487{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.0.gn2.gamma, [2]: CNode_6486}
#  27: @_cal_output_5337:CNode_6488{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6487}
#  28: @_cal_output_5337:CNode_6489{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5337:CNode_6490{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6489, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5337:CNode_6491{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.0.gn2.beta, [2]: CNode_6490}
#  31: @_cal_output_5337:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6488, [2]: CNode_6491}
#  32: @_cal_output_5337:CNode_6493{[0]: ValueNode<Primitive> Return, [1]: CNode_6492}


subgraph attr:
training : 0
subgraph instance: _cal_output_5366 : 0x561993d15660
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5366 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para433_x) {
  %1(CNode_6494) = call @shape_4343(%para433_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6495) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(128), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6496) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6497) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6498) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para433_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6499) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6500) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6501) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6502) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6503) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6504) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6505) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6506) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6507) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6508) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6509) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6510) = call @reshape_4457(%para98_backbone.layer2.1.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.1.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6511) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6512) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6513) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6514) = call @reshape_4457(%para81_backbone.layer2.1.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.1.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6515) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5366:CNode_6494{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5366:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6494, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5366:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6494, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5366:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6494, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5366:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6494, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5366:CNode_6495{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 128, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5366:CNode_6497{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5366:CNode_6498{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6497}
#   9: @_cal_output_5366:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6498}
#  10: @_cal_output_5366:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5366:CNode_6500{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5366:CNode_6501{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6500}
#  13: @_cal_output_5366:CNode_6502{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6501, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5366:CNode_6503{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5366:CNode_6504{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6503, [2]: width}
#  16: @_cal_output_5366:CNode_6505{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6504, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5366:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6502, [2]: CNode_6505}
#  18: @_cal_output_5366:CNode_6506{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5366:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6506}
#  20: @_cal_output_5366:CNode_6499{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5366:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6499, [2]: std}
#  22: @_cal_output_5366:CNode_6507{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5366:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6507}
#  24: @_cal_output_5366:CNode_6508{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5366:CNode_6509{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6508, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5366:CNode_6510{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.1.gn3.gamma, [2]: CNode_6509}
#  27: @_cal_output_5366:CNode_6511{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6510}
#  28: @_cal_output_5366:CNode_6512{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5366:CNode_6513{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6512, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5366:CNode_6514{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.1.gn3.beta, [2]: CNode_6513}
#  31: @_cal_output_5366:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6511, [2]: CNode_6514}
#  32: @_cal_output_5366:CNode_6516{[0]: ValueNode<Primitive> Return, [1]: CNode_6515}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5369 : 0x561a1923c400
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5369(%para434_x, %para435_) {
  %1(CNode_6517) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para435_L_backbone.layer2.1.conv2.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6518) = S_Prim_sub(%para435_L_backbone.layer2.1.conv2.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6519) = getattr(%para435_L_backbone.layer2.1.conv2.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6520) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6521) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6522) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6523) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6524) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6525) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6527) = call @L_sqrt_6526(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(128), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para434_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6517{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5369:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer2.1.conv2.weight, [2]: CNode_6517}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6519{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer2.1.conv2.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6520{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6521{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6520}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6522{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6523{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6524{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6522, [2]: CNode_6523}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5369:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6528, [1]: CNode_6519, [2]: CNode_6521, [3]: CNode_6524}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6518{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer2.1.conv2.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6525{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_6527{[0]: ValueNode<FuncGraph> L_sqrt_6526, [1]: CNode_6525}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5369:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6518, [2]: CNode_6527}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5369:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5369:CNode_5371{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_5379 : 0x561a199bac20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5379 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para436_x) {
  %1(CNode_6529) = call @shape_4343(%para436_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6530) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6531) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6532) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6533) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para436_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6534) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6535) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6536) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6537) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6538) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6539) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6540) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6541) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6542) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6543) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6544) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6545) = call @reshape_4457(%para121_backbone.layer2.1.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.1.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6546) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6547) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6548) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6549) = call @reshape_4457(%para99_backbone.layer2.1.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.1.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6550) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5379:CNode_6529{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5379:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6529, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5379:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6529, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5379:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6529, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5379:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6529, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5379:CNode_6530{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5379:CNode_6532{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5379:CNode_6533{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6532}
#   9: @_cal_output_5379:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6533}
#  10: @_cal_output_5379:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5379:CNode_6535{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5379:CNode_6536{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6535}
#  13: @_cal_output_5379:CNode_6537{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6536, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5379:CNode_6538{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5379:CNode_6539{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6538, [2]: width}
#  16: @_cal_output_5379:CNode_6540{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6539, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5379:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6537, [2]: CNode_6540}
#  18: @_cal_output_5379:CNode_6541{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5379:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6541}
#  20: @_cal_output_5379:CNode_6534{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5379:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6534, [2]: std}
#  22: @_cal_output_5379:CNode_6542{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5379:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6542}
#  24: @_cal_output_5379:CNode_6543{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5379:CNode_6544{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6543, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5379:CNode_6545{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.1.gn1.gamma, [2]: CNode_6544}
#  27: @_cal_output_5379:CNode_6546{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6545}
#  28: @_cal_output_5379:CNode_6547{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5379:CNode_6548{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6547, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5379:CNode_6549{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.1.gn1.beta, [2]: CNode_6548}
#  31: @_cal_output_5379:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6546, [2]: CNode_6549}
#  32: @_cal_output_5379:CNode_6551{[0]: ValueNode<Primitive> Return, [1]: CNode_6550}


subgraph attr:
training : 0
subgraph instance: _cal_output_5389 : 0x5619880b3140
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5389 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para437_x) {
  %1(CNode_6552) = call @shape_4343(%para437_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6553) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(128), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6554) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6555) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6556) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para437_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6557) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6558) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6559) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6560) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6561) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6562) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6563) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6564) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6565) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6566) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6567) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6568) = call @reshape_4457(%para146_backbone.layer2.1.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.1.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6569) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6570) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6571) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6572) = call @reshape_4457(%para138_backbone.layer2.1.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.1.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6573) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5389:CNode_6552{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5389:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6552, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5389:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6552, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5389:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6552, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5389:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6552, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5389:CNode_6553{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 128, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5389:CNode_6555{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5389:CNode_6556{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6555}
#   9: @_cal_output_5389:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6556}
#  10: @_cal_output_5389:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5389:CNode_6558{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5389:CNode_6559{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6558}
#  13: @_cal_output_5389:CNode_6560{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6559, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5389:CNode_6561{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5389:CNode_6562{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6561, [2]: width}
#  16: @_cal_output_5389:CNode_6563{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6562, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5389:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6560, [2]: CNode_6563}
#  18: @_cal_output_5389:CNode_6564{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5389:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6564}
#  20: @_cal_output_5389:CNode_6557{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5389:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6557, [2]: std}
#  22: @_cal_output_5389:CNode_6565{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5389:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6565}
#  24: @_cal_output_5389:CNode_6566{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5389:CNode_6567{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6566, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5389:CNode_6568{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.1.gn2.gamma, [2]: CNode_6567}
#  27: @_cal_output_5389:CNode_6569{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6568}
#  28: @_cal_output_5389:CNode_6570{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5389:CNode_6571{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6570, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5389:CNode_6572{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.1.gn2.beta, [2]: CNode_6571}
#  31: @_cal_output_5389:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6569, [2]: CNode_6572}
#  32: @_cal_output_5389:CNode_6574{[0]: ValueNode<Primitive> Return, [1]: CNode_6573}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5392 : 0x561993f05060
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5392(%para438_x, %para439_) {
  %1(CNode_6575) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para439_L_backbone.layer2.1.conv1.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6576) = S_Prim_sub(%para439_L_backbone.layer2.1.conv1.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6577) = getattr(%para439_L_backbone.layer2.1.conv1.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6578) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6579) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6580) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6581) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6582) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6583) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6585) = call @L_sqrt_6584(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(128), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para438_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6575{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5392:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer2.1.conv1.weight, [2]: CNode_6575}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6577{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer2.1.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6578{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6579{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6578}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6580{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6581{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6582{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6580, [2]: CNode_6581}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5392:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6586, [1]: CNode_6577, [2]: CNode_6579, [3]: CNode_6582}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6576{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer2.1.conv1.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6583{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_6585{[0]: ValueNode<FuncGraph> L_sqrt_6584, [1]: CNode_6583}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5392:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6576, [2]: CNode_6585}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5392:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5392:CNode_5394{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_5409 : 0x561993cede60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5409 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para440_x) {
  %1(CNode_6587) = call @shape_4343(%para440_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6588) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(128), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6589) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6590) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6591) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para440_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6592) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6593) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6594) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6595) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6596) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6597) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6598) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6599) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6600) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6601) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6602) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6603) = call @reshape_4457(%para100_backbone.layer2.2.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.2.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6604) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6605) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6606) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6607) = call @reshape_4457(%para83_backbone.layer2.2.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.2.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6608) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5409:CNode_6587{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5409:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6587, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5409:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6587, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5409:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6587, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5409:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6587, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5409:CNode_6588{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 128, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5409:CNode_6590{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5409:CNode_6591{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6590}
#   9: @_cal_output_5409:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6591}
#  10: @_cal_output_5409:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5409:CNode_6593{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5409:CNode_6594{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6593}
#  13: @_cal_output_5409:CNode_6595{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6594, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5409:CNode_6596{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5409:CNode_6597{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6596, [2]: width}
#  16: @_cal_output_5409:CNode_6598{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6597, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5409:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6595, [2]: CNode_6598}
#  18: @_cal_output_5409:CNode_6599{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5409:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6599}
#  20: @_cal_output_5409:CNode_6592{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5409:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6592, [2]: std}
#  22: @_cal_output_5409:CNode_6600{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5409:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6600}
#  24: @_cal_output_5409:CNode_6601{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5409:CNode_6602{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6601, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5409:CNode_6603{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.2.gn3.gamma, [2]: CNode_6602}
#  27: @_cal_output_5409:CNode_6604{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6603}
#  28: @_cal_output_5409:CNode_6605{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5409:CNode_6606{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6605, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5409:CNode_6607{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.2.gn3.beta, [2]: CNode_6606}
#  31: @_cal_output_5409:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6604, [2]: CNode_6607}
#  32: @_cal_output_5409:CNode_6609{[0]: ValueNode<Primitive> Return, [1]: CNode_6608}


subgraph attr:
training : 0
subgraph instance: _cal_output_5421 : 0x561a19801810
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5421 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para441_x) {
  %1(CNode_6610) = call @shape_4343(%para441_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6611) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6612) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6613) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6614) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para441_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6615) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6616) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6617) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6618) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6619) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6620) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6621) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6622) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6623) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6624) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6625) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6626) = call @reshape_4457(%para122_backbone.layer2.2.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.2.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6627) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6628) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6629) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6630) = call @reshape_4457(%para101_backbone.layer2.2.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.2.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6631) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5421:CNode_6610{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5421:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6610, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5421:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6610, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5421:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6610, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5421:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6610, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5421:CNode_6611{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5421:CNode_6613{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5421:CNode_6614{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6613}
#   9: @_cal_output_5421:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6614}
#  10: @_cal_output_5421:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5421:CNode_6616{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5421:CNode_6617{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6616}
#  13: @_cal_output_5421:CNode_6618{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6617, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5421:CNode_6619{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5421:CNode_6620{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6619, [2]: width}
#  16: @_cal_output_5421:CNode_6621{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6620, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5421:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6618, [2]: CNode_6621}
#  18: @_cal_output_5421:CNode_6622{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5421:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6622}
#  20: @_cal_output_5421:CNode_6615{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5421:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6615, [2]: std}
#  22: @_cal_output_5421:CNode_6623{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5421:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6623}
#  24: @_cal_output_5421:CNode_6624{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5421:CNode_6625{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6624, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5421:CNode_6626{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.2.gn1.gamma, [2]: CNode_6625}
#  27: @_cal_output_5421:CNode_6627{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6626}
#  28: @_cal_output_5421:CNode_6628{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5421:CNode_6629{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6628, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5421:CNode_6630{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.2.gn1.beta, [2]: CNode_6629}
#  31: @_cal_output_5421:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6627, [2]: CNode_6630}
#  32: @_cal_output_5421:CNode_6632{[0]: ValueNode<Primitive> Return, [1]: CNode_6631}


subgraph attr:
training : 0
subgraph instance: _cal_output_5431 : 0x561993a9d070
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5431 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para442_x) {
  %1(CNode_6633) = call @shape_4343(%para442_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6634) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(128), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6635) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6636) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6637) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para442_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6638) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6639) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6640) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6641) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6642) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6643) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6644) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6645) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6646) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6647) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6648) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6649) = call @reshape_4457(%para147_backbone.layer2.2.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.2.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6650) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6651) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6652) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6653) = call @reshape_4457(%para139_backbone.layer2.2.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.2.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6654) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5431:CNode_6633{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5431:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6633, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5431:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6633, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5431:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6633, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5431:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6633, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5431:CNode_6634{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 128, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5431:CNode_6636{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5431:CNode_6637{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6636}
#   9: @_cal_output_5431:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6637}
#  10: @_cal_output_5431:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5431:CNode_6639{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5431:CNode_6640{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6639}
#  13: @_cal_output_5431:CNode_6641{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6640, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5431:CNode_6642{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5431:CNode_6643{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6642, [2]: width}
#  16: @_cal_output_5431:CNode_6644{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6643, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5431:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6641, [2]: CNode_6644}
#  18: @_cal_output_5431:CNode_6645{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5431:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6645}
#  20: @_cal_output_5431:CNode_6638{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5431:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6638, [2]: std}
#  22: @_cal_output_5431:CNode_6646{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5431:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6646}
#  24: @_cal_output_5431:CNode_6647{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5431:CNode_6648{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6647, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5431:CNode_6649{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.2.gn2.gamma, [2]: CNode_6648}
#  27: @_cal_output_5431:CNode_6650{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6649}
#  28: @_cal_output_5431:CNode_6651{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5431:CNode_6652{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6651, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5431:CNode_6653{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.2.gn2.beta, [2]: CNode_6652}
#  31: @_cal_output_5431:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6650, [2]: CNode_6653}
#  32: @_cal_output_5431:CNode_6655{[0]: ValueNode<Primitive> Return, [1]: CNode_6654}


subgraph attr:
training : 0
subgraph instance: _cal_output_5450 : 0x561993b557e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5450 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para443_x) {
  %1(CNode_6656) = call @shape_4343(%para443_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6657) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(128), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6658) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6659) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6660) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para443_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6661) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6662) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6663) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6664) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6665) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6666) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6667) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6668) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6669) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6670) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6671) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6672) = call @reshape_4457(%para102_backbone.layer2.3.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.3.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6673) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6674) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6675) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6676) = call @reshape_4457(%para85_backbone.layer2.3.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.3.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6677) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5450:CNode_6656{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5450:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6656, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5450:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6656, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5450:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6656, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5450:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6656, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5450:CNode_6657{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 128, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5450:CNode_6659{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5450:CNode_6660{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6659}
#   9: @_cal_output_5450:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6660}
#  10: @_cal_output_5450:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5450:CNode_6662{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5450:CNode_6663{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6662}
#  13: @_cal_output_5450:CNode_6664{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6663, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5450:CNode_6665{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5450:CNode_6666{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6665, [2]: width}
#  16: @_cal_output_5450:CNode_6667{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6666, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5450:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6664, [2]: CNode_6667}
#  18: @_cal_output_5450:CNode_6668{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5450:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6668}
#  20: @_cal_output_5450:CNode_6661{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5450:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6661, [2]: std}
#  22: @_cal_output_5450:CNode_6669{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5450:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6669}
#  24: @_cal_output_5450:CNode_6670{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5450:CNode_6671{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6670, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5450:CNode_6672{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.3.gn3.gamma, [2]: CNode_6671}
#  27: @_cal_output_5450:CNode_6673{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6672}
#  28: @_cal_output_5450:CNode_6674{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5450:CNode_6675{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6674, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5450:CNode_6676{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.3.gn3.beta, [2]: CNode_6675}
#  31: @_cal_output_5450:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6673, [2]: CNode_6676}
#  32: @_cal_output_5450:CNode_6678{[0]: ValueNode<Primitive> Return, [1]: CNode_6677}


subgraph attr:
training : 0
subgraph instance: _cal_output_5462 : 0x561a197d73b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5462 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para444_x) {
  %1(CNode_6679) = call @shape_4343(%para444_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6680) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(512), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6681) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6682) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6683) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para444_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6684) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6685) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6686) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6687) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6688) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6689) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6690) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6691) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6692) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6693) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6694) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6695) = call @reshape_4457(%para123_backbone.layer2.3.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.3.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6696) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6697) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6698) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6699) = call @reshape_4457(%para103_backbone.layer2.3.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (512), ref_key=:backbone.layer2.3.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6700) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5462:CNode_6679{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5462:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6679, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5462:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6679, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5462:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6679, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5462:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6679, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5462:CNode_6680{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 512, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5462:CNode_6682{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5462:CNode_6683{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6682}
#   9: @_cal_output_5462:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6683}
#  10: @_cal_output_5462:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5462:CNode_6685{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5462:CNode_6686{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6685}
#  13: @_cal_output_5462:CNode_6687{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6686, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5462:CNode_6688{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5462:CNode_6689{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6688, [2]: width}
#  16: @_cal_output_5462:CNode_6690{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6689, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5462:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6687, [2]: CNode_6690}
#  18: @_cal_output_5462:CNode_6691{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5462:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6691}
#  20: @_cal_output_5462:CNode_6684{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5462:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6684, [2]: std}
#  22: @_cal_output_5462:CNode_6692{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5462:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6692}
#  24: @_cal_output_5462:CNode_6693{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5462:CNode_6694{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6693, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5462:CNode_6695{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.3.gn1.gamma, [2]: CNode_6694}
#  27: @_cal_output_5462:CNode_6696{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6695}
#  28: @_cal_output_5462:CNode_6697{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5462:CNode_6698{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6697, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5462:CNode_6699{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.3.gn1.beta, [2]: CNode_6698}
#  31: @_cal_output_5462:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6696, [2]: CNode_6699}
#  32: @_cal_output_5462:CNode_6701{[0]: ValueNode<Primitive> Return, [1]: CNode_6700}


subgraph attr:
training : 0
subgraph instance: _cal_output_5472 : 0x561a1d2042e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5472 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para445_x) {
  %1(CNode_6702) = call @shape_4343(%para445_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6703) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(128), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6704) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6705) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6706) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para445_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6707) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6708) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6709) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6710) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6711) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6712) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6713) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6714) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6715) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6716) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6717) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6718) = call @reshape_4457(%para148_backbone.layer2.3.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.3.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6719) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6720) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6721) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6722) = call @reshape_4457(%para140_backbone.layer2.3.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (128), ref_key=:backbone.layer2.3.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6723) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/3-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5472:CNode_6702{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5472:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6702, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5472:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6702, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5472:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6702, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5472:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6702, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5472:CNode_6703{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 128, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5472:CNode_6705{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5472:CNode_6706{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6705}
#   9: @_cal_output_5472:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6706}
#  10: @_cal_output_5472:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5472:CNode_6708{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5472:CNode_6709{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6708}
#  13: @_cal_output_5472:CNode_6710{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6709, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5472:CNode_6711{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5472:CNode_6712{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6711, [2]: width}
#  16: @_cal_output_5472:CNode_6713{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6712, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5472:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6710, [2]: CNode_6713}
#  18: @_cal_output_5472:CNode_6714{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5472:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6714}
#  20: @_cal_output_5472:CNode_6707{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5472:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6707, [2]: std}
#  22: @_cal_output_5472:CNode_6715{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5472:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6715}
#  24: @_cal_output_5472:CNode_6716{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5472:CNode_6717{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6716, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5472:CNode_6718{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.3.gn2.gamma, [2]: CNode_6717}
#  27: @_cal_output_5472:CNode_6719{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6718}
#  28: @_cal_output_5472:CNode_6720{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5472:CNode_6721{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6720, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5472:CNode_6722{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer2.3.gn2.beta, [2]: CNode_6721}
#  31: @_cal_output_5472:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6719, [2]: CNode_6722}
#  32: @_cal_output_5472:CNode_6724{[0]: ValueNode<Primitive> Return, [1]: CNode_6723}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5486 : 0x561a1c5eaaa0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5486(%para446_x, %para447_) {
  %1(CNode_6725) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para447_L_backbone.layer1.0.conv3.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6726) = S_Prim_sub(%para447_L_backbone.layer1.0.conv3.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6727) = getattr(%para447_L_backbone.layer1.0.conv3.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6728) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6729) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6730) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6731) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6732) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6733) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6735) = call @L_sqrt_6734(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(256), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para446_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv3-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6725{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5486:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer1.0.conv3.weight, [2]: CNode_6725}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6727{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer1.0.conv3.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6728{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6729{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6728}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6730{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6731{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6732{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6730, [2]: CNode_6731}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5486:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6736, [1]: CNode_6727, [2]: CNode_6729, [3]: CNode_6732}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6726{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer1.0.conv3.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6733{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_6735{[0]: ValueNode<FuncGraph> L_sqrt_6734, [1]: CNode_6733}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5486:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6726, [2]: CNode_6735}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5486:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5486:CNode_5488{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_5489 : 0x56199194abd0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5489 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_4738](%para448_, %para449_) {
  %1(CNode_5492) = $(mindspore_nn_layer_container_SequentialCell_construct_4738):MakeTuple(@mindcv_models_bit_StdConv2d_construct_6737)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_5491) = $(mindspore_nn_layer_container_SequentialCell_construct_4738):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_6738) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para448_@CNode_6739, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_6740) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_6741, @↓mindspore_nn_layer_container_SequentialCell_construct_6742)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_6743) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_5489:CNode_6738{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.10, [1]: param_@CNode_6739, [2]: CNode_5491}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_5489:CNode_6740{[0]: ValueNode<Primitive> Switch, [1]: CNode_6738, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_6741, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_6742}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_5489:CNode_6743{[0]: CNode_6740}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_5489:CNode_6744{[0]: ValueNode<Primitive> Return, [1]: CNode_6743}


subgraph attr:
training : 0
subgraph instance: mindcv_models_bit_StdConv2d_construct_6737 : 0x561a18369790
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @mindcv_models_bit_StdConv2d_construct_6737 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para450_x) {
  %1(CNode_6745) = call @L_mindcv_models_bit_StdConv2d_construct_5486(%para450_x, %para153_backbone.layer1.0.down_sample.0.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 64, 1, 1), ref_key=:backbone.layer1.0.down_sample.0.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell/0-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @mindcv_models_bit_StdConv2d_construct_6737:CNode_6745{[0]: ValueNode<FuncGraph> L_mindcv_models_bit_StdConv2d_construct_5486, [1]: param_x, [2]: param_backbone.layer1.0.down_sample.0.weight}
#   2: @mindcv_models_bit_StdConv2d_construct_6737:CNode_6746{[0]: ValueNode<Primitive> Return, [1]: CNode_6745}


subgraph attr:
training : 0
subgraph instance: _cal_output_5503 : 0x561a19663150
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5503 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para451_x) {
  %1(CNode_6747) = call @shape_4343(%para451_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6748) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(64), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6749) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6750) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6751) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para451_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6752) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6753) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6754) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6755) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6756) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6757) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6758) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6759) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6760) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6761) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6762) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6763) = call @reshape_4457(%para124_backbone.layer1.0.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6764) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6765) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6766) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6767) = call @reshape_4457(%para104_backbone.layer1.0.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6768) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5503:CNode_6747{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5503:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6747, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5503:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6747, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5503:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6747, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5503:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6747, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5503:CNode_6748{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5503:CNode_6750{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5503:CNode_6751{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6750}
#   9: @_cal_output_5503:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6751}
#  10: @_cal_output_5503:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5503:CNode_6753{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5503:CNode_6754{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6753}
#  13: @_cal_output_5503:CNode_6755{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6754, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5503:CNode_6756{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5503:CNode_6757{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6756, [2]: width}
#  16: @_cal_output_5503:CNode_6758{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6757, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5503:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6755, [2]: CNode_6758}
#  18: @_cal_output_5503:CNode_6759{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5503:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6759}
#  20: @_cal_output_5503:CNode_6752{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5503:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6752, [2]: std}
#  22: @_cal_output_5503:CNode_6760{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5503:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6760}
#  24: @_cal_output_5503:CNode_6761{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5503:CNode_6762{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6761, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5503:CNode_6763{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.0.gn3.gamma, [2]: CNode_6762}
#  27: @_cal_output_5503:CNode_6764{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6763}
#  28: @_cal_output_5503:CNode_6765{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5503:CNode_6766{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6765, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5503:CNode_6767{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.0.gn3.beta, [2]: CNode_6766}
#  31: @_cal_output_5503:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6764, [2]: CNode_6767}
#  32: @_cal_output_5503:CNode_6769{[0]: ValueNode<Primitive> Return, [1]: CNode_6768}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5506 : 0x56198e12d280
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5506(%para452_x, %para453_) {
  %1(CNode_6770) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para453_L_backbone.layer1.0.conv2.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6771) = S_Prim_sub(%para453_L_backbone.layer1.0.conv2.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6772) = getattr(%para453_L_backbone.layer1.0.conv2.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6773) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6774) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6775) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6776) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6777) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6778) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6780) = call @L_sqrt_6779(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(64), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para452_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/conv2-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6770{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5506:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer1.0.conv2.weight, [2]: CNode_6770}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6772{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer1.0.conv2.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6773{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6774{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6773}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6775{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6776{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6777{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6775, [2]: CNode_6776}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5506:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6781, [1]: CNode_6772, [2]: CNode_6774, [3]: CNode_6777}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6771{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer1.0.conv2.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6778{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_6780{[0]: ValueNode<FuncGraph> L_sqrt_6779, [1]: CNode_6778}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5506:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6771, [2]: CNode_6780}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5506:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5506:CNode_5508{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_5516 : 0x561a1c316100
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5516 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para454_x) {
  %1(CNode_6782) = call @shape_4343(%para454_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6783) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(64), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6784) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6785) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6786) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para454_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6787) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6788) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6789) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6790) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6791) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6792) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6793) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6794) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6795) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6796) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6797) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6798) = call @reshape_4457(%para141_backbone.layer1.0.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6799) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6800) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6801) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6802) = call @reshape_4457(%para125_backbone.layer1.0.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6803) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5516:CNode_6782{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5516:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6782, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5516:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6782, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5516:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6782, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5516:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6782, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5516:CNode_6783{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5516:CNode_6785{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5516:CNode_6786{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6785}
#   9: @_cal_output_5516:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6786}
#  10: @_cal_output_5516:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5516:CNode_6788{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5516:CNode_6789{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6788}
#  13: @_cal_output_5516:CNode_6790{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6789, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5516:CNode_6791{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5516:CNode_6792{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6791, [2]: width}
#  16: @_cal_output_5516:CNode_6793{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6792, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5516:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6790, [2]: CNode_6793}
#  18: @_cal_output_5516:CNode_6794{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5516:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6794}
#  20: @_cal_output_5516:CNode_6787{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5516:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6787, [2]: std}
#  22: @_cal_output_5516:CNode_6795{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5516:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6795}
#  24: @_cal_output_5516:CNode_6796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5516:CNode_6797{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6796, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5516:CNode_6798{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.0.gn1.gamma, [2]: CNode_6797}
#  27: @_cal_output_5516:CNode_6799{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6798}
#  28: @_cal_output_5516:CNode_6800{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5516:CNode_6801{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6800, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5516:CNode_6802{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.0.gn1.beta, [2]: CNode_6801}
#  31: @_cal_output_5516:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6799, [2]: CNode_6802}
#  32: @_cal_output_5516:CNode_6804{[0]: ValueNode<Primitive> Return, [1]: CNode_6803}


subgraph attr:
training : 0
subgraph instance: _cal_output_5526 : 0x561987e882d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5526 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para455_x) {
  %1(CNode_6805) = call @shape_4343(%para455_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6806) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(64), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6807) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6808) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6809) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para455_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6810) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6811) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6812) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6813) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6814) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6815) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6816) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6817) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6818) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6819) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6820) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6821) = call @reshape_4457(%para152_backbone.layer1.0.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6822) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6823) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6824) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6825) = call @reshape_4457(%para149_backbone.layer1.0.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.0.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6826) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5526:CNode_6805{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5526:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6805, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5526:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6805, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5526:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6805, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5526:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6805, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5526:CNode_6806{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5526:CNode_6808{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5526:CNode_6809{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6808}
#   9: @_cal_output_5526:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6809}
#  10: @_cal_output_5526:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5526:CNode_6811{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5526:CNode_6812{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6811}
#  13: @_cal_output_5526:CNode_6813{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6812, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5526:CNode_6814{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5526:CNode_6815{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6814, [2]: width}
#  16: @_cal_output_5526:CNode_6816{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6815, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5526:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6813, [2]: CNode_6816}
#  18: @_cal_output_5526:CNode_6817{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5526:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6817}
#  20: @_cal_output_5526:CNode_6810{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5526:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6810, [2]: std}
#  22: @_cal_output_5526:CNode_6818{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5526:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6818}
#  24: @_cal_output_5526:CNode_6819{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5526:CNode_6820{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6819, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5526:CNode_6821{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.0.gn2.gamma, [2]: CNode_6820}
#  27: @_cal_output_5526:CNode_6822{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6821}
#  28: @_cal_output_5526:CNode_6823{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5526:CNode_6824{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6823, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5526:CNode_6825{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.0.gn2.beta, [2]: CNode_6824}
#  31: @_cal_output_5526:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6822, [2]: CNode_6825}
#  32: @_cal_output_5526:CNode_6827{[0]: ValueNode<Primitive> Return, [1]: CNode_6826}


subgraph attr:
training : 0
subgraph instance: _cal_output_5555 : 0x561a19447f40
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5555 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para456_x) {
  %1(CNode_6828) = call @shape_4343(%para456_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6829) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(64), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6830) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6831) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6832) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para456_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6833) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6834) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6835) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6836) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6837) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6838) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6839) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6840) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6841) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6842) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6843) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6844) = call @reshape_4457(%para126_backbone.layer1.1.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.1.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6845) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6846) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6847) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6848) = call @reshape_4457(%para106_backbone.layer1.1.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.1.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6849) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5555:CNode_6828{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5555:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6828, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5555:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6828, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5555:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6828, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5555:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6828, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5555:CNode_6829{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5555:CNode_6831{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5555:CNode_6832{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6831}
#   9: @_cal_output_5555:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6832}
#  10: @_cal_output_5555:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5555:CNode_6834{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5555:CNode_6835{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6834}
#  13: @_cal_output_5555:CNode_6836{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6835, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5555:CNode_6837{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5555:CNode_6838{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6837, [2]: width}
#  16: @_cal_output_5555:CNode_6839{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6838, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5555:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6836, [2]: CNode_6839}
#  18: @_cal_output_5555:CNode_6840{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5555:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6840}
#  20: @_cal_output_5555:CNode_6833{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5555:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6833, [2]: std}
#  22: @_cal_output_5555:CNode_6841{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5555:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6841}
#  24: @_cal_output_5555:CNode_6842{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5555:CNode_6843{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6842, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5555:CNode_6844{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.1.gn3.gamma, [2]: CNode_6843}
#  27: @_cal_output_5555:CNode_6845{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6844}
#  28: @_cal_output_5555:CNode_6846{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5555:CNode_6847{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6846, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5555:CNode_6848{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.1.gn3.beta, [2]: CNode_6847}
#  31: @_cal_output_5555:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6845, [2]: CNode_6848}
#  32: @_cal_output_5555:CNode_6850{[0]: ValueNode<Primitive> Return, [1]: CNode_6849}


subgraph attr:
training : 0
subgraph instance: _cal_output_5567 : 0x561a1712d9d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5567 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para457_x) {
  %1(CNode_6851) = call @shape_4343(%para457_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6852) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6853) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6854) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6855) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para457_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6856) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6857) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6858) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6859) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6860) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6861) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6862) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6863) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6864) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6865) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6866) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6867) = call @reshape_4457(%para142_backbone.layer1.1.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer1.1.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6868) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6869) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6870) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6871) = call @reshape_4457(%para127_backbone.layer1.1.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer1.1.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6872) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5567:CNode_6851{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5567:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6851, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5567:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6851, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5567:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6851, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5567:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6851, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5567:CNode_6852{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5567:CNode_6854{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5567:CNode_6855{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6854}
#   9: @_cal_output_5567:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6855}
#  10: @_cal_output_5567:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5567:CNode_6857{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5567:CNode_6858{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6857}
#  13: @_cal_output_5567:CNode_6859{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6858, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5567:CNode_6860{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5567:CNode_6861{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6860, [2]: width}
#  16: @_cal_output_5567:CNode_6862{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6861, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5567:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6859, [2]: CNode_6862}
#  18: @_cal_output_5567:CNode_6863{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5567:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6863}
#  20: @_cal_output_5567:CNode_6856{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5567:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6856, [2]: std}
#  22: @_cal_output_5567:CNode_6864{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5567:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6864}
#  24: @_cal_output_5567:CNode_6865{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5567:CNode_6866{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6865, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5567:CNode_6867{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.1.gn1.gamma, [2]: CNode_6866}
#  27: @_cal_output_5567:CNode_6868{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6867}
#  28: @_cal_output_5567:CNode_6869{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5567:CNode_6870{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6869, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5567:CNode_6871{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.1.gn1.beta, [2]: CNode_6870}
#  31: @_cal_output_5567:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6868, [2]: CNode_6871}
#  32: @_cal_output_5567:CNode_6873{[0]: ValueNode<Primitive> Return, [1]: CNode_6872}


subgraph attr:
training : 0
subgraph instance: _cal_output_5577 : 0x5619a1cad090
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5577 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para458_x) {
  %1(CNode_6874) = call @shape_4343(%para458_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6875) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(64), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6876) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6877) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6878) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para458_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6879) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6880) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6881) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6882) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6883) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6884) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6885) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6886) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6887) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6888) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6889) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6890) = call @reshape_4457(%para154_backbone.layer1.1.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.1.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6891) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6892) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6893) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6894) = call @reshape_4457(%para150_backbone.layer1.1.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.1.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6895) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5577:CNode_6874{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5577:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6874, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5577:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6874, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5577:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6874, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5577:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6874, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5577:CNode_6875{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5577:CNode_6877{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5577:CNode_6878{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6877}
#   9: @_cal_output_5577:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6878}
#  10: @_cal_output_5577:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5577:CNode_6880{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5577:CNode_6881{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6880}
#  13: @_cal_output_5577:CNode_6882{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6881, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5577:CNode_6883{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5577:CNode_6884{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6883, [2]: width}
#  16: @_cal_output_5577:CNode_6885{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6884, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5577:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6882, [2]: CNode_6885}
#  18: @_cal_output_5577:CNode_6886{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5577:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6886}
#  20: @_cal_output_5577:CNode_6879{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5577:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6879, [2]: std}
#  22: @_cal_output_5577:CNode_6887{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5577:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6887}
#  24: @_cal_output_5577:CNode_6888{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5577:CNode_6889{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6888, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5577:CNode_6890{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.1.gn2.gamma, [2]: CNode_6889}
#  27: @_cal_output_5577:CNode_6891{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6890}
#  28: @_cal_output_5577:CNode_6892{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5577:CNode_6893{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6892, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5577:CNode_6894{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.1.gn2.beta, [2]: CNode_6893}
#  31: @_cal_output_5577:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6891, [2]: CNode_6894}
#  32: @_cal_output_5577:CNode_6896{[0]: ValueNode<Primitive> Return, [1]: CNode_6895}


subgraph attr:
training : 0
subgraph instance: L_mindcv_models_bit_StdConv2d_construct_5580 : 0x561a153dd4e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:73/    def construct(self, x):/
subgraph @L_mindcv_models_bit_StdConv2d_construct_5580(%para459_x, %para460_) {
  %1(CNode_6897) = S_Prim_make_list(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %2(m) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%para460_L_backbone.layer1.1.conv1.weight, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:75/        m = self.mean_op(w, [1, 2, 3])/
  %3(CNode_6898) = S_Prim_sub(%para460_L_backbone.layer1.1.conv1.weight, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %4(CNode_6899) = getattr(%para460_L_backbone.layer1.1.conv1.weight, "var")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %5(CNode_6900) = S_Prim_MakeTuple(I64(1), I64(2), I64(3))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %6(CNode_6901) = S_Prim_MakeTuple(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %7(CNode_6902) = S_Prim_MakeTuple("keepdims")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %8(CNode_6903) = S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %9(CNode_6904) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %10(v) = UnpackCall_unpack_call(%4, %6, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:76/        v = w.var((1, 2, 3), keepdims=True)/
  %11(CNode_6905) = S_Prim_add(%10, F32(1e-10))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %12(CNode_6907) = call @L_sqrt_6906(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %13(w) = S_Prim_div(%3, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:77/        w = (w - m) / mindspore.ops.sqrt(v + 1e-10)/
  %14(output) = S_Prim_Conv2D[kernel_size: (I64(1), I64(1)), mode: I64(1), out_channel: I64(64), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(0), I64(0)), pad_mode: I64(1), format: "NCHW", pad_list: (I64(0), I64(0), I64(0), I64(0)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para459_x, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:78/        output = self.conv2d(x, w)/
  Return(%14)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/1-Bottleneck/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:79/        return output/
}
# Order:
#   1: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6897{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   2: @L_mindcv_models_bit_StdConv2d_construct_5580:m{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: param_L_backbone.layer1.1.conv1.weight, [2]: CNode_6897}
#   3: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6899{[0]: ValueNode<Primitive> getattr, [1]: param_L_backbone.layer1.1.conv1.weight, [2]: ValueNode<StringImm> var}
#   4: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6900{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 3}
#   5: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6901{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6900}
#   6: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6902{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdims}
#   7: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6903{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   8: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6904{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6902, [2]: CNode_6903}
#   9: @L_mindcv_models_bit_StdConv2d_construct_5580:v{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.6908, [1]: CNode_6899, [2]: CNode_6901, [3]: CNode_6904}
#  10: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6898{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_L_backbone.layer1.1.conv1.weight, [2]: m}
#  11: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6905{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: v, [2]: ValueNode<FP32Imm> 1e-10}
#  12: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_6907{[0]: ValueNode<FuncGraph> L_sqrt_6906, [1]: CNode_6905}
#  13: @L_mindcv_models_bit_StdConv2d_construct_5580:w{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6898, [2]: CNode_6907}
#  14: @L_mindcv_models_bit_StdConv2d_construct_5580:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: w}
#  15: @L_mindcv_models_bit_StdConv2d_construct_5580:CNode_5582{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: _cal_output_5597 : 0x561a1938b8c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5597 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para461_x) {
  %1(CNode_6909) = call @shape_4343(%para461_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6910) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(64), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6911) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6912) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6913) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para461_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6914) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6915) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6916) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6917) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6918) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6919) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6920) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6921) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6922) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6923) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6924) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6925) = call @reshape_4457(%para128_backbone.layer1.2.gn3.gamma, %26)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.2.gn3.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6926) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6927) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6928) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6929) = call @reshape_4457(%para108_backbone.layer1.2.gn3.beta, %30)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.2.gn3.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6930) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn3-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5597:CNode_6909{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5597:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6909, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5597:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6909, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5597:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6909, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5597:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6909, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5597:CNode_6910{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5597:CNode_6912{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5597:CNode_6913{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6912}
#   9: @_cal_output_5597:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6913}
#  10: @_cal_output_5597:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5597:CNode_6915{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5597:CNode_6916{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6915}
#  13: @_cal_output_5597:CNode_6917{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6916, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5597:CNode_6918{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5597:CNode_6919{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6918, [2]: width}
#  16: @_cal_output_5597:CNode_6920{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6919, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5597:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6917, [2]: CNode_6920}
#  18: @_cal_output_5597:CNode_6921{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5597:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6921}
#  20: @_cal_output_5597:CNode_6914{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5597:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6914, [2]: std}
#  22: @_cal_output_5597:CNode_6922{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5597:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6922}
#  24: @_cal_output_5597:CNode_6923{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5597:CNode_6924{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6923, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5597:CNode_6925{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.2.gn3.gamma, [2]: CNode_6924}
#  27: @_cal_output_5597:CNode_6926{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6925}
#  28: @_cal_output_5597:CNode_6927{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5597:CNode_6928{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6927, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5597:CNode_6929{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.2.gn3.beta, [2]: CNode_6928}
#  31: @_cal_output_5597:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6926, [2]: CNode_6929}
#  32: @_cal_output_5597:CNode_6931{[0]: ValueNode<Primitive> Return, [1]: CNode_6930}


subgraph attr:
training : 0
subgraph instance: _cal_output_5609 : 0x56198783e340
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5609 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para462_x) {
  %1(CNode_6932) = call @shape_4343(%para462_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6933) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(256), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6934) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6935) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6936) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para462_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6937) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6938) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6939) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6940) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6941) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6942) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6943) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6944) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6945) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6946) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6947) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6948) = call @reshape_4457(%para143_backbone.layer1.2.gn1.gamma, %26)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer1.2.gn1.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6949) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6950) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6951) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6952) = call @reshape_4457(%para129_backbone.layer1.2.gn1.beta, %30)
      : (<Ref[Tensor[Float32]], (256), ref_key=:backbone.layer1.2.gn1.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6953) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn1-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5609:CNode_6932{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5609:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6932, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5609:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6932, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5609:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6932, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5609:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6932, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5609:CNode_6933{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 256, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5609:CNode_6935{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5609:CNode_6936{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6935}
#   9: @_cal_output_5609:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6936}
#  10: @_cal_output_5609:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5609:CNode_6938{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5609:CNode_6939{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6938}
#  13: @_cal_output_5609:CNode_6940{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6939, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5609:CNode_6941{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5609:CNode_6942{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6941, [2]: width}
#  16: @_cal_output_5609:CNode_6943{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6942, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5609:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6940, [2]: CNode_6943}
#  18: @_cal_output_5609:CNode_6944{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5609:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6944}
#  20: @_cal_output_5609:CNode_6937{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5609:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6937, [2]: std}
#  22: @_cal_output_5609:CNode_6945{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5609:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6945}
#  24: @_cal_output_5609:CNode_6946{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5609:CNode_6947{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6946, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5609:CNode_6948{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.2.gn1.gamma, [2]: CNode_6947}
#  27: @_cal_output_5609:CNode_6949{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6948}
#  28: @_cal_output_5609:CNode_6950{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5609:CNode_6951{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6950, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5609:CNode_6952{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.2.gn1.beta, [2]: CNode_6951}
#  31: @_cal_output_5609:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6949, [2]: CNode_6952}
#  32: @_cal_output_5609:CNode_6954{[0]: ValueNode<Primitive> Return, [1]: CNode_6953}


subgraph attr:
training : 0
subgraph instance: _cal_output_5619 : 0x561a1d336eb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
subgraph @_cal_output_5619 parent: [subgraph @mindspore_nn_wrap_cell_wrapper_WithEvalCell_construct_4163](%para463_x) {
  %1(CNode_6955) = call @shape_4343(%para463_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %2(channel) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %3(CNode_6956) = S_Prim__channel_check[constexpr_prim: Bool(1)](%2, I64(64), "GroupNorm")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1153/        self._channel_check(channel, self.num_channels, self.cls_name)/
  %4(CNode_6957) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1150/    def _cal_output(self, x):/
  %5(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %6(CNode_6958) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %7(CNode_6959) = S_Prim_MakeTuple(%5, I64(32), %6)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %8(x) = call @reshape_4457(%para463_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1154/        x = F.reshape(x, (batch, self.num_groups, -1))/
  %9(mean) = S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"]](%8, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1155/        mean = self.reduce_mean(x, 2)/
  %10(CNode_6960) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %11(CNode_6961) = call @sub_4458(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %12(CNode_6962) = call @square_4461(%11)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %13(CNode_6963) = S_Prim_ReduceSum[output_names: ["y"], keep_dims: Bool(1), input_names: ["input_x", "axis"], skip_mode: Bool(0)](%12, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %14(height) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %15(CNode_6964) = S_Prim_mul(%2, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %16(width) = S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1152/        batch, channel, height, width = F.shape(x)/
  %17(CNode_6965) = S_Prim_mul(%15, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %18(CNode_6966) = S_Prim_div(%17, I64(32))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %19(var) = call @div_4467(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  %20(CNode_6967) = S_Prim_add(%19, F32(1e-05))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %21(std) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%20)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1157/        std = self.sqrt(var + self.eps)/
  %22(x) = call @div_4467(%10, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1158/        x = F.div(F.sub(x, mean), std)/
  %23(CNode_6968) = S_Prim_MakeTuple(%5, %2, %14, %16)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %24(x) = call @reshape_4457(%22, %23)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1159/        x = F.reshape(x, (batch, channel, height, width))/
  %25(CNode_6969) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %26(CNode_6970) = S_Prim_MakeTuple(%25, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %27(CNode_6971) = call @reshape_4457(%para155_backbone.layer1.2.gn2.gamma, %26)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.2.gn2.gamma>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %28(CNode_6972) = S_Prim_mul(%24, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %29(CNode_6973) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %30(CNode_6974) = S_Prim_MakeTuple(%29, I64(1), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %31(CNode_6975) = call @reshape_4457(%para151_backbone.layer1.2.gn2.beta, %30)
      : (<Ref[Tensor[Float32]], (64), ref_key=:backbone.layer1.2.gn2.beta>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %32(output) = call @add_4477(%28, %31)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  %33(CNode_6976) = Depend[side_effect_propagate: I64(1)](%32, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1160/        output = F.add(x * F.reshape(self.gamma, (-1, 1, 1)), F.reshape(self.beta, (-1, 1, 1)))/
  Return(%33)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/2-Bottleneck/gn2-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1161/        return output/
}
# Order:
#   1: @_cal_output_5619:CNode_6955{[0]: ValueNode<FuncGraph> shape_4343, [1]: param_x}
#   2: @_cal_output_5619:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6955, [2]: ValueNode<Int64Imm> 0}
#   3: @_cal_output_5619:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6955, [2]: ValueNode<Int64Imm> 1}
#   4: @_cal_output_5619:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6955, [2]: ValueNode<Int64Imm> 2}
#   5: @_cal_output_5619:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_6955, [2]: ValueNode<Int64Imm> 3}
#   6: @_cal_output_5619:CNode_6956{[0]: ValueNode<DoSignaturePrimitive> S_Prim__channel_check, [1]: channel, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<StringImm> GroupNorm}
#   7: @_cal_output_5619:CNode_6958{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   8: @_cal_output_5619:CNode_6959{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: ValueNode<Int64Imm> 32, [3]: CNode_6958}
#   9: @_cal_output_5619:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_x, [2]: CNode_6959}
#  10: @_cal_output_5619:mean{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: ValueNode<Int64Imm> 2}
#  11: @_cal_output_5619:CNode_6961{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  12: @_cal_output_5619:CNode_6962{[0]: ValueNode<FuncGraph> square_4461, [1]: CNode_6961}
#  13: @_cal_output_5619:CNode_6963{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceSum, [1]: CNode_6962, [2]: ValueNode<Int64Imm> 2}
#  14: @_cal_output_5619:CNode_6964{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: channel, [2]: height}
#  15: @_cal_output_5619:CNode_6965{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_6964, [2]: width}
#  16: @_cal_output_5619:CNode_6966{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_6965, [2]: ValueNode<Int64Imm> 32}
#  17: @_cal_output_5619:var{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6963, [2]: CNode_6966}
#  18: @_cal_output_5619:CNode_6967{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: var, [2]: ValueNode<FP32Imm> 1e-05}
#  19: @_cal_output_5619:std{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: CNode_6967}
#  20: @_cal_output_5619:CNode_6960{[0]: ValueNode<FuncGraph> sub_4458, [1]: x, [2]: mean}
#  21: @_cal_output_5619:x{[0]: ValueNode<FuncGraph> div_4467, [1]: CNode_6960, [2]: std}
#  22: @_cal_output_5619:CNode_6968{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: channel, [3]: height, [4]: width}
#  23: @_cal_output_5619:x{[0]: ValueNode<FuncGraph> reshape_4457, [1]: x, [2]: CNode_6968}
#  24: @_cal_output_5619:CNode_6969{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  25: @_cal_output_5619:CNode_6970{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6969, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  26: @_cal_output_5619:CNode_6971{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.2.gn2.gamma, [2]: CNode_6970}
#  27: @_cal_output_5619:CNode_6972{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: x, [2]: CNode_6971}
#  28: @_cal_output_5619:CNode_6973{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#  29: @_cal_output_5619:CNode_6974{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_6973, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 1}
#  30: @_cal_output_5619:CNode_6975{[0]: ValueNode<FuncGraph> reshape_4457, [1]: param_backbone.layer1.2.gn2.beta, [2]: CNode_6974}
#  31: @_cal_output_5619:output{[0]: ValueNode<FuncGraph> add_4477, [1]: CNode_6972, [2]: CNode_6975}
#  32: @_cal_output_5619:CNode_6977{[0]: ValueNode<Primitive> Return, [1]: CNode_6976}


subgraph attr:
training : 0
subgraph instance: ✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624 : 0x561a21430300
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624 parent: [subgraph @↓mindspore_nn_layer_pooling_MaxPool2d_construct_4787]() {
  %1(CNode_6979) = call @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:581/            out = self.max_pool(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:581/            out = self.max_pool(x)/
}
# Order:
#   1: @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MaxPool, [1]: param_фx}
#   2: @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624:CNode_6979{[0]: ValueNode<FuncGraph> 2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978}
#   3: @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624:CNode_6980{[0]: ValueNode<Primitive> Return, [1]: CNode_6979}


subgraph attr:
subgraph instance: ✓sum_5631 : 0x561a1877d8b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✓sum_5631 parent: [subgraph @sum_4798]() {
  %1(CNode_6981) = S_Prim_MakeTuple("input")
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12011/        raise TypeError(f"For 'sum', 'input' must be Tensor, but got{type(input)}")/
  %2(CNode_6982) = S_Prim_MakeTuple(%para375_input)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12011/        raise TypeError(f"For 'sum', 'input' must be Tensor, but got{type(input)}")/
  %3(CNode_6983) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12011/        raise TypeError(f"For 'sum', 'input' must be Tensor, but got{type(input)}")/
  %4(ValueNode_6984) = PyInterpret[side_effect_io: Bool(1)](Script['f"For 'sum', 'input' must be Tensor, but got{type(input)}"'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12011/        raise TypeError(f"For 'sum', 'input' must be Tensor, but got{type(input)}")/
  %5(CNode_6985) = raise[side_effect_io: Bool(1)]("TypeError", %4, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12011/        raise TypeError(f"For 'sum', 'input' must be Tensor, but got{type(input)}")/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12011/        raise TypeError(f"For 'sum', 'input' must be Tensor, but got{type(input)}")/
}
# Order:
#   1: @✓sum_5631:CNode_6981{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> input}
#   2: @✓sum_5631:CNode_6982{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_input}
#   3: @✓sum_5631:CNode_6983{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_6981, [2]: CNode_6982}
#   4: @✓sum_5631:ValueNode_6984{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'f"For 'sum', 'input' must be Tensor, but got{type(input)}"', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'isinstance': <built-in function isinstance>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>, 'type': <class 'type'>}), [3]: CNode_6983}
#   5: @✓sum_5631:CNode_6985{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: ValueNode_6984, [3]: ValueNode<StringImm> None}
#   6: @✓sum_5631:CNode_6986{[0]: ValueNode<Primitive> Return, [1]: CNode_6985}


subgraph attr:
subgraph instance: ✗sum_5632 : 0x561a17ecfcb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✗sum_5632 parent: [subgraph @sum_4798]() {
  %1(CNode_6988) = call @↓sum_6987()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12010/    if not isinstance(input, Tensor):/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12010/    if not isinstance(input, Tensor):/
}
# Order:
#   1: @✗sum_5632:CNode_6988{[0]: ValueNode<FuncGraph> ↓sum_6987}
#   2: @✗sum_5632:CNode_6989{[0]: ValueNode<Primitive> Return, [1]: CNode_6988}


subgraph attr:
subgraph instance: _new_prim_for_graph_5635 : 0x561a190b2140
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:67/    def _new_prim_for_graph(*args, **kwargs) -> Primitive:/
subgraph @_new_prim_for_graph_5635 parent: [subgraph @_get_cache_prim_4422](%para464_args, %para465_kwargs) {
  %1(CNode_6990) = UnpackCall_unpack_call(%para225_cls, %para464_args, %para465_kwargs)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:68/        return cls(*args, **kwargs)/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:68/        return cls(*args, **kwargs)/
}
# Order:
#   1: @_new_prim_for_graph_5635:CNode_6990{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.4168, [1]: param_cls, [2]: param_args, [3]: param_kwargs}
#   2: @_new_prim_for_graph_5635:CNode_6991{[0]: ValueNode<Primitive> Return, [1]: CNode_6990}


subgraph attr:
training : 0
subgraph instance: 3↓mindspore_nn_layer_basic_Dense_construct_5637 : 0x561a1de7e8e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @3↓mindspore_nn_layer_basic_Dense_construct_5637 parent: [subgraph @✓↓mindspore_nn_layer_basic_Dense_construct_4310]() {
  %1(x_shape) = $(mindspore_nn_layer_basic_Dense_construct_4219):S_Prim_Shape(%para164_x)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623/        x_shape = self.shape_op(x)/
  %2(CNode_6992) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %3(CNode_6993) = S_Prim_not_equal(%2, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %4(CNode_6994) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %5(CNode_6995) = Switch(%4, @✓3↓mindspore_nn_layer_basic_Dense_construct_6996, @✗3↓mindspore_nn_layer_basic_Dense_construct_6997)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %6(CNode_6998) = %5()
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %7(CNode_7000) = call @4↓mindspore_nn_layer_basic_Dense_construct_6999(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:53/
  Return(%7)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
}
# Order:
#   1: @3↓mindspore_nn_layer_basic_Dense_construct_5637:CNode_6992{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: x_shape}
#   2: @3↓mindspore_nn_layer_basic_Dense_construct_5637:CNode_6993{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_6992, [2]: ValueNode<Int64Imm> 2}
#   3: @3↓mindspore_nn_layer_basic_Dense_construct_5637:CNode_6994{[0]: ValueNode<Primitive> Cond, [1]: CNode_6993, [2]: ValueNode<BoolImm> false}
#   4: @3↓mindspore_nn_layer_basic_Dense_construct_5637:CNode_6995{[0]: ValueNode<Primitive> Switch, [1]: CNode_6994, [2]: ValueNode<FuncGraph> ✓3↓mindspore_nn_layer_basic_Dense_construct_6996, [3]: ValueNode<FuncGraph> ✗3↓mindspore_nn_layer_basic_Dense_construct_6997}
#   5: @3↓mindspore_nn_layer_basic_Dense_construct_5637:CNode_6998{[0]: CNode_6995}
#   6: @3↓mindspore_nn_layer_basic_Dense_construct_5637:CNode_7000{[0]: ValueNode<FuncGraph> 4↓mindspore_nn_layer_basic_Dense_construct_6999, [1]: CNode_6998}
#   7: @3↓mindspore_nn_layer_basic_Dense_construct_5637:CNode_7001{[0]: ValueNode<Primitive> Return, [1]: CNode_7000}


subgraph attr:
after_block : 1
subgraph instance: ↓pad_5646 : 0x561a212f28c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @↓pad_5646 parent: [subgraph @pad_4440]() {
  %1(CNode_7002) = S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %2(CNode_7003) = S_Prim_isinstance(%para227_padding, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %3(CNode_7004) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %4(CNode_7005) = Switch(%3, @↰↓pad_7006, @↱↓pad_7007)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %5(CNode_7008) = %4()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %6(CNode_7009) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %7(CNode_7010) = Switch(%6, @↰↓pad_7011, @↱↓pad_7012)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %8(CNode_7013) = %7()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %9(CNode_7014) = Cond(%8, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %10(CNode_7015) = Switch(%9, @✓↓pad_7016, @✗↓pad_7017)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %11(CNode_7018) = %10()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  Return(%11)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
}
# Order:
#   1: @↓pad_5646:CNode_7002{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'tuple', [2]: ValueNode<ClassType> class 'list'}
#   2: @↓pad_5646:CNode_7003{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_padding, [2]: CNode_7002}
#   3: @↓pad_5646:CNode_7004{[0]: ValueNode<Primitive> Cond, [1]: CNode_7003, [2]: ValueNode<BoolImm> false}
#   4: @↓pad_5646:CNode_7005{[0]: ValueNode<Primitive> Switch, [1]: CNode_7004, [2]: ValueNode<FuncGraph> ↰↓pad_7006, [3]: ValueNode<FuncGraph> ↱↓pad_7007}
#   5: @↓pad_5646:CNode_7008{[0]: CNode_7005}
#   6: @↓pad_5646:CNode_7009{[0]: ValueNode<Primitive> Cond, [1]: CNode_7008, [2]: ValueNode<BoolImm> false}
#   7: @↓pad_5646:CNode_7010{[0]: ValueNode<Primitive> Switch, [1]: CNode_7009, [2]: ValueNode<FuncGraph> ↰↓pad_7011, [3]: ValueNode<FuncGraph> ↱↓pad_7012}
#   8: @↓pad_5646:CNode_7013{[0]: CNode_7010}
#   9: @↓pad_5646:CNode_7014{[0]: ValueNode<Primitive> Cond, [1]: CNode_7013, [2]: ValueNode<BoolImm> false}
#  10: @↓pad_5646:CNode_7015{[0]: ValueNode<Primitive> Switch, [1]: CNode_7014, [2]: ValueNode<FuncGraph> ✓↓pad_7016, [3]: ValueNode<FuncGraph> ✗↓pad_7017}
#  11: @↓pad_5646:CNode_7018{[0]: CNode_7015}
#  12: @↓pad_5646:CNode_7019{[0]: ValueNode<Primitive> Return, [1]: CNode_7018}


subgraph attr:
after_block : 1
subgraph instance: ↓div_5651 : 0x5619a17d3ad0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @↓div_5651 parent: [subgraph @div_4467]() {
  %1(CNode_7020) = S_Prim_equal(%para238_rounding_mode, "floor")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1085/    if rounding_mode == 'floor':/
  %2(CNode_7021) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1085/    if rounding_mode == 'floor':/
  %3(CNode_7022) = Switch(%2, @✓↓div_7023, @✗↓div_7024)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1085/    if rounding_mode == 'floor':/
  %4(CNode_7025) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1085/    if rounding_mode == 'floor':/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1085/    if rounding_mode == 'floor':/
}
# Order:
#   1: @↓div_5651:CNode_7020{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_rounding_mode, [2]: ValueNode<StringImm> floor}
#   2: @↓div_5651:CNode_7021{[0]: ValueNode<Primitive> Cond, [1]: CNode_7020, [2]: ValueNode<BoolImm> false}
#   3: @↓div_5651:CNode_7022{[0]: ValueNode<Primitive> Switch, [1]: CNode_7021, [2]: ValueNode<FuncGraph> ✓↓div_7023, [3]: ValueNode<FuncGraph> ✗↓div_7024}
#   4: @↓div_5651:CNode_7025{[0]: CNode_7022}
#   5: @↓div_5651:CNode_7026{[0]: ValueNode<Primitive> Return, [1]: CNode_7025}


subgraph attr:
subgraph instance: L_sqrt_5669 : 0x561a1ff07920
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_5669(%para466_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para466_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_5669:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_5669:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
training : 0
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_5676 : 0x561a216889f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_5676 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4854]() {
  %1(CNode_5674) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para382_@CNode_5674, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_7027) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_4857) = $(mindspore_nn_layer_container_SequentialCell_construct_4493):MakeTuple(@mindcv_models_bit_StdConv2d_construct_5672)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_7028) = call @ms_iter_4166(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para382_@CNode_5674)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para383_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_7029) = call @↵mindspore_nn_layer_container_SequentialCell_construct_4854(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_7030) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_5676:CNode_7028{[0]: ValueNode<FuncGraph> ms_iter_4166, [1]: CNode_4857}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_5676:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_7028, [2]: param_@CNode_5674}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_5676:CNode_5674{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.11, [1]: param_@CNode_5674, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_5676:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_5676:CNode_7029{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_4854, [1]: CNode_5674, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_5676:CNode_7031{[0]: ValueNode<Primitive> Return, [1]: CNode_7030}


subgraph attr:
training : 0
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_5677 : 0x561a217f40a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_5677 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_4854]() {
  Return(%para383_фinput_data)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer4-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_5677:CNode_7032{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
subgraph instance: L_sqrt_5793 : 0x561a1ce2da50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_5793(%para467_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para467_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_5793:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_5793:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
subgraph instance: L_sqrt_5851 : 0x56198a76a030
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_5851(%para468_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para468_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_5851:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_5851:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
subgraph instance: L_sqrt_5932 : 0x561987cc5e50
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_5932(%para469_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para469_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_5932:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_5932:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
training : 0
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_5939 : 0x561a1ff7d7c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_5939 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5011]() {
  %1(CNode_5937) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para400_@CNode_5937, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_7033) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_5014) = $(mindspore_nn_layer_container_SequentialCell_construct_4555):MakeTuple(@mindcv_models_bit_StdConv2d_construct_5935)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_7034) = call @ms_iter_4166(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para400_@CNode_5937)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para401_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_7035) = call @↵mindspore_nn_layer_container_SequentialCell_construct_5011(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_7036) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_5939:CNode_7034{[0]: ValueNode<FuncGraph> ms_iter_4166, [1]: CNode_5014}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_5939:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_7034, [2]: param_@CNode_5937}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_5939:CNode_5937{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.11, [1]: param_@CNode_5937, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_5939:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_5939:CNode_7035{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_5011, [1]: CNode_5937, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_5939:CNode_7037{[0]: ValueNode<Primitive> Return, [1]: CNode_7036}


subgraph attr:
training : 0
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_5940 : 0x561990f34590
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_5940 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5011]() {
  Return(%para401_фinput_data)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer3-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_5940:CNode_7038{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
subgraph instance: L_sqrt_6056 : 0x561994949cf0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_6056(%para470_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para470_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_6056:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_6056:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
subgraph instance: L_sqrt_6114 : 0x561a1f5fed90
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_6114(%para471_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para471_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_6114:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_6114:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
subgraph instance: L_sqrt_6402 : 0x561a21fef860
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_6402(%para472_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para472_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_6402:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_6402:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
training : 0
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_6409 : 0x561a1c16f960
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_6409 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5291]() {
  %1(CNode_6407) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para427_@CNode_6407, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_7039) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_5294) = $(mindspore_nn_layer_container_SequentialCell_construct_4663):MakeTuple(@mindcv_models_bit_StdConv2d_construct_6405)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_7040) = call @ms_iter_4166(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para427_@CNode_6407)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para428_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_7041) = call @↵mindspore_nn_layer_container_SequentialCell_construct_5291(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_7042) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_6409:CNode_7040{[0]: ValueNode<FuncGraph> ms_iter_4166, [1]: CNode_5294}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_6409:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_7040, [2]: param_@CNode_6407}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_6409:CNode_6407{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.11, [1]: param_@CNode_6407, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_6409:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_6409:CNode_7041{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_5291, [1]: CNode_6407, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_6409:CNode_7043{[0]: ValueNode<Primitive> Return, [1]: CNode_7042}


subgraph attr:
training : 0
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_6410 : 0x561993cf26c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_6410 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5291]() {
  Return(%para428_фinput_data)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer2-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_6410:CNode_7044{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
subgraph instance: L_sqrt_6526 : 0x561a218e98c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_6526(%para473_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para473_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_6526:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_6526:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
subgraph instance: L_sqrt_6584 : 0x561a1796ee40
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_6584(%para474_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para474_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_6584:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_6584:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
subgraph instance: L_sqrt_6734 : 0x561a200c9e00
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_6734(%para475_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para475_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_6734:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_6734:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
training : 0
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_6741 : 0x56198bb260b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_6741 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5489]() {
  %1(CNode_6739) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para448_@CNode_6739, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_7045) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_5492) = $(mindspore_nn_layer_container_SequentialCell_construct_4738):MakeTuple(@mindcv_models_bit_StdConv2d_construct_6737)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_7046) = call @ms_iter_4166(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para448_@CNode_6739)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para449_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_7047) = call @↵mindspore_nn_layer_container_SequentialCell_construct_5489(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_7048) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_6741:CNode_7046{[0]: ValueNode<FuncGraph> ms_iter_4166, [1]: CNode_5492}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_6741:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_7046, [2]: param_@CNode_6739}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_6741:CNode_6739{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.11, [1]: param_@CNode_6739, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_6741:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_6741:CNode_7047{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_5489, [1]: CNode_6739, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_6741:CNode_7049{[0]: ValueNode<Primitive> Return, [1]: CNode_7048}


subgraph attr:
training : 0
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_6742 : 0x561993891c20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_6742 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_5489]() {
  Return(%para449_фinput_data)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/layer1-SequentialCell/0-Bottleneck/down_sample-SequentialCell)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_6742:CNode_7050{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
subgraph instance: L_sqrt_6779 : 0x561a20852a70
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_6779(%para476_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para476_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_6779:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_6779:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
subgraph instance: L_sqrt_6906 : 0x561a142449f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6050/def sqrt(x):/
subgraph @L_sqrt_6906(%para477_x) {
  %1(CNode_4796) = S_Prim_Sqrt[output_names: ["output"], input_names: ["x"]](%para477_x)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/conv1-StdConv2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6078/    return sqrt_(x)/
}
# Order:
#   1: @L_sqrt_6906:CNode_4796{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Sqrt, [1]: param_x}
#   2: @L_sqrt_6906:CNode_4797{[0]: ValueNode<Primitive> Return, [1]: CNode_4796}


subgraph attr:
training : 0
subgraph instance: 2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978 : 0x561991077b20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624]() {
  %1(CNode_7051) = Cond(%para374_фexpand_batch, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
  %2(CNode_7052) = Switch(%1, @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053, @✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7054)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
  %3(CNode_7055) = %2()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
  %4(CNode_7057) = call @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7056(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:244/        x = self.max_pool(x)/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
}
# Order:
#   1: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978:CNode_7051{[0]: ValueNode<Primitive> Cond, [1]: param_фexpand_batch, [2]: ValueNode<BoolImm> false}
#   2: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978:CNode_7052{[0]: ValueNode<Primitive> Switch, [1]: CNode_7051, [2]: ValueNode<FuncGraph> ✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053, [3]: ValueNode<FuncGraph> ✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7054}
#   3: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978:CNode_7055{[0]: CNode_7052}
#   4: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978:CNode_7057{[0]: ValueNode<FuncGraph> 3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7056, [1]: CNode_7055}
#   5: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_6978:CNode_7058{[0]: ValueNode<Primitive> Return, [1]: CNode_7057}


subgraph attr:
after_block : 1
subgraph instance: ↓sum_6987 : 0x561a17c5df60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @↓sum_6987 parent: [subgraph @sum_4798]() {
  %1(CNode_7059) = S_Prim_is_not(%para376_dim, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  %2(CNode_7060) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  %3(CNode_7061) = Switch(%2, @↰↓sum_7062, @↱↓sum_7063)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  %4(CNode_7064) = %3()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  %5(CNode_7065) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  %6(CNode_7066) = Switch(%5, @✓↓sum_7067, @✗↓sum_7068)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  %7(CNode_7069) = %6()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  Return(%7)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
}
# Order:
#   1: @↓sum_6987:CNode_7059{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: param_dim, [2]: ValueNode<None> None}
#   2: @↓sum_6987:CNode_7060{[0]: ValueNode<Primitive> Cond, [1]: CNode_7059, [2]: ValueNode<BoolImm> false}
#   3: @↓sum_6987:CNode_7061{[0]: ValueNode<Primitive> Switch, [1]: CNode_7060, [2]: ValueNode<FuncGraph> ↰↓sum_7062, [3]: ValueNode<FuncGraph> ↱↓sum_7063}
#   4: @↓sum_6987:CNode_7064{[0]: CNode_7061}
#   5: @↓sum_6987:CNode_7065{[0]: ValueNode<Primitive> Cond, [1]: CNode_7064, [2]: ValueNode<BoolImm> false}
#   6: @↓sum_6987:CNode_7066{[0]: ValueNode<Primitive> Switch, [1]: CNode_7065, [2]: ValueNode<FuncGraph> ✓↓sum_7067, [3]: ValueNode<FuncGraph> ✗↓sum_7068}
#   7: @↓sum_6987:CNode_7069{[0]: CNode_7066}
#   8: @↓sum_6987:CNode_7070{[0]: ValueNode<Primitive> Return, [1]: CNode_7069}


subgraph attr:
after_block : 1
training : 0
subgraph instance: 4↓mindspore_nn_layer_basic_Dense_construct_6999 : 0x561a1da31260
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @4↓mindspore_nn_layer_basic_Dense_construct_6999(%para478_) {
  Return(%para478_фx)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:635/        return x/
}
# Order:
#   1: @4↓mindspore_nn_layer_basic_Dense_construct_6999:CNode_7071{[0]: ValueNode<Primitive> Return, [1]: param_фx}


subgraph attr:
training : 0
subgraph instance: ✓3↓mindspore_nn_layer_basic_Dense_construct_6996 : 0x561a1de64560
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @✓3↓mindspore_nn_layer_basic_Dense_construct_6996 parent: [subgraph @✓↓mindspore_nn_layer_basic_Dense_construct_4310]() {
  %1(x) = $(↓mindspore_nn_layer_basic_Dense_construct_4255):S_Prim_MatMul[output_names: ["output"], transpose_a: Bool(0), input_names: ["x1", "x2"], transpose_x2: Bool(1), transpose_x1: Bool(0), transpose_b: Bool(1)](%para175_фx, %para5_classifier.weight)
      : (<null>, <Ref[Tensor[Float32]], (5, 2048), ref_key=:classifier.weight>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:627/        x = self.matmul(x, self.weight)/
  %2(x) = $(✓↓mindspore_nn_layer_basic_Dense_construct_4310):S_Prim_BiasAdd[output_names: ["output"], format: "NCHW", input_names: ["x", "b"], data_format: "NCHW"](%1, %para3_classifier.bias)
      : (<null>, <Ref[Tensor[Float32]], (5), ref_key=:classifier.bias>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:629/            x = self.bias_add(x, self.bias)/
  %3(x_shape) = $(mindspore_nn_layer_basic_Dense_construct_4219):S_Prim_Shape(%para164_x)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623/        x_shape = self.shape_op(x)/
  %4(CNode_7072) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %5(CNode_7073) = S_Prim_make_slice(None, %4, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %6(CNode_7074) = S_Prim_getitem(%3, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %7(CNode_7075) = call @shape_4343(%2)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %8(CNode_7076) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %9(CNode_7077) = S_Prim_getitem(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %10(CNode_7078) = S_Prim_MakeTuple(%9)
      : (<null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %11(out_shape) = S_Prim_add(%6, %10)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %12(x) = S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%2, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:634/            x = self.reshape(x, out_shape)/
  Return(%12)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
}
# Order:
#   1: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:CNode_7072{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:CNode_7073{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: CNode_7072, [3]: ValueNode<None> None}
#   3: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:CNode_7074{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_7073}
#   4: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:CNode_7075{[0]: ValueNode<FuncGraph> shape_4343, [1]: x}
#   5: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:CNode_7076{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   6: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:CNode_7077{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_7075, [2]: CNode_7076}
#   7: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:CNode_7078{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_7077}
#   8: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:out_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_7074, [2]: CNode_7078}
#   9: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: x, [2]: out_shape}
#  10: @✓3↓mindspore_nn_layer_basic_Dense_construct_6996:CNode_7079{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 0
subgraph instance: ✗3↓mindspore_nn_layer_basic_Dense_construct_6997 : 0x561a1ddca670
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @✗3↓mindspore_nn_layer_basic_Dense_construct_6997 parent: [subgraph @✓↓mindspore_nn_layer_basic_Dense_construct_4310]() {
  %1(x) = $(↓mindspore_nn_layer_basic_Dense_construct_4255):S_Prim_MatMul[output_names: ["output"], transpose_a: Bool(0), input_names: ["x1", "x2"], transpose_x2: Bool(1), transpose_x1: Bool(0), transpose_b: Bool(1)](%para175_фx, %para5_classifier.weight)
      : (<null>, <Ref[Tensor[Float32]], (5, 2048), ref_key=:classifier.weight>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:627/        x = self.matmul(x, self.weight)/
  %2(x) = $(✓↓mindspore_nn_layer_basic_Dense_construct_4310):S_Prim_BiasAdd[output_names: ["output"], format: "NCHW", input_names: ["x", "b"], data_format: "NCHW"](%1, %para3_classifier.bias)
      : (<null>, <Ref[Tensor[Float32]], (5), ref_key=:classifier.bias>) -> (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:629/            x = self.bias_add(x, self.bias)/
  Return(%2)
      : (<null>)
      #scope: (Default/classifier-Dense)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
}
# Order:
#   1: @✗3↓mindspore_nn_layer_basic_Dense_construct_6997:CNode_7080{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
subgraph instance: ✓↓pad_7016 : 0x561987447f10
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓↓pad_7016 parent: [subgraph @pad_4440]() {
  Return(%para226_input_x)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3395/        return input_x/
}
# Order:
#   1: @✓↓pad_7016:CNode_7081{[0]: ValueNode<Primitive> Return, [1]: param_input_x}


subgraph attr:
subgraph instance: ✗↓pad_7017 : 0x561987410da0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗↓pad_7017 parent: [subgraph @pad_4440]() {
  %1(CNode_7083) = call @2↓pad_7082()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
}
# Order:
#   1: @✗↓pad_7017:CNode_7083{[0]: ValueNode<FuncGraph> 2↓pad_7082}
#   2: @✗↓pad_7017:CNode_7084{[0]: ValueNode<Primitive> Return, [1]: CNode_7083}


subgraph attr:
subgraph instance: ↰↓pad_7006 : 0x561a1f18d5b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @↰↓pad_7006 parent: [subgraph @pad_4440]() {
  %1(CNode_7085) = S_Prim_logical_not(%para227_padding)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
}
# Order:
#   1: @↰↓pad_7006:CNode_7085{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: param_padding}
#   2: @↰↓pad_7006:CNode_7086{[0]: ValueNode<Primitive> Return, [1]: CNode_7085}


subgraph attr:
subgraph instance: ↱↓pad_7007 : 0x561990dc8620
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @↱↓pad_7007 parent: [subgraph @↓pad_5646]() {
  %1(CNode_7002) = $(↓pad_5646):S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %2(CNode_7003) = $(↓pad_5646):S_Prim_isinstance(%para227_padding, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  Return(%2)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
}
# Order:
#   1: @↱↓pad_7007:CNode_7087{[0]: ValueNode<Primitive> Return, [1]: CNode_7003}


subgraph attr:
subgraph instance: ↰↓pad_7011 : 0x561987e3b870
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @↰↓pad_7011 parent: [subgraph @↓pad_5646]() {
  %1(CNode_7002) = $(↓pad_5646):S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %2(CNode_7003) = $(↓pad_5646):S_Prim_isinstance(%para227_padding, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %3(CNode_7004) = $(↓pad_5646):Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %4(CNode_7005) = $(↓pad_5646):Switch(%3, @↰↓pad_7006, @↱↓pad_7007)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %5(CNode_7008) = $(↓pad_5646):%4()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
}
# Order:
#   1: @↰↓pad_7011:CNode_7088{[0]: ValueNode<Primitive> Return, [1]: CNode_7008}


subgraph attr:
subgraph instance: ↱↓pad_7012 : 0x561a21338150
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @↱↓pad_7012 parent: [subgraph @pad_4440]() {
  %1(CNode_7089) = S_Prim_isinstance(%para227_padding, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %2(CNode_7090) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %3(CNode_7091) = Switch(%2, @↰↱↓pad_7092, @2↱↓pad_7093)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %4(CNode_7094) = %3()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
}
# Order:
#   1: @↱↓pad_7012:CNode_7089{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_padding, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   2: @↱↓pad_7012:CNode_7090{[0]: ValueNode<Primitive> Cond, [1]: CNode_7089, [2]: ValueNode<BoolImm> false}
#   3: @↱↓pad_7012:CNode_7091{[0]: ValueNode<Primitive> Switch, [1]: CNode_7090, [2]: ValueNode<FuncGraph> ↰↱↓pad_7092, [3]: ValueNode<FuncGraph> 2↱↓pad_7093}
#   4: @↱↓pad_7012:CNode_7094{[0]: CNode_7091}
#   5: @↱↓pad_7012:CNode_7095{[0]: ValueNode<Primitive> Return, [1]: CNode_7094}


subgraph attr:
subgraph instance: ✓↓div_7023 : 0x561a206b75c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @✓↓div_7023 parent: [subgraph @div_4467]() {
  %1(CNode_7096) = S_Prim_FloorDiv[output_names: ["output"], input_names: ["x", "y"]](%para236_input, %para237_other)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1086/        return tensor_floordiv(input, other)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1086/        return tensor_floordiv(input, other)/
}
# Order:
#   1: @✓↓div_7023:CNode_7096{[0]: ValueNode<DoSignaturePrimitive> S_Prim_FloorDiv, [1]: param_input, [2]: param_other}
#   2: @✓↓div_7023:CNode_7097{[0]: ValueNode<Primitive> Return, [1]: CNode_7096}


subgraph attr:
subgraph instance: ✗↓div_7024 : 0x561a20466400
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @✗↓div_7024 parent: [subgraph @div_4467]() {
  %1(CNode_7099) = call @2↓div_7098()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1085/    if rounding_mode == 'floor':/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1085/    if rounding_mode == 'floor':/
}
# Order:
#   1: @✗↓div_7024:CNode_7099{[0]: ValueNode<FuncGraph> 2↓div_7098}
#   2: @✗↓div_7024:CNode_7100{[0]: ValueNode<Primitive> Return, [1]: CNode_7099}


subgraph attr:
after_block : 1
training : 0
subgraph instance: 3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7056 : 0x56199484a130
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7056(%para479_) {
  %1(CNode_7102) = call @✗3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7101()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:587/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:587/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7056:CNode_7102{[0]: ValueNode<FuncGraph> ✗3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7101}
#   2: @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7056:CNode_7103{[0]: ValueNode<Primitive> Return, [1]: CNode_7102}


subgraph attr:
training : 0
subgraph instance: ✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053 : 0x56198a836500
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624]() {
  %1(out) = $(✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(3), I64(3)), format: "NCHW", strides: (I64(1), I64(1), I64(2), I64(2)), input_names: ["x"]](%para373_фx)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:581/            out = self.max_pool(x)/
  %2(CNode_7104) = S_Prim_isinstance(%1, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
  %3(CNode_7105) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
  %4(CNode_7106) = Switch(%3, @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107, @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7108)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
  %5(CNode_7109) = %4()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
  %6(CNode_7111) = call @↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7110(%5)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindcv/models/bit.py:244/        x = self.max_pool(x)/
  Return(%6)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
}
# Order:
#   1: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053:CNode_7104{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: out, [2]: ValueNode<ClassType> class 'tuple'}
#   2: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053:CNode_7105{[0]: ValueNode<Primitive> Cond, [1]: CNode_7104, [2]: ValueNode<BoolImm> false}
#   3: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053:CNode_7106{[0]: ValueNode<Primitive> Switch, [1]: CNode_7105, [2]: ValueNode<FuncGraph> 2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107, [3]: ValueNode<FuncGraph> ✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7108}
#   4: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053:CNode_7109{[0]: CNode_7106}
#   5: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053:CNode_7111{[0]: ValueNode<FuncGraph> ↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7110, [1]: CNode_7109}
#   6: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7053:CNode_7112{[0]: ValueNode<Primitive> Return, [1]: CNode_7111}


subgraph attr:
training : 0
subgraph instance: ✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7054 : 0x5619a1540e20
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7054 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624]() {
  %1(out) = $(✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(3), I64(3)), format: "NCHW", strides: (I64(1), I64(1), I64(2), I64(2)), input_names: ["x"]](%para373_фx)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:581/            out = self.max_pool(x)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
}
# Order:
#   1: @✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7054:CNode_7113{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
subgraph instance: ✓↓sum_7067 : 0x56198aa2b4f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✓↓sum_7067 parent: [subgraph @sum_4798]() {
  %1(CNode_7114) = S_Prim_MakeTuple("dim")
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12013/        raise TypeError(f"For 'sum', 'dim' must be int, tuple(int), list(int) or None, but got {type(dim)}")/
  %2(CNode_7115) = S_Prim_MakeTuple(%para376_dim)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12013/        raise TypeError(f"For 'sum', 'dim' must be int, tuple(int), list(int) or None, but got {type(dim)}")/
  %3(CNode_7116) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12013/        raise TypeError(f"For 'sum', 'dim' must be int, tuple(int), list(int) or None, but got {type(dim)}")/
  %4(ValueNode_7117) = PyInterpret[side_effect_io: Bool(1)](Script['f"For 'sum', 'dim' must be int, tuple(int), list(int) or None, but got {type(dim)}"'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12013/        raise TypeError(f"For 'sum', 'dim' must be int, tuple(int), list(int) or None, but got {type(dim)}")/
  %5(CNode_7118) = raise[side_effect_io: Bool(1)]("TypeError", %4, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12013/        raise TypeError(f"For 'sum', 'dim' must be int, tuple(int), list(int) or None, but got {type(dim)}")/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12013/        raise TypeError(f"For 'sum', 'dim' must be int, tuple(int), list(int) or None, but got {type(dim)}")/
}
# Order:
#   1: @✓↓sum_7067:CNode_7114{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> dim}
#   2: @✓↓sum_7067:CNode_7115{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_dim}
#   3: @✓↓sum_7067:CNode_7116{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_7114, [2]: CNode_7115}
#   4: @✓↓sum_7067:ValueNode_7117{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'f"For 'sum', 'dim' must be int, tuple(int), list(int) or None, but got {type(dim)}"', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'isinstance': <built-in function isinstance>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>, 'type': <class 'type'>, 'int': <class 'int'>, 'tuple': <class 'tuple'>, 'list': <class 'list'>}), [3]: CNode_7116}
#   5: @✓↓sum_7067:CNode_7118{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: ValueNode_7117, [3]: ValueNode<StringImm> None}
#   6: @✓↓sum_7067:CNode_7119{[0]: ValueNode<Primitive> Return, [1]: CNode_7118}


subgraph attr:
subgraph instance: ✗↓sum_7068 : 0x561986c7a230
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✗↓sum_7068 parent: [subgraph @sum_4798]() {
  %1(CNode_7121) = call @2↓sum_7120()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
}
# Order:
#   1: @✗↓sum_7068:CNode_7121{[0]: ValueNode<FuncGraph> 2↓sum_7120}
#   2: @✗↓sum_7068:CNode_7122{[0]: ValueNode<Primitive> Return, [1]: CNode_7121}


subgraph attr:
subgraph instance: ↰↓sum_7062 : 0x5619891cd240
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @↰↓sum_7062 parent: [subgraph @sum_4798]() {
  %1(CNode_7123) = S_Prim_MakeTuple(ClassType, ClassType, ClassType)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  %2(CNode_7124) = S_Prim_isinstance(%para376_dim, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  %3(CNode_7125) = S_Prim_logical_not(%2)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  Return(%3)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
}
# Order:
#   1: @↰↓sum_7062:CNode_7123{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'int', [2]: ValueNode<ClassType> class 'tuple', [3]: ValueNode<ClassType> class 'list'}
#   2: @↰↓sum_7062:CNode_7124{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_dim, [2]: CNode_7123}
#   3: @↰↓sum_7062:CNode_7125{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_7124}
#   4: @↰↓sum_7062:CNode_7126{[0]: ValueNode<Primitive> Return, [1]: CNode_7125}


subgraph attr:
subgraph instance: ↱↓sum_7063 : 0x561985ec4770
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @↱↓sum_7063 parent: [subgraph @↓sum_6987]() {
  %1(CNode_7059) = $(↓sum_6987):S_Prim_is_not(%para376_dim, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12012/    if dim is not None and not isinstance(dim, (int, tuple, list)):/
}
# Order:
#   1: @↱↓sum_7063:CNode_7127{[0]: ValueNode<Primitive> Return, [1]: CNode_7059}


subgraph attr:
after_block : 1
subgraph instance: 2↓pad_7082 : 0x5619873dee30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @2↓pad_7082 parent: [subgraph @pad_4440]() {
  %1(CNode_7128) = S_Prim_isinstance(%para227_padding, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3396/    if not isinstance(padding, Tensor):/
  %2(CNode_7129) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3396/    if not isinstance(padding, Tensor):/
  %3(CNode_7130) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3396/    if not isinstance(padding, Tensor):/
  %4(CNode_7131) = Switch(%3, @✓2↓pad_7132, @✗2↓pad_7133)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3396/    if not isinstance(padding, Tensor):/
  %5(CNode_7134) = %4()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3396/    if not isinstance(padding, Tensor):/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3396/    if not isinstance(padding, Tensor):/
}
# Order:
#   1: @2↓pad_7082:CNode_7128{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_padding, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   2: @2↓pad_7082:CNode_7129{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_7128}
#   3: @2↓pad_7082:CNode_7130{[0]: ValueNode<Primitive> Cond, [1]: CNode_7129, [2]: ValueNode<BoolImm> false}
#   4: @2↓pad_7082:CNode_7131{[0]: ValueNode<Primitive> Switch, [1]: CNode_7130, [2]: ValueNode<FuncGraph> ✓2↓pad_7132, [3]: ValueNode<FuncGraph> ✗2↓pad_7133}
#   5: @2↓pad_7082:CNode_7134{[0]: CNode_7131}
#   6: @2↓pad_7082:CNode_7135{[0]: ValueNode<Primitive> Return, [1]: CNode_7134}


subgraph attr:
subgraph instance: ↰↱↓pad_7092 : 0x561993841030
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @↰↱↓pad_7092 parent: [subgraph @pad_4440]() {
  %1(CNode_7136) = getattr(%para227_padding, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %2(CNode_7137) = S_Prim_MakeTuple(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  %3(CNode_7138) = S_Prim_equal(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
}
# Order:
#   1: @↰↱↓pad_7092:CNode_7136{[0]: ValueNode<Primitive> getattr, [1]: param_padding, [2]: ValueNode<StringImm> shape}
#   2: @↰↱↓pad_7092:CNode_7137{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0}
#   3: @↰↱↓pad_7092:CNode_7138{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_7136, [2]: CNode_7137}
#   4: @↰↱↓pad_7092:CNode_7139{[0]: ValueNode<Primitive> Return, [1]: CNode_7138}


subgraph attr:
subgraph instance: 2↱↓pad_7093 : 0x56198749c0c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @2↱↓pad_7093 parent: [subgraph @↱↓pad_7012]() {
  %1(CNode_7089) = $(↱↓pad_7012):S_Prim_isinstance(%para227_padding, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3394/    if (isinstance(padding, (tuple, list)) and not padding) or (isinstance(padding, Tensor) and padding.shape == (0,)):/
}
# Order:
#   1: @2↱↓pad_7093:CNode_7140{[0]: ValueNode<Primitive> Return, [1]: CNode_7089}


subgraph attr:
after_block : 1
subgraph instance: 2↓div_7098 : 0x561a202dc950
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @2↓div_7098 parent: [subgraph @div_4467]() {
  %1(CNode_7141) = S_Prim_equal(%para238_rounding_mode, "trunc")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1088/    if rounding_mode == 'trunc':/
  %2(CNode_7142) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1088/    if rounding_mode == 'trunc':/
  %3(CNode_7143) = Switch(%2, @✓2↓div_7144, @✗2↓div_7145)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1088/    if rounding_mode == 'trunc':/
  %4(CNode_7146) = %3()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1088/    if rounding_mode == 'trunc':/
  %5(CNode_7148) = call @3↓div_7147(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:1156/        var = F.div(self.reduce_sum(F.square(F.sub(x, mean)), 2), (channel * height * width / self.num_groups))/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1088/    if rounding_mode == 'trunc':/
}
# Order:
#   1: @2↓div_7098:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Div, [1]: param_input, [2]: param_other}
#   2: @2↓div_7098:CNode_7141{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_rounding_mode, [2]: ValueNode<StringImm> trunc}
#   3: @2↓div_7098:CNode_7142{[0]: ValueNode<Primitive> Cond, [1]: CNode_7141, [2]: ValueNode<BoolImm> false}
#   4: @2↓div_7098:CNode_7143{[0]: ValueNode<Primitive> Switch, [1]: CNode_7142, [2]: ValueNode<FuncGraph> ✓2↓div_7144, [3]: ValueNode<FuncGraph> ✗2↓div_7145}
#   5: @2↓div_7098:CNode_7146{[0]: CNode_7143}
#   6: @2↓div_7098:CNode_7148{[0]: ValueNode<FuncGraph> 3↓div_7147, [1]: CNode_7146}
#   7: @2↓div_7098:CNode_7149{[0]: ValueNode<Primitive> Return, [1]: CNode_7148}


subgraph attr:
training : 0
subgraph instance: ✗3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7101 : 0x561a19509db0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7101 parent: [subgraph @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7056]() {
  %1(CNode_7151) = call @4↓mindspore_nn_layer_pooling_MaxPool2d_construct_7150()
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:587/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:587/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @✗3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7101:CNode_7151{[0]: ValueNode<FuncGraph> 4↓mindspore_nn_layer_pooling_MaxPool2d_construct_7150}
#   2: @✗3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7101:CNode_7152{[0]: ValueNode<Primitive> Return, [1]: CNode_7151}


subgraph attr:
after_block : 1
training : 0
subgraph instance: ↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7110 : 0x561a16cea610
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7110(%para480_) {
  Return(%para480_фout)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
}
# Order:
#   1: @↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7110:CNode_7153{[0]: ValueNode<Primitive> Return, [1]: param_фout}


subgraph attr:
training : 0
subgraph instance: 2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107 : 0x561993dead10
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624]() {
  %1(out) = $(✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(3), I64(3)), format: "NCHW", strides: (I64(1), I64(1), I64(2), I64(2)), input_names: ["x"]](%para373_фx)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:581/            out = self.max_pool(x)/
  %2(CNode_7154) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %3(CNode_7155) = getattr(%2, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %4(CNode_7156) = %3(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %5(CNode_7157) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %6(CNode_7158) = getattr(%5, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %7(CNode_7159) = %6(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %8(out) = S_Prim_MakeTuple(%4, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
}
# Order:
#   1: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107:CNode_7154{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: out, [2]: ValueNode<Int64Imm> 0}
#   2: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107:CNode_7155{[0]: ValueNode<Primitive> getattr, [1]: CNode_7154, [2]: ValueNode<StringImm> squeeze}
#   3: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107:CNode_7156{[0]: CNode_7155, [1]: ValueNode<Int64Imm> 0}
#   4: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107:CNode_7157{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: out, [2]: ValueNode<Int64Imm> 1}
#   5: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107:CNode_7158{[0]: ValueNode<Primitive> getattr, [1]: CNode_7157, [2]: ValueNode<StringImm> squeeze}
#   6: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107:CNode_7159{[0]: CNode_7158, [1]: ValueNode<Int64Imm> 0}
#   7: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_7156, [2]: CNode_7159}
#   8: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7107:CNode_7160{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 0
subgraph instance: ✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7108 : 0x56198ec3a420
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7108 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624]() {
  %1(out) = $(✗↓mindspore_nn_layer_pooling_MaxPool2d_construct_5624):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(3), I64(3)), format: "NCHW", strides: (I64(1), I64(1), I64(2), I64(2)), input_names: ["x"]](%para373_фx)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:581/            out = self.max_pool(x)/
  %2(CNode_7161) = getattr(%1, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:586/                out = out.squeeze(0)/
  %3(out) = %2(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:586/                out = out.squeeze(0)/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:586/                out = out.squeeze(0)/
}
# Order:
#   1: @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7108:CNode_7161{[0]: ValueNode<Primitive> getattr, [1]: out, [2]: ValueNode<StringImm> squeeze}
#   2: @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7108:out{[0]: CNode_7161, [1]: ValueNode<Int64Imm> 0}
#   3: @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_7108:CNode_7162{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
after_block : 1
subgraph instance: 2↓sum_7120 : 0x561a143386f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @2↓sum_7120 parent: [subgraph @sum_4798]() {
  %1(CNode_7163) = S_Prim_isinstance(%para377_keepdim, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12014/    if not isinstance(keepdim, bool):/
  %2(CNode_7164) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12014/    if not isinstance(keepdim, bool):/
  %3(CNode_7165) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12014/    if not isinstance(keepdim, bool):/
  %4(CNode_7166) = Switch(%3, @✓2↓sum_7167, @✗2↓sum_7168)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12014/    if not isinstance(keepdim, bool):/
  %5(CNode_7169) = %4()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12014/    if not isinstance(keepdim, bool):/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12014/    if not isinstance(keepdim, bool):/
}
# Order:
#   1: @2↓sum_7120:CNode_7163{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_keepdim, [2]: ValueNode<ClassType> class 'bool'}
#   2: @2↓sum_7120:CNode_7164{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_7163}
#   3: @2↓sum_7120:CNode_7165{[0]: ValueNode<Primitive> Cond, [1]: CNode_7164, [2]: ValueNode<BoolImm> false}
#   4: @2↓sum_7120:CNode_7166{[0]: ValueNode<Primitive> Switch, [1]: CNode_7165, [2]: ValueNode<FuncGraph> ✓2↓sum_7167, [3]: ValueNode<FuncGraph> ✗2↓sum_7168}
#   5: @2↓sum_7120:CNode_7169{[0]: CNode_7166}
#   6: @2↓sum_7120:CNode_7170{[0]: ValueNode<Primitive> Return, [1]: CNode_7169}


subgraph attr:
subgraph instance: ✓2↓pad_7132 : 0x5619871619e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓2↓pad_7132 parent: [subgraph @pad_4440]() {
  %1(CNode_7171) = S_Prim__check_pad_inputs[constexpr_prim: Bool(1)](%para227_padding)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3397/        _check_pad_inputs(padding)/
  %2(CNode_7172) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
  %3(CNode_7173) = S_Prim_MakeTuple("padding")
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3398/        padding = Tensor(padding)/
  %4(CNode_7174) = S_Prim_MakeTuple(%para227_padding)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3398/        padding = Tensor(padding)/
  %5(CNode_7175) = S_Prim_make_dict(%3, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3398/        padding = Tensor(padding)/
  %6(padding) = PyInterpret[side_effect_io: Bool(1)](Script['Tensor(padding)'], InterpretedObject, %5)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3398/        padding = Tensor(padding)/
  %7(CNode_7177) = call @3↓pad_7176(%6)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %8(CNode_7178) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3397/        _check_pad_inputs(padding)/
  Return(%8)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3397/        _check_pad_inputs(padding)/
}
# Order:
#   1: @✓2↓pad_7132:CNode_7171{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_pad_inputs, [1]: param_padding}
#   2: @✓2↓pad_7132:CNode_7173{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> padding}
#   3: @✓2↓pad_7132:CNode_7174{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_padding}
#   4: @✓2↓pad_7132:CNode_7175{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_7173, [2]: CNode_7174}
#   5: @✓2↓pad_7132:padding{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'Tensor(padding)', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'isinstance': <built-in function isinstance>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>, 'type': <class 'type'>, 'tuple': <class 'tuple'>, 'list': <class 'list'>, '_check_pad_inputs': Prim[_check_pad_inputs]<constexpr_prim=True>}), [3]: CNode_7175}
#   6: @✓2↓pad_7132:CNode_7179{[0]: ValueNode<Primitive> Return, [1]: CNode_7178}
#   7: @✓2↓pad_7132:CNode_7177{[0]: ValueNode<FuncGraph> 3↓pad_7176, [1]: padding}


subgraph attr:
subgraph instance: ✗2↓pad_7133 : 0x561987109650
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗2↓pad_7133 parent: [subgraph @pad_4440]() {
  %1(CNode_7180) = call @3↓pad_7176(%para227_padding)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3396/    if not isinstance(padding, Tensor):/
}
# Order:
#   1: @✗2↓pad_7133:CNode_7181{[0]: ValueNode<Primitive> Return, [1]: CNode_7180}
#   2: @✗2↓pad_7133:CNode_7180{[0]: ValueNode<FuncGraph> 3↓pad_7176, [1]: param_padding}


subgraph attr:
after_block : 1
subgraph instance: 3↓div_7147 : 0x561993e998e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @3↓div_7147(%para481_) {
  Return(%para481_фoutput)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1090/    return output/
}
# Order:
#   1: @3↓div_7147:CNode_7182{[0]: ValueNode<Primitive> Return, [1]: param_фoutput}


subgraph attr:
subgraph instance: ✓2↓div_7144 : 0x561a20268480
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @✓2↓div_7144 parent: [subgraph @2↓div_7098]() {
  %1(output) = $(2↓div_7098):S_Prim_Div[output_names: ["output"], input_names: ["x", "y"]](%para236_input, %para237_other)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1087/    output = div_(input, other)/
  %2(output) = S_Prim_Trunc[output_names: ["output"], input_names: ["input"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1089/        output = trunc_(output)/
  Return(%2)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1089/        output = trunc_(output)/
}
# Order:
#   1: @✓2↓div_7144:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Trunc, [1]: output}
#   2: @✓2↓div_7144:CNode_7183{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
subgraph instance: ✗2↓div_7145 : 0x561a20307ea0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1028/def div(input, other, *, rounding_mode=None):/
subgraph @✗2↓div_7145 parent: [subgraph @2↓div_7098]() {
  %1(output) = $(2↓div_7098):S_Prim_Div[output_names: ["output"], input_names: ["x", "y"]](%para236_input, %para237_other)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1087/    output = div_(input, other)/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/gn-GroupNorm)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:1088/    if rounding_mode == 'trunc':/
}
# Order:
#   1: @✗2↓div_7145:CNode_7184{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 0
subgraph instance: 4↓mindspore_nn_layer_pooling_MaxPool2d_construct_7150 : 0x5619a1aad490
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @4↓mindspore_nn_layer_pooling_MaxPool2d_construct_7150 parent: [subgraph @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_7056]() {
  Return(%para479_фout)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-BiT_ResNet/max_pool-MaxPool2d)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:589/        return out/
}
# Order:
#   1: @4↓mindspore_nn_layer_pooling_MaxPool2d_construct_7150:CNode_7185{[0]: ValueNode<Primitive> Return, [1]: param_фout}


subgraph attr:
subgraph instance: ✓2↓sum_7167 : 0x561a12cf1290
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✓2↓sum_7167 parent: [subgraph @sum_4798]() {
  %1(CNode_7186) = S_Prim_MakeTuple("keepdim")
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12015/        raise TypeError(f"For 'sum', 'keepdim' must be bool, but got {type(keepdim)}")/
  %2(CNode_7187) = S_Prim_MakeTuple(%para377_keepdim)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12015/        raise TypeError(f"For 'sum', 'keepdim' must be bool, but got {type(keepdim)}")/
  %3(CNode_7188) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12015/        raise TypeError(f"For 'sum', 'keepdim' must be bool, but got {type(keepdim)}")/
  %4(ValueNode_7189) = PyInterpret[side_effect_io: Bool(1)](Script['f"For 'sum', 'keepdim' must be bool, but got {type(keepdim)}"'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12015/        raise TypeError(f"For 'sum', 'keepdim' must be bool, but got {type(keepdim)}")/
  %5(CNode_7190) = raise[side_effect_io: Bool(1)]("TypeError", %4, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12015/        raise TypeError(f"For 'sum', 'keepdim' must be bool, but got {type(keepdim)}")/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12015/        raise TypeError(f"For 'sum', 'keepdim' must be bool, but got {type(keepdim)}")/
}
# Order:
#   1: @✓2↓sum_7167:CNode_7186{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keepdim}
#   2: @✓2↓sum_7167:CNode_7187{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_keepdim}
#   3: @✓2↓sum_7167:CNode_7188{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_7186, [2]: CNode_7187}
#   4: @✓2↓sum_7167:ValueNode_7189{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'f"For 'sum', 'keepdim' must be bool, but got {type(keepdim)}"', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'isinstance': <built-in function isinstance>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>, 'type': <class 'type'>, 'int': <class 'int'>, 'tuple': <class 'tuple'>, 'list': <class 'list'>, 'bool': <class 'bool'>}), [3]: CNode_7188}
#   5: @✓2↓sum_7167:CNode_7190{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: ValueNode_7189, [3]: ValueNode<StringImm> None}
#   6: @✓2↓sum_7167:CNode_7191{[0]: ValueNode<Primitive> Return, [1]: CNode_7190}


subgraph attr:
subgraph instance: ✗2↓sum_7168 : 0x5619939e85b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✗2↓sum_7168 parent: [subgraph @sum_4798]() {
  %1(CNode_7193) = call @3↓sum_7192()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12014/    if not isinstance(keepdim, bool):/
  Return(%1)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12014/    if not isinstance(keepdim, bool):/
}
# Order:
#   1: @✗2↓sum_7168:CNode_7193{[0]: ValueNode<FuncGraph> 3↓sum_7192}
#   2: @✗2↓sum_7168:CNode_7194{[0]: ValueNode<Primitive> Return, [1]: CNode_7193}


subgraph attr:
after_block : 1
subgraph instance: 3↓pad_7176 : 0x561986c95850
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @3↓pad_7176 parent: [subgraph @pad_4440](%para482_) {
  %1(CNode_7195) = S_Prim_equal(%para228_mode, "constant")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3400/    if mode == "constant":/
  %2(CNode_7196) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3400/    if mode == "constant":/
  %3(CNode_7197) = Switch(%2, @✓3↓pad_7198, @✗3↓pad_7199)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3400/    if mode == "constant":/
  %4(CNode_7200) = %3()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3400/    if mode == "constant":/
  %5(CNode_7201) = TupleGetItem(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %6(CNode_7202) = TupleGetItem(%4, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %7(CNode_7203) = TupleGetItem(%4, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %8(CNode_7204) = TupleGetItem(%4, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  %9(CNode_7206) = call @4↓pad_7205(%5, %6, %7, %8)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3400/    if mode == "constant":/
}
# Order:
#   1: @3↓pad_7176:CNode_7195{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_mode, [2]: ValueNode<StringImm> constant}
#   2: @3↓pad_7176:CNode_7196{[0]: ValueNode<Primitive> Cond, [1]: CNode_7195, [2]: ValueNode<BoolImm> false}
#   3: @3↓pad_7176:CNode_7197{[0]: ValueNode<Primitive> Switch, [1]: CNode_7196, [2]: ValueNode<FuncGraph> ✓3↓pad_7198, [3]: ValueNode<FuncGraph> ✗3↓pad_7199}
#   4: @3↓pad_7176:CNode_7200{[0]: CNode_7197}
#   5: @3↓pad_7176:CNode_7206{[0]: ValueNode<FuncGraph> 4↓pad_7205, [1]: CNode_7201, [2]: CNode_7202, [3]: CNode_7203, [4]: CNode_7204}
#   6: @3↓pad_7176:CNode_7207{[0]: ValueNode<Primitive> Return, [1]: CNode_7206}
#   7: @3↓pad_7176:CNode_7201{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_7200, [2]: ValueNode<Int64Imm> 0}
#   8: @3↓pad_7176:CNode_7202{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_7200, [2]: ValueNode<Int64Imm> 1}
#   9: @3↓pad_7176:CNode_7203{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_7200, [2]: ValueNode<Int64Imm> 2}
#  10: @3↓pad_7176:CNode_7204{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_7200, [2]: ValueNode<Int64Imm> 3}


subgraph attr:
after_block : 1
subgraph instance: 3↓sum_7192 : 0x561987435e90
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @3↓sum_7192 parent: [subgraph @sum_4798]() {
  %1(CNode_7208) = getattr(%para375_input, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12017/    if input.dtype == mstype.bool_:/
  %2(CNode_7209) = S_Prim_equal(%1, Bool)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12017/    if input.dtype == mstype.bool_:/
  %3(CNode_7210) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12017/    if input.dtype == mstype.bool_:/
  %4(CNode_7211) = Switch(%3, @✓3↓sum_7212, @✗3↓sum_7213)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12017/    if input.dtype == mstype.bool_:/
  %5(CNode_7214) = %4()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12017/    if input.dtype == mstype.bool_:/
  %6(CNode_7216) = call @4↓sum_7215(%5)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:39/
  Return(%6)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12017/    if input.dtype == mstype.bool_:/
}
# Order:
#   1: @3↓sum_7192:CNode_7208{[0]: ValueNode<Primitive> getattr, [1]: param_input, [2]: ValueNode<StringImm> dtype}
#   2: @3↓sum_7192:CNode_7209{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_7208, [2]: ValueNode<Bool> Bool}
#   3: @3↓sum_7192:CNode_7210{[0]: ValueNode<Primitive> Cond, [1]: CNode_7209, [2]: ValueNode<BoolImm> false}
#   4: @3↓sum_7192:CNode_7211{[0]: ValueNode<Primitive> Switch, [1]: CNode_7210, [2]: ValueNode<FuncGraph> ✓3↓sum_7212, [3]: ValueNode<FuncGraph> ✗3↓sum_7213}
#   5: @3↓sum_7192:CNode_7214{[0]: CNode_7211}
#   6: @3↓sum_7192:CNode_7216{[0]: ValueNode<FuncGraph> 4↓sum_7215, [1]: CNode_7214}
#   7: @3↓sum_7192:CNode_7217{[0]: ValueNode<Primitive> Return, [1]: CNode_7216}


subgraph attr:
after_block : 1
subgraph instance: 4↓pad_7205 : 0x561991aa08d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @4↓pad_7205 parent: [subgraph @3↓pad_7176](%para483_, %para484_, %para485_, %para486_) {
  %1(CNode_7218) = Cond(%para486_фis_expand, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3415/    if is_expand:/
  %2(CNode_7219) = Switch(%1, @✓4↓pad_7220, @✗4↓pad_7221)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3415/    if is_expand:/
  %3(CNode_7222) = %2()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3415/    if is_expand:/
  %4(CNode_7224) = call @5↓pad_7223(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3415/    if is_expand:/
}
# Order:
#   1: @4↓pad_7205:CNode_7225{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> mode, [2]: ValueNode<StringImm> paddings_contiguous}
#   2: @4↓pad_7205:CNode_7226{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_фmode, [2]: ValueNode<BoolImm> true}
#   3: @4↓pad_7205:CNode_7227{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_7225, [2]: CNode_7226}
#   4: @4↓pad_7205:CNode_7228{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.7229, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.nn_ops.PadV3', [2]: CNode_7227}
#   5: @4↓pad_7205:out{[0]: CNode_7228, [1]: param_фinput_x, [2]: param_фpadding, [3]: param_фvalue}
#   6: @4↓pad_7205:CNode_7218{[0]: ValueNode<Primitive> Cond, [1]: param_фis_expand, [2]: ValueNode<BoolImm> false}
#   7: @4↓pad_7205:CNode_7219{[0]: ValueNode<Primitive> Switch, [1]: CNode_7218, [2]: ValueNode<FuncGraph> ✓4↓pad_7220, [3]: ValueNode<FuncGraph> ✗4↓pad_7221}
#   8: @4↓pad_7205:CNode_7222{[0]: CNode_7219}
#   9: @4↓pad_7205:CNode_7224{[0]: ValueNode<FuncGraph> 5↓pad_7223, [1]: CNode_7222}
#  10: @4↓pad_7205:CNode_7230{[0]: ValueNode<Primitive> Return, [1]: CNode_7224}


subgraph attr:
subgraph instance: ✓3↓pad_7198 : 0x561986b9add0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓3↓pad_7198 parent: [subgraph @pad_4440]() {
  %1(CNode_7231) = S_Prim_is_(%para229_value, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %2(CNode_7232) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %3(CNode_7233) = Switch(%2, @↰✓3↓pad_7234, @↱✓3↓pad_7235)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %4(value) = %3()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %5(CNode_7236) = S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3402/        if isinstance(value, (float, int)):/
  %6(CNode_7237) = S_Prim_isinstance(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3402/        if isinstance(value, (float, int)):/
  %7(CNode_7238) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3402/        if isinstance(value, (float, int)):/
  %8(CNode_7239) = Switch(%7, @2✓3↓pad_7240, @✗✓3↓pad_7241)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3402/        if isinstance(value, (float, int)):/
  %9(CNode_7242) = %8()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3402/        if isinstance(value, (float, int)):/
  %10(CNode_7244) = call @↓✓3↓pad_7243(%9)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%10)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3402/        if isinstance(value, (float, int)):/
}
# Order:
#   1: @✓3↓pad_7198:CNode_7231{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: param_value, [2]: ValueNode<None> None}
#   2: @✓3↓pad_7198:CNode_7232{[0]: ValueNode<Primitive> Cond, [1]: CNode_7231, [2]: ValueNode<BoolImm> false}
#   3: @✓3↓pad_7198:CNode_7233{[0]: ValueNode<Primitive> Switch, [1]: CNode_7232, [2]: ValueNode<FuncGraph> ↰✓3↓pad_7234, [3]: ValueNode<FuncGraph> ↱✓3↓pad_7235}
#   4: @✓3↓pad_7198:value{[0]: CNode_7233}
#   5: @✓3↓pad_7198:CNode_7236{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'float', [2]: ValueNode<ClassType> class 'int'}
#   6: @✓3↓pad_7198:CNode_7237{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: value, [2]: CNode_7236}
#   7: @✓3↓pad_7198:CNode_7238{[0]: ValueNode<Primitive> Cond, [1]: CNode_7237, [2]: ValueNode<BoolImm> false}
#   8: @✓3↓pad_7198:CNode_7239{[0]: ValueNode<Primitive> Switch, [1]: CNode_7238, [2]: ValueNode<FuncGraph> 2✓3↓pad_7240, [3]: ValueNode<FuncGraph> ✗✓3↓pad_7241}
#   9: @✓3↓pad_7198:CNode_7242{[0]: CNode_7239}
#  10: @✓3↓pad_7198:CNode_7244{[0]: ValueNode<FuncGraph> ↓✓3↓pad_7243, [1]: CNode_7242}
#  11: @✓3↓pad_7198:CNode_7245{[0]: ValueNode<Primitive> Return, [1]: CNode_7244}


subgraph attr:
subgraph instance: ✗3↓pad_7199 : 0x561991aa31f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗3↓pad_7199 parent: [subgraph @3↓pad_7176]() {
  %1(CNode_7246) = S_Prim_inner_len(%para482_фpadding)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
  %2(CNode_7247) = S_Prim_greater(%1, I64(6))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
  %3(CNode_7248) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
  %4(CNode_7249) = Switch(%3, @✓✗3↓pad_7250, @2✗3↓pad_7251)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
  %5(CNode_7252) = %4()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
}
# Order:
#   1: @✗3↓pad_7199:CNode_7246{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фpadding}
#   2: @✗3↓pad_7199:CNode_7247{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: CNode_7246, [2]: ValueNode<Int64Imm> 6}
#   3: @✗3↓pad_7199:CNode_7248{[0]: ValueNode<Primitive> Cond, [1]: CNode_7247, [2]: ValueNode<BoolImm> false}
#   4: @✗3↓pad_7199:CNode_7249{[0]: ValueNode<Primitive> Switch, [1]: CNode_7248, [2]: ValueNode<FuncGraph> ✓✗3↓pad_7250, [3]: ValueNode<FuncGraph> 2✗3↓pad_7251}
#   5: @✗3↓pad_7199:CNode_7252{[0]: CNode_7249}
#   6: @✗3↓pad_7199:CNode_7253{[0]: ValueNode<Primitive> Return, [1]: CNode_7252}


subgraph attr:
after_block : 1
subgraph instance: 4↓sum_7215 : 0x561992082e00
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @4↓sum_7215 parent: [subgraph @sum_4798](%para487_) {
  %1(CNode_7254) = S_Prim_is_not(%para378_dtype, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12019/    if dtype is not None:/
  %2(CNode_7255) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12019/    if dtype is not None:/
  %3(CNode_7256) = Switch(%2, @✓4↓sum_7257, @✗4↓sum_7258)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12019/    if dtype is not None:/
  %4(CNode_7259) = %3()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12019/    if dtype is not None:/
  %5(CNode_7261) = call @5↓sum_7260(%4)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:39/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12019/    if dtype is not None:/
}
# Order:
#   1: @4↓sum_7215:CNode_7254{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: param_dtype, [2]: ValueNode<None> None}
#   2: @4↓sum_7215:CNode_7255{[0]: ValueNode<Primitive> Cond, [1]: CNode_7254, [2]: ValueNode<BoolImm> false}
#   3: @4↓sum_7215:CNode_7256{[0]: ValueNode<Primitive> Switch, [1]: CNode_7255, [2]: ValueNode<FuncGraph> ✓4↓sum_7257, [3]: ValueNode<FuncGraph> ✗4↓sum_7258}
#   4: @4↓sum_7215:CNode_7259{[0]: CNode_7256}
#   5: @4↓sum_7215:CNode_7261{[0]: ValueNode<FuncGraph> 5↓sum_7260, [1]: CNode_7259}
#   6: @4↓sum_7215:CNode_7262{[0]: ValueNode<Primitive> Return, [1]: CNode_7261}


subgraph attr:
subgraph instance: ✓3↓sum_7212 : 0x56198781a4a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✓3↓sum_7212 parent: [subgraph @sum_4798]() {
  %1(CNode_7263) = getattr(%para375_input, "astype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12018/        input = input.astype(mstype.int64)/
  %2(input) = %1(I64)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12018/        input = input.astype(mstype.int64)/
  Return(%2)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12018/        input = input.astype(mstype.int64)/
}
# Order:
#   1: @✓3↓sum_7212:CNode_7263{[0]: ValueNode<Primitive> getattr, [1]: param_input, [2]: ValueNode<StringImm> astype}
#   2: @✓3↓sum_7212:input{[0]: CNode_7263, [1]: ValueNode<Int> Int64}
#   3: @✓3↓sum_7212:CNode_7264{[0]: ValueNode<Primitive> Return, [1]: input}


subgraph attr:
subgraph instance: ✗3↓sum_7213 : 0x56198add93b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✗3↓sum_7213 parent: [subgraph @sum_4798]() {
  Return(%para375_input)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12017/    if input.dtype == mstype.bool_:/
}
# Order:
#   1: @✗3↓sum_7213:CNode_7265{[0]: ValueNode<Primitive> Return, [1]: param_input}


subgraph attr:
after_block : 1
subgraph instance: 5↓pad_7223 : 0x561a17b85c60
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @5↓pad_7223(%para488_) {
  Return(%para488_фout)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3417/    return out/
}
# Order:
#   1: @5↓pad_7223:CNode_7266{[0]: ValueNode<Primitive> Return, [1]: param_фout}


subgraph attr:
subgraph instance: ✓4↓pad_7220 : 0x561a17c488a0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓4↓pad_7220 parent: [subgraph @4↓pad_7205]() {
  %1(CNode_7225) = $(4↓pad_7205):S_Prim_MakeTuple("mode", "paddings_contiguous")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %2(CNode_7226) = $(4↓pad_7205):S_Prim_MakeTuple(%para483_фmode, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %3(CNode_7227) = $(4↓pad_7205):S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %4(CNode_7228) = $(4↓pad_7205):UnpackCall_unpack_call(ClassType, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %5(out) = $(4↓pad_7205):%4(%para484_фinput_x, %para482_фpadding, %para485_фvalue)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %6(CNode_7267) = getattr(%5, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3416/        out = out.squeeze(0)/
  %7(out) = %6(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3416/        out = out.squeeze(0)/
  Return(%7)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3416/        out = out.squeeze(0)/
}
# Order:
#   1: @✓4↓pad_7220:CNode_7267{[0]: ValueNode<Primitive> getattr, [1]: out, [2]: ValueNode<StringImm> squeeze}
#   2: @✓4↓pad_7220:out{[0]: CNode_7267, [1]: ValueNode<Int64Imm> 0}
#   3: @✓4↓pad_7220:CNode_7268{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
subgraph instance: ✗4↓pad_7221 : 0x561a17bf8860
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗4↓pad_7221 parent: [subgraph @4↓pad_7205]() {
  %1(CNode_7225) = $(4↓pad_7205):S_Prim_MakeTuple("mode", "paddings_contiguous")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %2(CNode_7226) = $(4↓pad_7205):S_Prim_MakeTuple(%para483_фmode, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %3(CNode_7227) = $(4↓pad_7205):S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %4(CNode_7228) = $(4↓pad_7205):UnpackCall_unpack_call(ClassType, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  %5(out) = $(4↓pad_7205):%4(%para484_фinput_x, %para482_фpadding, %para485_фvalue)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3414/    out = PadV3(mode=mode, paddings_contiguous=True)(input_x, padding, value)/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3415/    if is_expand:/
}
# Order:
#   1: @✗4↓pad_7221:CNode_7269{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
after_block : 1
subgraph instance: ↓✓3↓pad_7243 : 0x561991889970
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @↓✓3↓pad_7243 parent: [subgraph @pad_4440](%para489_) {
  %1(CNode_7270) = MakeTuple(%para228_mode, %para226_input_x, %para489_фvalue, Bool(0))
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
}
# Order:
#   1: @↓✓3↓pad_7243:CNode_7271{[0]: ValueNode<Primitive> Return, [1]: CNode_7270}
#   2: @↓✓3↓pad_7243:CNode_7270{[0]: ValueNode<Primitive> MakeTuple, [1]: param_mode, [2]: param_input_x, [3]: param_фvalue, [4]: ValueNode<BoolImm> false}


subgraph attr:
subgraph instance: ↰✓3↓pad_7234 : 0x5619919c6c80
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
subgraph @↰✓3↓pad_7234() {
  Return(I64(0))
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
}
# Order:
#   1: @↰✓3↓pad_7234:CNode_7272{[0]: ValueNode<Primitive> Return, [1]: ValueNode<Int64Imm> 0}


subgraph attr:
subgraph instance: ↱✓3↓pad_7235 : 0x5619919a1f30
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
subgraph @↱✓3↓pad_7235 parent: [subgraph @pad_4440]() {
  Return(%para229_value)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
}
# Order:
#   1: @↱✓3↓pad_7235:CNode_7273{[0]: ValueNode<Primitive> Return, [1]: param_value}


subgraph attr:
subgraph instance: 2✓3↓pad_7240 : 0x561991940420
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @2✓3↓pad_7240 parent: [subgraph @✓3↓pad_7198]() {
  %1(CNode_7231) = $(✓3↓pad_7198):S_Prim_is_(%para229_value, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %2(CNode_7232) = $(✓3↓pad_7198):Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %3(CNode_7233) = $(✓3↓pad_7198):Switch(%2, @↰✓3↓pad_7234, @↱✓3↓pad_7235)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %4(value) = $(✓3↓pad_7198):%3()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %5(CNode_7274) = getattr(%para226_input_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3403/            value = scalar_to_tensor_(value, input_x.dtype)/
  %6(value) = S_Prim_ScalarToTensor[output_names: ["output_data"], input_names: ["input_scalar", "dtype"]](%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3403/            value = scalar_to_tensor_(value, input_x.dtype)/
  Return(%6)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3403/            value = scalar_to_tensor_(value, input_x.dtype)/
}
# Order:
#   1: @2✓3↓pad_7240:CNode_7274{[0]: ValueNode<Primitive> getattr, [1]: param_input_x, [2]: ValueNode<StringImm> dtype}
#   2: @2✓3↓pad_7240:value{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ScalarToTensor, [1]: value, [2]: CNode_7274}
#   3: @2✓3↓pad_7240:CNode_7275{[0]: ValueNode<Primitive> Return, [1]: value}


subgraph attr:
subgraph instance: ✗✓3↓pad_7241 : 0x56199188b9f0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗✓3↓pad_7241 parent: [subgraph @✓3↓pad_7198]() {
  %1(CNode_7231) = $(✓3↓pad_7198):S_Prim_is_(%para229_value, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %2(CNode_7232) = $(✓3↓pad_7198):Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %3(CNode_7233) = $(✓3↓pad_7198):Switch(%2, @↰✓3↓pad_7234, @↱✓3↓pad_7235)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  %4(value) = $(✓3↓pad_7198):%3()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3401/        value = 0 if value is None else value/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3402/        if isinstance(value, (float, int)):/
}
# Order:
#   1: @✗✓3↓pad_7241:CNode_7276{[0]: ValueNode<Primitive> Return, [1]: value}


subgraph attr:
subgraph instance: ✓✗3↓pad_7250 : 0x561991441f90
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓✗3↓pad_7250 parent: [subgraph @3↓pad_7176]() {
  %1(CNode_7277) = S_Prim_inner_len(%para482_фpadding)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3406/            raise ValueError(f"For 'pad', the padding must be less than or equal to 6, but got {len(padding)}.")/
  %2(CNode_7278) = JoinedStr("For 'pad', the padding must be less than or equal to 6, but got ", %1, ".")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3406/            raise ValueError(f"For 'pad', the padding must be less than or equal to 6, but got {len(padding)}.")/
  %3(CNode_7279) = raise[side_effect_io: Bool(1)]("ValueError", %2, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3406/            raise ValueError(f"For 'pad', the padding must be less than or equal to 6, but got {len(padding)}.")/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3406/            raise ValueError(f"For 'pad', the padding must be less than or equal to 6, but got {len(padding)}.")/
}
# Order:
#   1: @✓✗3↓pad_7250:CNode_7277{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фpadding}
#   2: @✓✗3↓pad_7250:CNode_7278{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> For 'pad', the padding must be less than or equal to 6, but got , [2]: CNode_7277, [3]: ValueNode<StringImm> .}
#   3: @✓✗3↓pad_7250:CNode_7279{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_7278, [3]: ValueNode<StringImm> None}
#   4: @✓✗3↓pad_7250:CNode_7280{[0]: ValueNode<Primitive> Return, [1]: CNode_7279}


subgraph attr:
subgraph instance: 2✗3↓pad_7251 : 0x561a12c7d2e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @2✗3↓pad_7251 parent: [subgraph @3↓pad_7176]() {
  %1(CNode_7282) = call @↓✗3↓pad_7281()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
}
# Order:
#   1: @2✗3↓pad_7251:CNode_7282{[0]: ValueNode<FuncGraph> ↓✗3↓pad_7281}
#   2: @2✗3↓pad_7251:CNode_7283{[0]: ValueNode<Primitive> Return, [1]: CNode_7282}


subgraph attr:
after_block : 1
subgraph instance: 5↓sum_7260 : 0x56198d2da5d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @5↓sum_7260 parent: [subgraph @sum_4798](%para490_) {
  %1(CNode_7284) = S_Prim_is_not(%para376_dim, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12022/    if dim is not None:/
  %2(CNode_7285) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12022/    if dim is not None:/
  %3(CNode_7286) = Switch(%2, @✓5↓sum_7287, @✗5↓sum_7288)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12022/    if dim is not None:/
  %4(CNode_7289) = %3()
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12022/    if dim is not None:/
  %5(CNode_7291) = call @6↓sum_7290(%4)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /tmp/ipykernel_280126/1697004305.py:39/
  Return(%5)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12022/    if dim is not None:/
}
# Order:
#   1: @5↓sum_7260:CNode_7292{[0]: ValueNode<FuncGraph> _get_cache_prim_4422, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.ReduceSum'}
#   2: @5↓sum_7260:CNode_7293{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> keep_dims}
#   3: @5↓sum_7260:CNode_7294{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_keepdim}
#   4: @5↓sum_7260:CNode_7295{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_7293, [2]: CNode_7294}
#   5: @5↓sum_7260:reduce_sum{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.7296, [1]: CNode_7292, [2]: CNode_7295}
#   6: @5↓sum_7260:CNode_7284{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: param_dim, [2]: ValueNode<None> None}
#   7: @5↓sum_7260:CNode_7285{[0]: ValueNode<Primitive> Cond, [1]: CNode_7284, [2]: ValueNode<BoolImm> false}
#   8: @5↓sum_7260:CNode_7286{[0]: ValueNode<Primitive> Switch, [1]: CNode_7285, [2]: ValueNode<FuncGraph> ✓5↓sum_7287, [3]: ValueNode<FuncGraph> ✗5↓sum_7288}
#   9: @5↓sum_7260:CNode_7289{[0]: CNode_7286}
#  10: @5↓sum_7260:CNode_7291{[0]: ValueNode<FuncGraph> 6↓sum_7290, [1]: CNode_7289}
#  11: @5↓sum_7260:CNode_7297{[0]: ValueNode<Primitive> Return, [1]: CNode_7291}


subgraph attr:
subgraph instance: ✓4↓sum_7257 : 0x56198fe83990
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✓4↓sum_7257 parent: [subgraph @4↓sum_7215]() {
  %1(CNode_7298) = getattr(%para487_фinput, "astype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12020/        input = input.astype(dtype)/
  %2(input) = %1(%para378_dtype)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12020/        input = input.astype(dtype)/
  Return(%2)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12020/        input = input.astype(dtype)/
}
# Order:
#   1: @✓4↓sum_7257:CNode_7298{[0]: ValueNode<Primitive> getattr, [1]: param_фinput, [2]: ValueNode<StringImm> astype}
#   2: @✓4↓sum_7257:input{[0]: CNode_7298, [1]: param_dtype}
#   3: @✓4↓sum_7257:CNode_7299{[0]: ValueNode<Primitive> Return, [1]: input}


subgraph attr:
subgraph instance: ✗4↓sum_7258 : 0x56198b98d6d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✗4↓sum_7258 parent: [subgraph @4↓sum_7215]() {
  Return(%para487_фinput)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12019/    if dtype is not None:/
}
# Order:
#   1: @✗4↓sum_7258:CNode_7300{[0]: ValueNode<Primitive> Return, [1]: param_фinput}


subgraph attr:
after_block : 1
subgraph instance: ↓✗3↓pad_7281 : 0x561a12c493e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @↓✗3↓pad_7281 parent: [subgraph @3↓pad_7176]() {
  %1(CNode_7301) = S_Prim_is_not(%para229_value, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3407/        if value is not None:/
  %2(CNode_7302) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3407/        if value is not None:/
  %3(CNode_7303) = Switch(%2, @✓↓✗3↓pad_7304, @✗↓✗3↓pad_7305)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3407/        if value is not None:/
  %4(CNode_7306) = %3()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3407/        if value is not None:/
  Return(%4)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3407/        if value is not None:/
}
# Order:
#   1: @↓✗3↓pad_7281:CNode_7301{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: param_value, [2]: ValueNode<None> None}
#   2: @↓✗3↓pad_7281:CNode_7302{[0]: ValueNode<Primitive> Cond, [1]: CNode_7301, [2]: ValueNode<BoolImm> false}
#   3: @↓✗3↓pad_7281:CNode_7303{[0]: ValueNode<Primitive> Switch, [1]: CNode_7302, [2]: ValueNode<FuncGraph> ✓↓✗3↓pad_7304, [3]: ValueNode<FuncGraph> ✗↓✗3↓pad_7305}
#   4: @↓✗3↓pad_7281:CNode_7306{[0]: CNode_7303}
#   5: @↓✗3↓pad_7281:CNode_7307{[0]: ValueNode<Primitive> Return, [1]: CNode_7306}


subgraph attr:
after_block : 1
subgraph instance: 6↓sum_7290 : 0x561a1fd5e350
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @6↓sum_7290(%para491_) {
  Return(%para491_фout)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12026/    return out/
}
# Order:
#   1: @6↓sum_7290:CNode_7308{[0]: ValueNode<Primitive> Return, [1]: param_фout}


subgraph attr:
subgraph instance: ✓5↓sum_7287 : 0x561987c3f3d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✓5↓sum_7287 parent: [subgraph @5↓sum_7260]() {
  %1(CNode_7292) = $(5↓sum_7260):call @_get_cache_prim_4422(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %2(CNode_7293) = $(5↓sum_7260):S_Prim_MakeTuple("keep_dims")
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %3(CNode_7294) = $(5↓sum_7260):S_Prim_MakeTuple(%para377_keepdim)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %4(CNode_7295) = $(5↓sum_7260):S_Prim_make_dict(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %5(reduce_sum) = $(5↓sum_7260):UnpackCall_unpack_call(%1, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %6(out) = %5(%para490_фinput, %para376_dim)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12023/        out = reduce_sum(input, dim)/
  Return(%6)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12023/        out = reduce_sum(input, dim)/
}
# Order:
#   1: @✓5↓sum_7287:out{[0]: reduce_sum, [1]: param_фinput, [2]: param_dim}
#   2: @✓5↓sum_7287:CNode_7309{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
subgraph instance: ✗5↓sum_7288 : 0x5619881ab2d0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:11954/def sum(input, dim=None, keepdim=False, *, dtype=None):/
subgraph @✗5↓sum_7288 parent: [subgraph @5↓sum_7260]() {
  %1(CNode_7292) = $(5↓sum_7260):call @_get_cache_prim_4422(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %2(CNode_7293) = $(5↓sum_7260):S_Prim_MakeTuple("keep_dims")
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %3(CNode_7294) = $(5↓sum_7260):S_Prim_MakeTuple(%para377_keepdim)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %4(CNode_7295) = $(5↓sum_7260):S_Prim_make_dict(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %5(reduce_sum) = $(5↓sum_7260):UnpackCall_unpack_call(%1, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12021/    reduce_sum = _get_cache_prim(P.ReduceSum)(keep_dims=keepdim)/
  %6(out) = %5(%para490_фinput)
      : (<null>) -> (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12025/        out = reduce_sum(input)/
  Return(%6)
      : (<null>)
      #scope: (Default/_loss_fn-FocalLoss)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:12025/        out = reduce_sum(input)/
}
# Order:
#   1: @✗5↓sum_7288:out{[0]: reduce_sum, [1]: param_фinput}
#   2: @✗5↓sum_7288:CNode_7310{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
subgraph instance: ✓↓✗3↓pad_7304 : 0x561a12beb3e0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓↓✗3↓pad_7304 parent: [subgraph @pad_4440]() {
  %1(CNode_7311) = JoinedStr("For 'pad', the padding mode '", %para228_mode, "' can not set value, but got value ", %para229_value, ".")
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3408/            raise ValueError(f"For 'pad', the padding mode '{mode}' can not set value, but got value {value}.")/
  %2(CNode_7312) = raise[side_effect_io: Bool(1)]("ValueError", %1, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3408/            raise ValueError(f"For 'pad', the padding mode '{mode}' can not set value, but got value {value}.")/
  Return(%2)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3408/            raise ValueError(f"For 'pad', the padding mode '{mode}' can not set value, but got value {value}.")/
}
# Order:
#   1: @✓↓✗3↓pad_7304:CNode_7311{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> For 'pad', the padding mode ', [2]: param_mode, [3]: ValueNode<StringImm> ' can not set value, but got value , [4]: param_value, [5]: ValueNode<StringImm> .}
#   2: @✓↓✗3↓pad_7304:CNode_7312{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_7311, [3]: ValueNode<StringImm> None}
#   3: @✓↓✗3↓pad_7304:CNode_7313{[0]: ValueNode<Primitive> Return, [1]: CNode_7312}


subgraph attr:
subgraph instance: ✗↓✗3↓pad_7305 : 0x561a12b437c0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗↓✗3↓pad_7305 parent: [subgraph @3↓pad_7176]() {
  %1(CNode_7315) = call @2↓✗3↓pad_7314()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3407/        if value is not None:/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3407/        if value is not None:/
}
# Order:
#   1: @✗↓✗3↓pad_7305:CNode_7315{[0]: ValueNode<FuncGraph> 2↓✗3↓pad_7314}
#   2: @✗↓✗3↓pad_7305:CNode_7316{[0]: ValueNode<Primitive> Return, [1]: CNode_7315}


subgraph attr:
after_block : 1
subgraph instance: 2↓✗3↓pad_7314 : 0x561a12a73790
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @2↓✗3↓pad_7314 parent: [subgraph @3↓pad_7176]() {
  %1(CNode_7317) = S_Prim_equal(%para228_mode, "replicate")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3409/        if mode == "replicate":/
  %2(CNode_7318) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3409/        if mode == "replicate":/
  %3(CNode_7319) = Switch(%2, @✓2↓✗3↓pad_7320, @✗2↓✗3↓pad_7321)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3409/        if mode == "replicate":/
  %4(CNode_7322) = %3()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3409/        if mode == "replicate":/
  %5(CNode_7324) = call @3↓✗3↓pad_7323(%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3409/        if mode == "replicate":/
}
# Order:
#   1: @2↓✗3↓pad_7314:CNode_7317{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_mode, [2]: ValueNode<StringImm> replicate}
#   2: @2↓✗3↓pad_7314:CNode_7318{[0]: ValueNode<Primitive> Cond, [1]: CNode_7317, [2]: ValueNode<BoolImm> false}
#   3: @2↓✗3↓pad_7314:CNode_7319{[0]: ValueNode<Primitive> Switch, [1]: CNode_7318, [2]: ValueNode<FuncGraph> ✓2↓✗3↓pad_7320, [3]: ValueNode<FuncGraph> ✗2↓✗3↓pad_7321}
#   4: @2↓✗3↓pad_7314:CNode_7322{[0]: CNode_7319}
#   5: @2↓✗3↓pad_7314:CNode_7324{[0]: ValueNode<FuncGraph> 3↓✗3↓pad_7323, [1]: CNode_7322}
#   6: @2↓✗3↓pad_7314:CNode_7325{[0]: ValueNode<Primitive> Return, [1]: CNode_7324}


subgraph attr:
after_block : 1
subgraph instance: 3↓✗3↓pad_7323 : 0x5619a2263420
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @3↓✗3↓pad_7323 parent: [subgraph @3↓pad_7176](%para492_) {
  %1(CNode_7326) = getattr(%para482_фpadding, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  %2(CNode_7327) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  %3(CNode_7328) = S_Prim_floordiv(%2, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  %4(CNode_7329) = S_Prim_add(%3, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  %5(CNode_7330) = getattr(%para226_input_x, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  %6(CNode_7331) = S_Prim_equal(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  %7(CNode_7332) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  %8(CNode_7333) = Switch(%7, @✓3↓✗3↓pad_7334, @✗3↓✗3↓pad_7335)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  %9(CNode_7336) = %8()
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
  Return(%9)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
}
# Order:
#   1: @3↓✗3↓pad_7323:CNode_7326{[0]: ValueNode<Primitive> getattr, [1]: param_фpadding, [2]: ValueNode<StringImm> shape}
#   2: @3↓✗3↓pad_7323:CNode_7327{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_7326, [2]: ValueNode<Int64Imm> 0}
#   3: @3↓✗3↓pad_7323:CNode_7328{[0]: ValueNode<DoSignaturePrimitive> S_Prim_floordiv, [1]: CNode_7327, [2]: ValueNode<Int64Imm> 2}
#   4: @3↓✗3↓pad_7323:CNode_7329{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_7328, [2]: ValueNode<Int64Imm> 1}
#   5: @3↓✗3↓pad_7323:CNode_7330{[0]: ValueNode<Primitive> getattr, [1]: param_input_x, [2]: ValueNode<StringImm> ndim}
#   6: @3↓✗3↓pad_7323:CNode_7331{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_7329, [2]: CNode_7330}
#   7: @3↓✗3↓pad_7323:CNode_7332{[0]: ValueNode<Primitive> Cond, [1]: CNode_7331, [2]: ValueNode<BoolImm> false}
#   8: @3↓✗3↓pad_7323:CNode_7333{[0]: ValueNode<Primitive> Switch, [1]: CNode_7332, [2]: ValueNode<FuncGraph> ✓3↓✗3↓pad_7334, [3]: ValueNode<FuncGraph> ✗3↓✗3↓pad_7335}
#   9: @3↓✗3↓pad_7323:CNode_7336{[0]: CNode_7333}
#  10: @3↓✗3↓pad_7323:CNode_7337{[0]: ValueNode<Primitive> Return, [1]: CNode_7336}


subgraph attr:
subgraph instance: ✓2↓✗3↓pad_7320 : 0x561a1279a990
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓2↓✗3↓pad_7320() {
  Return("edge")
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3410/            mode = "edge"/
}
# Order:
#   1: @✓2↓✗3↓pad_7320:CNode_7338{[0]: ValueNode<Primitive> Return, [1]: ValueNode<StringImm> edge}


subgraph attr:
subgraph instance: ✗2↓✗3↓pad_7321 : 0x5619a227acb0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗2↓✗3↓pad_7321 parent: [subgraph @pad_4440]() {
  Return(%para228_mode)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3409/        if mode == "replicate":/
}
# Order:
#   1: @✗2↓✗3↓pad_7321:CNode_7339{[0]: ValueNode<Primitive> Return, [1]: param_mode}


subgraph attr:
subgraph instance: ✓3↓✗3↓pad_7334 : 0x5619891561b0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✓3↓✗3↓pad_7334 parent: [subgraph @3↓✗3↓pad_7323]() {
  %1(CNode_7340) = getattr(%para226_input_x, "expand_dims")
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3412/            input_x = input_x.expand_dims(0)/
  %2(input_x) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3412/            input_x = input_x.expand_dims(0)/
  %3(CNode_7342) = call @4↓✗3↓pad_7341(%2, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3412/            input_x = input_x.expand_dims(0)/
}
# Order:
#   1: @✓3↓✗3↓pad_7334:CNode_7340{[0]: ValueNode<Primitive> getattr, [1]: param_input_x, [2]: ValueNode<StringImm> expand_dims}
#   2: @✓3↓✗3↓pad_7334:input_x{[0]: CNode_7340, [1]: ValueNode<Int64Imm> 0}
#   3: @✓3↓✗3↓pad_7334:CNode_7343{[0]: ValueNode<Primitive> Return, [1]: CNode_7342}
#   4: @✓3↓✗3↓pad_7334:CNode_7342{[0]: ValueNode<FuncGraph> 4↓✗3↓pad_7341, [1]: input_x, [2]: ValueNode<BoolImm> true}


subgraph attr:
subgraph instance: ✗3↓✗3↓pad_7335 : 0x561a17d3bef0
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @✗3↓✗3↓pad_7335 parent: [subgraph @3↓✗3↓pad_7323]() {
  %1(CNode_7344) = call @4↓✗3↓pad_7341(%para226_input_x, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3411/        if padding.shape[0] // 2 + 1 == input_x.ndim:/
}
# Order:
#   1: @✗3↓✗3↓pad_7335:CNode_7345{[0]: ValueNode<Primitive> Return, [1]: CNode_7344}
#   2: @✗3↓✗3↓pad_7335:CNode_7344{[0]: ValueNode<FuncGraph> 4↓✗3↓pad_7341, [1]: param_input_x, [2]: ValueNode<BoolImm> false}


subgraph attr:
after_block : 1
subgraph instance: 4↓✗3↓pad_7341 : 0x561a17c63410
# In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3284/def pad(input_x, padding, mode='constant', value=None):/
subgraph @4↓✗3↓pad_7341 parent: [subgraph @3↓✗3↓pad_7323](%para493_, %para494_) {
  %1(CNode_7346) = MakeTuple(%para492_фmode, %para493_фinput_x, %para229_value, %para494_фis_expand)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /tmp/ipykernel_280126/3613542768.py:50/
  Return(%1)
      : (<null>)
      #scope: (Default/network-WithLossCell/_backbone-FixedBitModel)
      # In file /home/y/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:3405/        if len(padding) > 6:/
}
# Order:
#   1: @4↓✗3↓pad_7341:CNode_7347{[0]: ValueNode<Primitive> Return, [1]: CNode_7346}
#   2: @4↓✗3↓pad_7341:CNode_7346{[0]: ValueNode<Primitive> MakeTuple, [1]: param_фmode, [2]: param_фinput_x, [3]: param_value, [4]: param_фis_expand}


